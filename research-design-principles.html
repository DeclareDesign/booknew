<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 3 Research design principles | Research Design: Declare, Diagnose, Redesign</title>
<meta name="author" content="Graeme Blair, Alexander Coppock, and Macartan Humphreys">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.4.9002/tabs.js"></script><script src="libs/bs3compat-0.2.4.9002/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<link href="libs/bs4_book-1.0.0/dd_imgpopup.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/bs4_book-1.0.0/dd_imgpopup.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://hypothes.is/embed.js" async></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS --><link rel="stylesheet" href="headers/style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Research Design: Declare, Diagnose, Redesign</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li class="book-part">Introduction</li>
<li><a class="" href="preamble.html"><span class="header-section-number">1</span> Preamble</a></li>
<li><a class="" href="defining-research-designs.html"><span class="header-section-number">2</span> Defining research designs</a></li>
<li><a class="active" href="research-design-principles.html"><span class="header-section-number">3</span> Research design principles</a></li>
<li><a class="" href="primer.html"><span class="header-section-number">4</span> Software primer</a></li>
<li><a class="" href="part-i-exercises.html"><span class="header-section-number">5</span> Part I Exercises</a></li>
<li class="book-part">Declaration, Diagnosis, Redesign</li>
<li><a class="" href="declaration-1.html"><span class="header-section-number">6</span> Declaration</a></li>
<li><a class="" href="specifying-the-model.html"><span class="header-section-number">7</span> Specifying the model</a></li>
<li><a class="" href="defining-the-inquiry.html"><span class="header-section-number">8</span> Defining the inquiry</a></li>
<li><a class="" href="crafting-a-data-strategy.html"><span class="header-section-number">9</span> Crafting a data strategy</a></li>
<li><a class="" href="choosing-an-answer-strategy.html"><span class="header-section-number">10</span> Choosing an answer strategy</a></li>
<li><a class="" href="p2diagnosis.html"><span class="header-section-number">11</span> Diagnosis</a></li>
<li><a class="" href="redesign-2.html"><span class="header-section-number">12</span> Redesign</a></li>
<li><a class="" href="part-ii-exercises.html"><span class="header-section-number">13</span> Part II Exercises</a></li>
<li class="book-part">Research Design Library</li>
<li><a class="" href="research-design-library.html"><span class="header-section-number">14</span> Research Design Library</a></li>
<li><a class="" href="observational-descriptive.html"><span class="header-section-number">15</span> Observational | descriptive</a></li>
<li><a class="" href="observational-causal.html"><span class="header-section-number">16</span> Observational | causal</a></li>
<li><a class="" href="experimental-causal.html"><span class="header-section-number">17</span> Experimental | causal</a></li>
<li><a class="" href="experimental-descriptive.html"><span class="header-section-number">18</span> Experimental | descriptive</a></li>
<li><a class="" href="complex-designs-1.html"><span class="header-section-number">19</span> Complex designs</a></li>
<li><a class="" href="part-iii-exercises.html"><span class="header-section-number">20</span> Part III Exercises</a></li>
<li class="book-part">Research Design Lifecycle</li>
<li><a class="" href="research-design-lifecycle.html"><span class="header-section-number">21</span> Research Design Lifecycle</a></li>
<li><a class="" href="brainstorming.html"><span class="header-section-number">22</span> Brainstorming</a></li>
<li><a class="" href="planning.html"><span class="header-section-number">23</span> Planning</a></li>
<li><a class="" href="realization.html"><span class="header-section-number">24</span> Realization</a></li>
<li><a class="" href="integration.html"><span class="header-section-number">25</span> Integration</a></li>
<li><a class="" href="part-iv-exercises.html"><span class="header-section-number">26</span> Part IV Exercises</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="research-design-principles" class="section level1">
<h1>
<span class="header-section-number">3</span> Research design principles<a class="anchor" aria-label="anchor" href="#research-design-principles"><i class="fas fa-link"></i></a>
</h1>
<p>The declare, diagnose, redesign framework suggests a set of twelve principles that can guide the design process. Not all principles are equally important in all cases but we think all are worth giving consideration when developing and assessing a design.</p>
<p>We state the principles and then describe each in detail.</p>
<div class="principles">
<div class="principles-title">
<p>Design principles</p>
</div>
<ol style="list-style-type: decimal">
<li><p>Design early</p></li>
<li><p>Select answerable inquiries</p></li>
<li><p>Render inquiries insensitive to models</p></li>
<li><p>Seek <em>M</em>:<em>I</em>, <em>D</em>:<em>A</em> parallelism</p></li>
<li><p>Make <em>M</em> large</p></li>
<li><p>Find your limits</p></li>
<li><p>Bake in implementation failures</p></li>
<li><p>Specify your criteria for a good design</p></li>
<li><p>Evaluate holistically</p></li>
<li><p>Redesign over <em>D</em> and <em>A</em></p></li>
<li><p>Redesign often</p></li>
<li><p>Design to share</p></li>
</ol>
</div>
<div id="design-early" class="section level2">
<h2>
<span class="header-section-number">3.1</span> Design early<a class="anchor" aria-label="anchor" href="#design-early"><i class="fas fa-link"></i></a>
</h2>
<p>Research designs can be declared and diagnosed profitably at many stages of the research process, including after implementation or even publication. However, designing early yields big gains. You learn about the properties of a design when there is still time to improve them. Once data strategies are implemented – units sampled, treatments assigned, and outcomes measured – there is no going backwards. But when you are at the point of analysis you might well wish you gather data differently, or even pose new questions.</p>
<p>The process of declaring the design may change the design, so we recommend frontloading design decisions. By revealing how the model, inquiry, data strategy, and answer strategy are interconnected, improvements to each element may be surfaced. If the answer strategy and inquiry are mismatched, the designer faces a choice to change one or the other. If the units sampled in the data strategy are in disharmony with the theoretical model, alternative participants might be sourced. Models may reveal assumptions that require defense through additional data collection. Better inquiries, with more theoretical leverage over the model, may be identified. Inquiries that cannot be answered may be replaced.</p>
<p>Designing early does not mean being inflexible. You can change a design to reflect new knowledge gained during piloting or implementation. But the fact that designs can change later does not take away from the gains from thinking ahead.</p>
<p><span class="math inline">\(\rightarrow\)</span> In section <code>X</code> we give examples of how to design in advance when you don’t yet know.</p>
</div>
<div id="select-answerable-inquiries" class="section level2">
<h2>
<span class="header-section-number">3.2</span> Select answerable inquiries<a class="anchor" aria-label="anchor" href="#select-answerable-inquiries"><i class="fas fa-link"></i></a>
</h2>
<p>This principle has two components.</p>
<p>First, <em>you should have an inquiry</em>. Oddly, it is possible to carry out data analysis – for instance, running a regression of <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> – and getting something that looks like an answer without specifying any question in particular. The diagnosis process is generally geared to seeing whether you have a good answer. Assessing that in turn requires a well-defined inquiry. So the process of declaration and diagnosis helps make sure you have a question.</p>
<p>Second, the question you have should be in principle answerable. That’s trickier than it sounds. We can think of being answerable in theory and in practice.</p>
<p>A question is answerable “in theory” if you can write down a model such that, if that model were the true model, and you knew the model, you could answer the question. Simple sounding questions like “Did Germany cause the Second World War?” or “did New Zealand do well against Covid-19 because Prime Minister Jacinda Ardern was a woman?” can turn out to be difficult to ask and answer even if you have a well-defined model. This, we think, can give a hint to when a question is poorly posed. Make sure that you can describe <em>some</em> world such that if you fully understood the world you would have a precise answer to your question. In the <em>MIDA</em> framework we might think of a model as being answerable in theory if you get an answer when you apply <em>I</em> to <em>M</em>.</p>
<p>We can think of a question as being answerable “in practice” if the question could be answerable with data (even if such a dataset would be difficult to obtain). This idea relates to the concept of “identification” in statistics. A question is at least partly answerable if there are at least two different sets of data you might observe that would lead you to make two different inferences. In the best case, one might imagine that you have lots of data and each possible data pattern you see is consistent with only one possible answer. You might then say that your model, or inquiry, is identified. Failing that you might imagine that different data patterns at least let you rule out some answers even though you can’t be sure of the right answer. In this case we have “partial identification.”</p>
<p>Perhaps surprisingly, some inquiries might not even be partially identifiable. For instance if we have a model that says an outcome <span class="math inline">\(Y\)</span> is defined by the equation <span class="math inline">\(Y=(a+b)X\)</span>, no amount of data can tell us the exact values of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. Indeed without boundary constraints, no amount of data can even narrow down the ranges of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. The basic problem is that for any value of <span class="math inline">\(a\)</span> we can choose a <span class="math inline">\(b\)</span> that keeps the sum of <span class="math inline">\(a+b\)</span> constant. In this setting, even though there is an answer to our inquiry (<span class="math inline">\(a\)</span>) in theory it is not one we can ever answer in practice. Many other types of inquiries, such as mediation inquiries, are not identifiable. There are some circumstances in which we can provide a partial answer to the inquiry, such as learning a range of values within which the parameter lives. At a minimum, we urge you to pose inquiries that are at least partially answerable with possible data.</p>
<p><span class="math inline">\(\rightarrow\)</span> In section <code>X</code> we give an example of a design that sought to answer a question that turned out to be unanswerable.</p>
</div>
<div id="render-inquiries-insensitive-to-models" class="section level2">
<h2>
<span class="header-section-number">3.3</span> Render inquiries insensitive to models<a class="anchor" aria-label="anchor" href="#render-inquiries-insensitive-to-models"><i class="fas fa-link"></i></a>
</h2>
<p>Sometimes researchers write down a model and then point to some model-specific quantity that they want to lean about. The problem with this approach however is that if you, or someone else, worry that the model might be wrong and want to assess how the design performs under a different model you might find that you can’t do it because the inquiry is defined under the original model, but not under others.</p>
<p>Here are two quite common examples where a problem like this arises. First, imagine a researcher assumes that <span class="math inline">\(Y= \beta_0+\beta_1 X\)</span> and says they want to learn about <span class="math inline">\(\beta_1\)</span>. A second researcher thinks the true model is <span class="math inline">\(Y= \gamma_0 + \gamma_1 X + \gamma_2 X^2\)</span>. What then is researcher 1’s question under researcher 2’s model? For a second example researcher 1 is interested in the average treatment effect, which they describe as <span class="math inline">\(E(Y_i(1)-Y_i(0))\)</span>. Researcher 2 wonders how well researcher 1’s strategy works if there are spillovers, but then realizes that the presupposition of no spillovers is baked into the definition of research 1’s inquiry. How then to assess whether the strategy works well?</p>
<p>One approach is to require that readers just accept that our model is correct and so the question is well defined. But this has the distinct disadvantage of preventing us from even <em>asking</em> how the design would perform if the model is wrong. A better approach is to define the inquiry in a way that requires as few assumptions as possible about the world. For instance, for example 1, instead of <span class="math inline">\(\beta\)</span> we could say that we are interested in the average effect on <span class="math inline">\(Y\)</span> of a unit change in <span class="math inline">\(X\)</span>. Similarly, for example 2, we might redefine the average treatment effect as the average difference between a unit being the only unit treated and a situation where all other units are assigned to control.</p>
<!-- This paragraph relies on too many ideas we haven't introduced yet -->
<!-- In practice we encourage you to define inquiries as summaries of the values (or potential values) of  nodes of a model. If you do that then the definition depends only on what's called the "signature" of the model---the set of nodes and their ranges---and not specific assumptions about how nodes relate to each other---the structural equations. -->
<p><span class="math inline">\(\rightarrow\)</span> In section <code>X</code> we show an example of a design that seeks to estimate deep parameters from a structural model but using an approach where the question does not depend on the model being correct.</p>
</div>
<div id="seek-mi-da-parallelism" class="section level2">
<h2>
<span class="header-section-number">3.4</span> Seek <em>M</em>:<em>I</em>, <em>D</em>:<em>A</em> parallelism<a class="anchor" aria-label="anchor" href="#seek-mi-da-parallelism"><i class="fas fa-link"></i></a>
</h2>
<p>A useful feature that you can see from the <em>MIDA</em> framework is that when data strategies introduce no distortions, answer strategies can be directly analogous to inquiries. If the data is “like” the distributions generated by a model then if <em>A</em> is like <em>I</em>, the estimate will be like the estimand.</p>
<p>This idea is is a version “plug-in principle” that under many data strategies, we can “plug-in” the inquiry for the answer strategy For example if you are interested in estimating the population mean or the population variance, you can draw a sample from the population and estimate these quantities using the sample mean and variance estimators <span class="citation">(Van der Vaart <a href="references.html#ref-van2000asymptotic" role="doc-biblioref">2000</a>)</span>.</p>
<p>The principle does not always hold but there is an interesting generalization. When data strategies do introduce distortions, the answer strategy should compensate for them to restore parallelism. We restore parallelism then by seeking an <em>A</em> such that <em>A</em> after <em>D</em> approximates <em>I</em>. This idea underpins the maxim “analyze as you randomize” <span class="citation">(Fisher <a href="references.html#ref-fisher1937design" role="doc-biblioref">1937</a>)</span>: if your data is not a simple draw from the population you care about you need to account for that fact and the data strategy itself gives guidance for how to do that.</p>
<p><span class="math inline">\(\rightarrow\)</span> We show plug-in principles in action in section <code>X</code>.</p>
</div>
<div id="make-m-large" class="section level2">
<h2>
<span class="header-section-number">3.5</span> Make <em>M</em> large<a class="anchor" aria-label="anchor" href="#make-m-large"><i class="fas fa-link"></i></a>
</h2>
<!-- This principle is still a little tough to grok -- does the right name? Consider many models? -->
<p>Broadly, there are two ways to be sure that a data and answer strategy return the right answer under some class of models. One is a form of shooting fish in a barrel: you narrow down the set of models so much that your data and answer strategy are sure to work within the set. In the extreme case, you entertain models in which the answer is “4” and your answer strategy is “4”. For a less trivial example you assume that there are no confounders and interpret correlation as causation, refusing to contemplate alternatives. People do that.</p>
<p>The second approach is to design <em>D</em> and <em>A</em> specifically to ensure that <em>D</em> and <em>A</em> perform well even under a wide class of models – including models that you might have never considered. This is the principle behind “design based inference” approaches or behind the use of “doubly robust” estimators. The core idea is that your design gets stronger if it continues to perform well as your assumptions on <em>M</em> get weaker.</p>
</div>
<div id="find-your-limits" class="section level2">
<h2>
<span class="header-section-number">3.6</span> Find your limits<a class="anchor" aria-label="anchor" href="#find-your-limits"><i class="fas fa-link"></i></a>
</h2>
<p>A kind of corollary of “Make <em>M</em> large” is that while you should try to make <span class="math inline">\(M\)</span> large you have to know where its edges are. It’s good to learn from design declaration and diagnosis that given some model and some empirical strategy faithfully implemented, we get a reliable answer with high probability. But designs can also be used to get clarity over when a design will <em>not</em> produce a good answer. Your design might assume for instance that one variable is not affected by another variable and the validity of your answer might depend on the extent to which this is true. A design that contains a set of models that include violations of this assumption can be used to assess the extent to which the assumption matters, how bad a violation has to be to produce misleading results of consequence, and what types of assumptions are critical for inference and which ones are not. In short, seek to construct a model set so you can understand the worlds for which your design works and the worlds in which you run into problems.</p>
<p>Research design diagnosis is useful only if the design is assessed not only under conditions favorable to the researcher, but those unfavorable to the researcher. Designs should provide useful answers to inquiries in both sets of circumstances. Diagnosis under both sets can reveal if that is the case, or if changes to the data and answer strategy are needed. Even when there are circumstances under which the design performs poorly, understanding when that is the case aids interpretation of the results and focuses reanalysis debates substantively on which models are plausible.</p>
<p><span class="math inline">\(\rightarrow\)</span> Section <code>X</code> describes a design defined over a <em>set</em> of models; diagnosis reveals that the design performs excellently in subsets of the set but fails in other subsets.</p>
</div>
<div id="bake-in-implementation-failures" class="section level2">
<h2>
<span class="header-section-number">3.7</span> Bake in implementation failures<a class="anchor" aria-label="anchor" href="#bake-in-implementation-failures"><i class="fas fa-link"></i></a>
</h2>
<p>A common approach to research planning is to write down the ideal design, then go implement it, encounter problems, and seek fixes. Missing data, archival documents that cannot be traced, noncompliance with treatment assignments, evidence of spillovers, and difficulties recontacting subjects in followup surveys are just some of the common problems empirical researchers face. Insofar as these are predictable problems it can be useful to think of them as <em>parts</em> of your design not <em>deviations</em> from your design. Answer strategies can be developed that anticipate these problems, and account for them, including if-then plans for handling each likely implementation problem. More fundamentally, anticipated failures themselves can be included in your model so that you can diagnose the properties of different strategies, in advance, given risks of different kinds.</p>
<p><span class="math inline">\(\rightarrow\)</span> Section <code>X</code> gives an example of a design that incorporates risks of non-random attrition.</p>
</div>
<div id="specify-your-criteria-for-a-good-design" class="section level2">
<h2>
<span class="header-section-number">3.8</span> Specify your criteria for a good design<a class="anchor" aria-label="anchor" href="#specify-your-criteria-for-a-good-design"><i class="fas fa-link"></i></a>
</h2>
<p>In evaluating designs, researchers often focus on quite narrow criteria, or what we call diagnosands, and consider them in isolation. Is the estimator unbiased? Do I have statistical power? But the evaluation of a design often requires balancing multiple criteria: scientific precision, logistical constraints, policy goals, as well ethical considerations. Each of these goals can be specified as a function of an implementation of the design. The cost is straightforward, a function translating the number of units and the amount of time it took to collect and analyze data about them into a financial value. Scientific goals may be represented in a number of ways, such as the root mean-squared error or statistical power or most directly the amount of learning between before and after the study was conducted. Ethical goals may also be translated into functions. An ethical diagnosand might be the number of minutes of time taken from participants of the study or whether any participants would be harmed.</p>
<p>A diagnosis of designs across multiple criteria can provide us with a multidimensional value statement of each design. We then should select the optimal design, subject to feasibility. Putting this into practice forces us to provide a weighting scheme between ethical, logistical, and scientific values. Those weighting schemes may be that either the study is ethical and we do it or it is not ethical and we do not do it. Or there may be tradeoffs we navigate between the amount of time taken up of subjects and the scientific value of a larger sample that imply choosing a middle ground.</p>
<p><span class="math inline">\(\rightarrow\)</span> Section <code>X</code> walks through the selection and combination of “diagnosands.”</p>
</div>
<div id="evaluate-holistically" class="section level2">
<h2>
<span class="header-section-number">3.9</span> Evaluate holistically<a class="anchor" aria-label="anchor" href="#evaluate-holistically"><i class="fas fa-link"></i></a>
</h2>
<p>Too often, researchers evaluate parts of their designs in isolation: is this a good question? Is this a good estimator? What’s the best way to sample? However, evaluation of a design requires knowing how the parts fit together. If we ask, “What’s your research design?” and you respond “It’s a regression discontinuity design,” we’ve learned what your answer strategy might be, but we don’t have enough information to decide whether it’s a strong design until we learn about the model, inquiry, data strategy, and other parts of the answer strategy.</p>
<p>In practice we do this by declaring the entire design, and asking how it performs, from start to finish, with respect to specified diagnosands. To be able to do this we require a sufficiently complete design declaration. Indeed the ability to run through a design to the point where a diagnosis can be undertaken is, we think, a good indicator of an adequately declared design. In Chapter <a href="p2diagnosis.html#p2diagnosis">11</a>, we discuss the idea of “diagnosand-complete” designs in more detail.</p>
<p><span class="math inline">\(\rightarrow\)</span> Section <code>X</code> revisits a common debate “should I use OLS or ordered probit?” and show how the question is poorly posed without clarity on other aspects of a design</p>
</div>
<div id="redesign-over-d-and-a" class="section level2">
<h2>
<span class="header-section-number">3.10</span> Redesign over <em>D</em> and <em>A</em><a class="anchor" aria-label="anchor" href="#redesign-over-d-and-a"><i class="fas fa-link"></i></a>
</h2>
<p>You may well feel that you are done once you declare a design that promises to answer the questions you care about. That is the point however when you can most easily think through the performance of your design relative to alternatives. The redesign stage is centered on identifying alternative feasible data and answer strategies and then diagnosing the alternatives. The feasible set may include variations in <em>D</em> – changes to sampling procedures, assignment probabilities, or measurement techniques. The data strategy is where researchers often fine tune designs. But redesign can also consider changes to <em>A</em>, by varying estimation or inferential procedures. Optimization can then be conducted by diagnosing across multiple feasible combinations of the different dimensions of the designs and selecting from the best-performing combinations.</p>
<p><span class="math inline">\(\rightarrow\)</span> Section <code>X</code> describes formal optimization procedures.</p>
</div>
<div id="redesign-often" class="section level2">
<h2>
<span class="header-section-number">3.11</span> Redesign often<a class="anchor" aria-label="anchor" href="#redesign-often"><i class="fas fa-link"></i></a>
</h2>
<p>We emphasized designing early and we often have an image of designing first and implementing later. But in practice as you implement your design, it might change. Sample sizes change, measures change, estimation strategies change. Sometimes even your questions change.</p>
<p>These features might not have been part of your original design but they are part of your design once they happen. In such cases you can redesign, assess the properties of the updated design, and compare it to the old design. When unforeseen changes to budgets, time availability, or other logistical constraints appear, we should ask ourselves two questions: First, given new realities, what is the best design, even if different from originally envisioned? The best design subject to new constraints can be answered with a fresh round of declaration, diagnosis and redesign. Second, is it worth implementing this new, modified design? The new design may have a different ethical status, cost, and scientific value and thus sometimes it may not be worth continuing given the new reality. Redesign and diagnosis help navigate these two decisions.</p>
<p><span class="math inline">\(\rightarrow\)</span> Section <code>X</code> describes “design reconciliation” and useful ways to compare designs as planned and designs as executed.</p>
</div>
<div id="design-to-share" class="section level2">
<h2>
<span class="header-section-number">3.12</span> Design to share<a class="anchor" aria-label="anchor" href="#design-to-share"><i class="fas fa-link"></i></a>
</h2>
<p>We emphasize design as a process to improve your work. But it is also a process for communicating your research, justifying your decisions, and contributing to the work of others. Formalizing design declaration makes this sharing easier. By coding up a design as an interrogable object that can be run, diagnosed, and redesigned, you let other researchers see, understand, and question the logic of your research. We urge you to keep this sharing function in mind as you write code, explore alternatives, and optimize over designs. A design that is hard coded to capture your final decisions might break when researchers try to modify parts. Alternatively designs can be created specifically to make it easier to explore neighboring designs, let others see why you chose the design you chose, and give them a leg up in their own work. In our ideal world, when you create a design you contribute it to a design library so others can check it out and build on your good work.</p>
<p><span class="math inline">\(\rightarrow\)</span> Section <code>X</code> describes how to prepare your design for the “integration” stage of a research life cycle.</p>

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
<!-- start post here, do not edit above -->
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="defining-research-designs.html"><span class="header-section-number">2</span> Defining research designs</a></div>
<div class="next"><a href="primer.html"><span class="header-section-number">4</span> Software primer</a></div>
</div></main><div id="on-this-page-nav" class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#research-design-principles"><span class="header-section-number">3</span> Research design principles</a></li>
<li><a class="nav-link" href="#design-early"><span class="header-section-number">3.1</span> Design early</a></li>
<li><a class="nav-link" href="#select-answerable-inquiries"><span class="header-section-number">3.2</span> Select answerable inquiries</a></li>
<li><a class="nav-link" href="#render-inquiries-insensitive-to-models"><span class="header-section-number">3.3</span> Render inquiries insensitive to models</a></li>
<li><a class="nav-link" href="#seek-mi-da-parallelism"><span class="header-section-number">3.4</span> Seek M:I, D:A parallelism</a></li>
<li><a class="nav-link" href="#make-m-large"><span class="header-section-number">3.5</span> Make M large</a></li>
<li><a class="nav-link" href="#find-your-limits"><span class="header-section-number">3.6</span> Find your limits</a></li>
<li><a class="nav-link" href="#bake-in-implementation-failures"><span class="header-section-number">3.7</span> Bake in implementation failures</a></li>
<li><a class="nav-link" href="#specify-your-criteria-for-a-good-design"><span class="header-section-number">3.8</span> Specify your criteria for a good design</a></li>
<li><a class="nav-link" href="#evaluate-holistically"><span class="header-section-number">3.9</span> Evaluate holistically</a></li>
<li><a class="nav-link" href="#redesign-over-d-and-a"><span class="header-section-number">3.10</span> Redesign over D and A</a></li>
<li><a class="nav-link" href="#redesign-often"><span class="header-section-number">3.11</span> Redesign often</a></li>
<li><a class="nav-link" href="#design-to-share"><span class="header-section-number">3.12</span> Design to share</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="download-code" href="./research-design-principles.R"><i class="far fa-file-code"></i> Download R code</a></li>
          
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Research Design: Declare, Diagnose, Redesign</strong>" was written by Graeme Blair, Alexander Coppock, and Macartan Humphreys. </p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
