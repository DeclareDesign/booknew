---
title: "Software primer"
output:
  html_document:
    number_sections: yes
  pdf_document: default
tables: yes
bibliography: ../bib/book.bib
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

# Software primer

<!-- make sure to rename the section title below -->

```{r software_primer, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```

In this section, we introduce you to `DeclareDesign` for R and describe how to use it to implement each step of the design-diagnose-redesign process.

## Installing R 

You can download the statistical computing environment R for free from [CRAN](https://cran.r-project.org). We also recommend the free program [RStudio](https://www.rstudio.com/products/rstudio/download), which provides a friendly interface to R.^[Both R and RStudio are available on Windows, Mac, and Linux.]

Once you have got RStudio installed, open it up and install `DeclareDesign` and its  related packages. These include three packages that enable specific steps in the research process (`fabricatr` for simulating social science data; `randomizr`, for random sampling and random assignment; and `estimatr` for design-based estimators). You can also install `DesignLibrary`, which gets standard designs up-and-running in one line. To install them, you can type:

```{r, eval = FALSE}
install.packages(c("DeclareDesign", "fabricatr", "randomizr", "estimatr", "DesignLibrary"))
```

We also recommend that you install and get to know the `tidyverse` suite of packages for data analysis, which we will use throughout the book:

```{r, eval = FALSE}
install.packages("tidyverse")
```

For introductions to R and the `tidyverse` we especially recommend the free resource [`R for Data Science`](https://r4ds.had.co.nz).

## Building a step of a research design 

A research design is a concatenation of steps so the best way to learn how to build a design is learn how to make a step. We will start out by making---or *declaring*---a step that implements random assignment. 

Almost all steps take a dataset as input and return a dataset as output. We will will imagine input data that describes a set of voters in Los Angeles. The research project we are planning involves randomly assigning voters to receive (or not receive) a knock on their door from a canvasser. Our data look like this:

```{r, echo = FALSE}
voter_file <- fabricate(
  N = 100,
  age = sample(18:80, N, replace = TRUE),
  sex = sample(c("F", "M"), N, replace = TRUE),
  party = sample(c("DEM", "REP", "GRN"), N, replace = TRUE),
  precinct = sample(2000:10000, N, replace = TRUE)
)
```

```{r voterfile, echo = FALSE}
kable(head(voter_file), digits = 3, caption = "Example data")
```

There are `r nrow(voter_file)` voters in the dataset. 

We want a function that takes this dataset, implements a random assignment, adds it to the dataset, and then returns the new dataset containing the random assignment.

You could write your own function to do that but you can also use one of the `declare_*` functions in `DeclareDesign` that are designed to write functions.  Each one of these functions is a kind of *function factory*: it takes a set of parameters about your research design like the number of units and the random assignment probability as *inputs*, and returns a *function* as an output. 

For generating assignment functions we can use  `declare_assignment` like this: 

```{r}
simple_random_assignment_step <- declare_assignment(prob = 0.6)
```

The big idea to understand here is that the object we created, `simple_random_assignment_step`, is not a particular assignment, it is a *function* that creates an assignment. In particular it is a tidy function that summarizes how your design does assignment. You can run the function on data:

```{r, eval = FALSE}
simple_random_assignment_step(voter_file) 
```
```{r voterfilera, echo = FALSE}
simple_random_assignment_step(voter_file) %>% head %>% kable(caption = "Data output following implementation of an assignment step.", digits = 3)
```

The output here is an expanded dataset with a new column indicating treatment assignment (`Z`). As a bonus the data also includes the implied assignment propensity for each unit *to the condition in which it is in* (`Z_cond`). The most important thing to understand here is that implementing a step means taking a dataset in and sending a new dataset out.  

A few parts of this step declaration may seem a little bit odd. First, we did not tell R anything about the number of units in our dataset. Second, we did not give it the data. This is because a step declaration creates functions that are meant to be flexible, function that will work on any size dataset. We told `declare_assignment` that we want to assign treatment with probability `0.6` (and implicitly control with probability `1-0.6 = 0.4`), regardless of how large the dataset is. We did not send the declaration the data because, although the assignment is a function of the data, the assignment *function* is not a function of the data. Put differently, the assignment function takes data as an argument, but the function to create the assignment function (`declare_assignment()`) does not. 

When you implement your research design after you have conducted it, you can use the exact same functions you generated in this design phase. In the same way when you *diagnose* your design you will use the same function many times. This is one of the reasons we *declare* the assignment step --- because we will learn about the properties of your design with the same code you can actually use to randomly assign treatment.

Every step of a research design in MIDA can be written using one of the `declare_*` functions. In the next section, we walk through each step and how to declare it using `DeclareDesign`. 

### Options and defaults

Most of the `declare_*` functions have many options. In general you do not have to specify these as default values are usually provided (though you should be familiar with what these default values are). For instance you might have noticed above that when you ran the assignment step above, the new variable that was created was called `Z`. This is because `declare_assignment` has an argument  `assignment_variable` that defaults to `Z`. You can change that of course to whatever you want.

More subtly, the `declare_*` functions also default to "handlers" which have their own default arguments. These handlers are generally quite well developed sets of functions that implement the tasks needed by the `declare_` function. For instance `declare_assignment` defaults to `conduct_ra` from the `randomizr` package as a handler and passes  any additional arguments that you give it on to `conduct_ra`, and, by the same token, assumes by default the default values of the handler. In the example above we had `prob = 0.6` as an argument. If you look at the documentation, `prob` is not an argument of `declare_assignment` but it is an argument of `conduct_ra`, with a default value of .5. If we had left this bit out we would have gotten a function that assigned treatment with probability .5. 

### Your own handlers

The built in functions we provide in the `DeclareDesign` package are quite flexible and handle many major designs but the framework is built so that you are never constrained by what we provide. At any point rather than using the default handlers (such as `conduct_ra`), you can write a function that implements your own procedures. The only discipline that the framework imposes is that you write your procedure as a function that takes data in and send data back.  

Here is an example of how you turn your own functions into design steps.


```{r, eval = FALSE}
custom_assignment <- function(data)
  mutate(data, X = rbinom(n = nrow(data), 1, prob = 0.5))

my_assignment_step <- declare_assignment(handler = custom_assignment)

my_assignment_step(voter_file)  
```

```{r voterfilecustomfunction, echo = FALSE}
custom_assignment <- function(data)
  mutate(data, X = rbinom(n = nrow(data), 1, prob = 0.5))
 
my_assignment_step <- declare_assignment(handler = custom_assignment)

my_assignment_step(voter_file) %>% head %>% kable(caption = "Data generated using a custom function")  
```

There is, of course, no great difference in this example between `custom_assignment` and `my_assignment_step` since `my_assignment_step` is just a function that applies  `custom_assignment`. Even still, it is worth declaring this step formally as a design step using `declare_assignment` since this lets `DeclareDesign` know how the step fits into the whole design, how to interpret it, and when to call it.   

## Research design steps

In this section, we walk through how to declare each step of a research design using `DeclareDesign`. In the next section, we build those steps into a research design, and then describe how to interrogate the design.

### Model

The model defines the structure of the world, both its size and background characteristics as well as how interventions in the world determine outcomes. In `DeclareDesign`, we split the model into two main design steps: the population and potential outcomes steps. There 

<!-- is always one population in a design, but there can be multiple sets of potential outcomes. -->

<!-- ALWAYS ONE POPULATION -- OR ARE WE DESCRIBING SETS -->

#### Population

The population defines the number of units in the population, any multilevel structure to the data, and its background characteristics. We can define the population in several ways. 

In some cases, you may start a design with data on the population. When that happens, we do not to simulate it. We can simply declare the data as our population:

```{r, eval = FALSE}
declare_population(data = voter_file)
```
```{r voterfilepopulation, echo = FALSE}
declare_population(data = voter_file)() %>% head %>% kable(digits = 3, caption = "Draw from a fixed population")
```

When we do not have complete data on the population, we simulate it. Relying on the data simulation functions from our `fabricatr` package, `declare_population` asks about the size and variables of the population. For instance if we want a function that generates a dataset with 100 units and a random variable `u` we write:

```{r, eval = FALSE}
declare_population(N = 100, u = rnorm(N))
```

When we run this population function, we will get a different 100-unit dataset each time:

```{r threepopulationdraws, echo = FALSE}
tab1 <- declare_population(N = 100, u = rnorm(N))() %>% head
tab2 <- declare_population(N = 100, u = rnorm(N))() %>% head
tab3 <- declare_population(N = 100, u = rnorm(N))() %>% head
kable(list(tab1, tab2, tab3), booktabs = TRUE, digits = 3, caption = "Three draws from the population function.")
```

The `fabricatr` package can simulate many different typs of data, including various types of categorical variables or different types of data structures, such as panel or multilevel strucures. 

You can read the `fabricatr` [website](https://declaredesign.org/r/fabricatr/) to get started simulating your data structure. 

As an exmaple of a simple two-level data structure, we imagine a setting with 100 households and random number of individuals within each household. This two level structure could be declared as:

```{r, eval = FALSE}
declare_population(
  households = add_level(N = 100, individuals_per_hh = sample(1:10, N, replace = TRUE)),
  individuals = add_level(N = individuals_per_hh, age = sample(1:100, N, replace = TRUE))
)
```

Remember, in every step of the research design process, you can short-circuit our default way of doing things and bring in your own code. This is useful when you have a complex design, or when you have already written code for your design and you want to use it directly. It works by setting the handler:

```{r, eval = FALSE}
complex_population_function <- function(data, N_units) {
  data.frame(u = rnorm(N_units))
}

declare_population(handler = complex_population_function, N_units = 100)
```

#### Potential outcomes

Defining potential outcomes is as easy as a single expression per potential outcome. These may be a function of background characteristics, other potential outcomes, or other R functions.^[Typically, we think of potential outcomes as fixed and not random, and move random variables to the population.]

```{r, eval = FALSE}
declare_potential_outcomes(
  Y_Z_0 = u, 
  Y_Z_1 = Y_Z_0 + 0.25)
```

```{r, eval = FALSE}
des <- declare_population(N = 100, u = rnorm(N)) +
  declare_potential_outcomes(Y_Z_0 = u, Y_Z_1 = Y_Z_0 + 0.25)

draw_data(des)
```
```{r potentialoutcomesdraw, echo = FALSE}
des <- declare_population(N = 100, u = rnorm(N)) +
  declare_potential_outcomes(Y_Z_0 = u, Y_Z_1 = Y_Z_0 + 0.25)

draw_data(des) %>% head %>% kable(digits = 3, caption = "Adding potential outcomes to the population.")
```

We also have a simpler interface to define all the potential outcomes at once as a function of a treatment assignment variable. The names of the potential outcomes are constructed from the outcome name (here `Y` on the lefthand side of the formula) and from the `assignment_variables` argument (here `Z`). 

```{r, eval = FALSE}
declare_potential_outcomes(Y ~ u + 0.25 * Z, assignment_variables = Z)
```

Either way of creating potential outcomes works; one may be easier or harder to code up in a given research design setting.

### Inquiry

To define your inquiry, declare your estimand, which is a function of background characteristics from your population, potential outcomes, or both. We define the average treatment effect for the experiment in our simple design as follows:

```{r, eval = FALSE}
declare_estimand(PATE = mean(Y_Z_1 - Y_Z_0))
```

Notice that we defined the PATE (the *population* average treatment effect), but said nothing special related to the population. In fact, it looks like we just defined the average treatment effect. This is because where you define the estimand in your design is going to determine whether it refers to the population, sample, or other form of estimand. We will see how to do this in a moment.

### Data strategy

The data strategy constitutes one or more steps representing interventions the researcher makes in the world from sampling to assignment to measurement. Typically, this may include sampling and assignment.

#### Sampling

The sampling step relies on the `randomizr` package to conduct random sampling. See Section \@ref(p2sampling) for an overview of the many kinds of sampling that are possible. We define a simple 50-unit sample from the population as follows:

```{r, eval = FALSE}
declare_sampling(n = 50)
```

When we draw data from our simple design at this point, it will be smaller: from 100 units in the population to a data frame of 50 units representing the sample. In the data frame, we have an inclusion probability, the probability of being included in the sample. `randomizr` includes this by default. In this case, every unit in the population had an equal 0.5 probability of inclusion.

```{r sampleddatadraw, echo = FALSE}
simple_design <- 
  declare_population(N = 100, u = rnorm(N)) +
  declare_potential_outcomes(Y_Z_0 = u, Y_Z_1 = Y_Z_0 + 0.25) +
  declare_estimand(PATE = mean(Y_Z_1 - Y_Z_0)) +
  declare_sampling(n = 50) 

draw_data(simple_design) %>% head %>% kable(digits = 3, caption = "Sampled data.")
```

Sampling could also be non-random, which could be accomplished by using a handler. 

#### Assignment

Assignment also relies, by default, on the `randomizr` package for random assignment. Here, we define assignment as a 50% probability of assignment to treatment and 50% to control.

```{r, eval = FALSE}
declare_assignment(prob = 0.5)
```

Assignment results in a data frame with an additional indicator `Z` of the assignment as well as the probability of assignment. Again, here the assignment probabilities are constant, but in other designs described in Section \@ref(p2assignment) they are not and this is crucial information for the analysis stage.

```{r simpledesignassignment, echo = FALSE}
simple_design <- 
  declare_population(N = 100, u = rnorm(N)) +
  declare_potential_outcomes(Y_Z_0 = u, Y_Z_1 = Y_Z_0 + 0.25) +
  declare_estimand(PATE = mean(Y_Z_1 - Y_Z_0)) +
  declare_sampling(n = 50) +
  declare_assignment(prob = 0.5)

draw_data(simple_design) %>% head %>% kable(digits = 3, caption = "Sampled data with assignment indicator.")
```

#### Other data strategies

Random sampling and random assignment are not the only kinds of data strategies. Others may include merging in fixed administrative data from other sources, collapsing data across months or days, and other operations. You can include these as steps in your design too, using `declare_step`. Here, you must define a handler, as we did for using a custom function in `declare_population`. Some handlers that may prove useful are the `dplyr` verbs such as `mutate` and `summarize`, and the `fabricate` function from our `fabricatr` package.

To add a variable using fabricate:

```{r, eval = FALSE}
declare_step(handler = fabricate, add_variable = rnorm(N))
```

If you have district-month data you may want to analyze at the district level, collapsing across months:^[The `{{ }}` syntax is handy for writing functions in `dplyr` where you want to be able reuse the function with different variable names. Here, the `collapse_data` function will `group_by` the variable you send to the argument `collapse_by`, which in our declaration we set to `district`. The pipeline within the function then calculates the mean in each district.]

```{r, eval = FALSE}
collapse_data <- function(data, collapse_by) {
  data %>% group_by({{ collapse_by }}) %>% summarize_all(mean, na.rm = TRUE)
}

declare_step(handler = collapse_data, collapse_by = district)
```

### Answer strategy

Through our model and data strategy steps, we have simulated a dataset with two key inputs to the answer strategy: an assignment variable and an outcome. In other answer strategies, pretreatment characteristics from the model might also be relevant. The data look like this:

```{r simpledesignrevealedoutcomes, echo = FALSE}
simple_design <- 
  declare_population(N = 100, u = rnorm(N)) +
  declare_potential_outcomes(Y_Z_0 = u, Y_Z_1 = Y_Z_0 + 0.25) +
  declare_estimand(PATE = mean(Y_Z_1 - Y_Z_0)) +
  declare_sampling(n = 50) +
  declare_assignment(prob = 0.5) +
  declare_reveal(outcome_variables = Y, assignment_variables = Z) +
  declare_estimator(Y ~ Z, model = difference_in_means, estimand = "PATE")
simple_design_data <- draw_data(simple_design)
simple_design_data %>% head %>% kable(digits = 3, caption = "Data with revealed outcomes.")
```

Our estimator is the difference-in-means estimator, which compares outcomes between the group that was assigned to treatment and that assigned to control. The `estimatr` package makes this easy and calculates the design-based standard error and a p-value and confidence interval for you:

```{r, eval = FALSE}
difference_in_means(Y ~ Z, data = simple_design_data)
```
```{r simpledesigndimestimate, echo = FALSE}
difference_in_means(Y ~ Z, data = simple_design_data) %>% tidy %>% kable(digits = 3, caption = "Difference-in-means estimate from simulated data.")
```

Now, in order to *declare* our estimator, we can send the name of a model to `declare_estimator`. R has many models that work with `declare_estimator`, including `lm`, `glm`, the `ictreg` package from the `list` package, etc. The design-based estimators from `estimatr` can all be used. 

```{r, eval = FALSE}
declare_estimator(Y ~ Z, model = difference_in_means, estimand = "PATE")
```

In this declaration, we also define the estimand we are targeting with the difference-in-means estimator.^[Sometimes, you may be interested just in the properties of an estimator, such as calculating its power. In this case, you need not define an estimand.] Typically, you will have an estimand that you are targeting, and sometimes you may consider targeting more than one and assessing how good your estimator estimates them. For example, you may want to know how good a job your instrumental variables job is at targeting the complier average causal effect, but also how close it gets on average to the average treatment effect. 

## Building a design from design steps

In the last section, we defined a set of individual research steps. We draw one version of them together here:

```{r}
population <- declare_population(N = 100, u = rnorm(N)) 
potential_outcomes <- declare_potential_outcomes(Y_Z_0 = u, Y_Z_1 = Y_Z_0 + 0.25) 
estimand <- declare_estimand(PATE = mean(Y_Z_1 - Y_Z_0)) 
sampling <- declare_sampling(n = 50) 
assignment <- declare_assignment(prob = 0.5) 
reveal <- declare_reveal(outcome_variables = Y, assignment_variables = Z) 
estimator <- declare_estimator(Y ~ Z, model = difference_in_means, estimand = "PATE")
```

To construct a research design *object* that we can operate on --- diagnose it, redesign it, draw data from it, etc. --- we add them together with the `+` operator. The `+` creates a design object. 

```{r}
simple_design <- 
  population + potential_outcomes + estimand + sampling + assignment + reveal + estimator
```

In the book, we'll use a more compact way of writing a design, where we define it all at once with the `+`:

```{r}
simple_design <- 
  declare_population(N = 100, u = rnorm(N)) +
  declare_potential_outcomes(Y_Z_0 = u, Y_Z_1 = Y_Z_0 + 0.25) +
  declare_estimand(PATE = mean(Y_Z_1 - Y_Z_0)) +
  declare_sampling(n = 50) +
  declare_assignment(prob = 0.5) +
  declare_reveal(outcome_variables = Y, assignment_variables = Z) +
  declare_estimator(Y ~ Z, model = difference_in_means, estimand = "PATE")
```

### Order matters

When defining a design, the order steps are included in the design via the `+` operator matters. Think of the order of your design as the causal order in which steps take place. 
```{r, eval = FALSE}
population + potential_outcomes + estimand + sampling + assignment + reveal + estimator
```

The order encodes several important aspects of the design:
- First, the fact that the estimand follows the potential outcomes and comes before sampling and assignment means it is a *population* estimand, the population average treatment effect. This is because it is calculated on the data created *so far*. 
- The estimator comes after the assignment and reveal outcomes steps. If it didn't, our difference-in-means would not work, because it wouldn't have access to the treatment variable and the realized outcomes.

## Simulating a research design

Diagnosing a research design --- learning about its properties --- requires first simulating running the design over and over. We need to simulate the data generating process, then calculate the estimands, then calculate the estimates that will result. 

With simple design defined as an object, we can easily learn about what kind of data it generates, the values of its estimand and estimates, and other features with simple funtions in `DeclareDesign`. They chain together functions in a similar way to a `dplyr` or `ggplot` pipeline.

To draw simulated data based on the design, we use `draw_data`:

```{r, eval = FALSE}
draw_data(simple_design)
```
```{r simpledesigndatadraw, echo = FALSE}
draw_data(simple_design) %>% head %>% kable(digits = 3, caption = "Simulated data draw.")
```

`draw_data` runs all of the "data steps" in a design, which are both from the model (population and potential outcomes) and from the data strategy (typically sampling and assignment).

To simulate the estimands from a single run of the design, we use `draw_estimands`. This runs two operations at once: it draws the data, and calculates the estimands at the point defined by the design. For example, in our design the estimand comes just after the potential outcomes. In this design, `draw_estimands` will run the first two steps and then calculate the estimands from the `estimand` function we declared:

```{r, eval = FALSE}
draw_estimands(simple_design)
```
```{r simpledesignestimanddraw, echo = FALSE}
draw_estimands(simple_design) %>% kable(digits = 3, caption = "Estimands calculated from simulated data.")
```

Similarly, we can draw the estimates from a single run with `draw_estimates` which simulates data and at the appropriate moment calculates estimates.

```{r, eval = FALSE}
draw_estimates(simple_design)
```
```{r simpledesignestimatedraw, echo = FALSE}
draw_estimates(simple_design) %>% kable(digits = 3, caption = "Estimates calculated from simulated data.")
```

To diagnose a design, we want a data frame that includes the estimates *and* estimands from many runs of a design. That is, we want to run the design, draw estimates and estimands, and then do that over and over and stack the results. This is exactly what `simulate_design` does:

```{r, eval = FALSE}
simulate_design(simple_design, sims = 500)
```
```{r simpledesignsimulationsdf, echo = FALSE}
simulations_df <- simulate_design(simple_design, sims = 5) 

simulations_df %>% kable(digits = 3, caption = "Simulations data frame.")
```

## Diagnosing a research design

The simulations data frame we created allows us to diagnose the design (calculate summary statistics from the simulations) directly. We can now calculate the bias, root mean-squared error, and power for each estimator-estimand pair. In `DeclareDesign`, we do this in two steps. First, declare your diagnosands. These are functions of the simulations data. We have precoded several standard diagnosands (see Section \@ref(p2diagnosis)).

```{r}
study_diagnosands <- declare_diagnosands(
  select = c(bias, rmse, power), 
  mse = mean((estimate - estimand)^2))
```

Next, take your simulations data and the diagnosands, and diagnose. This runs a single operation, which is to calculate the diagnosands on your simulations data.

```{r, eval = FALSE}
diagnose_design(simulations_df, diagnosands = study_diagnosands)
```
```{r simpledesigndiagnosis2, echo = FALSE}
diagnose_design(simulations_df, diagnosands = study_diagnosands) %>% get_diagnosands %>% kable(digits = 3, caption = "Design diagnosis.")
```

We can also do this in a single step. When you send `diagnose_design` a design object, it will first run the simulations for you, then calculate the diagnosands from the simulations data frame that results.

```{r, eval = FALSE}
diagnose_design(simple_design, diagnosands = study_diagnosands)
```

## Comparing designs

In the diagnosis phase, you will often want to compare the properties of two designs to see which you prefer on the basis of the diagnosand values. We have two ways to compare. First, we can compare the designs themselves --- what kinds of estimates and estimands do they produce, what steps are in the design. And we can compare the diagnoses.

```{r, eval = FALSE}
compare_designs(simple_design, redesigned_simple_design)
```

To compare the diagnoses, we run a diagnosis for each one and then calculate the difference between each diagnosand for the two designs and conduct a statistical test of the null effect of no difference.

```{r, eval = FALSE}
compare_diagnoses(simple_design, redesigned_simple_design)
```
```{r simpledesigncomparison, echo = FALSE, eval = FALSE}
compare_diagnoses(simple_design, redesigned_simple_design, sims = sims)$compared_diagnoses_df %>% kable(digits = 3, caption = "Comparison of two designs.")
```

### Comparing many variants of a design

In the diagnosis phase, you will often want to compare the properties of two designs to see which you prefer on the basis of the diagnosand values. We have two ways to compare. First, we can compare the designs themselves --- what kinds of estimates and estimands do they produce, what steps are in the design. And we can compare the diagnoses. We can do this using `redesign`:

```{r, eval = FALSE}
redesign(simple_design, N = c(100, 200, 300, 400, 500))
```

An alternative way to do this is to write a function that makes designs based on a set of these design inputs. This offers the researcher more flexibility in setting up the design variants. We call these functions *designers*. Here's a simple designer based on our running example:

```{r}
simple_designer <- function(sample_size, effect_size) {
  declare_population(N = sample_size, u = rnorm(N)) +
    declare_potential_outcomes(Y_Z_0 = u, Y_Z_1 = Y_Z_0 + effect_size) +
    declare_estimand(PATE = mean(Y_Z_1 - Y_Z_0)) +
    declare_sampling(n = 50) +
    declare_assignment(prob = 0.5) +
    declare_reveal(outcome_variables = Y, assignment_variables = Z) +
    declare_estimator(Y ~ Z, model = difference_in_means, estimand = "PATE")
}
```

To create a single design, based on our original parameters of a 100-unit sample size and a treatment effect of `0.25`, we can run:

```{r}
simple_design <- simple_designer(sample_size = 100, effect_size = 0.25)
```

Now to simulate multiple designs, we can use the `DeclareDesign` function `expand_design`. Here we examine our simple design under several possible sample sizes, which we might want to do to conduct a minimum power analysis. We hold the effect size constant.

```{r, eval = FALSE}
simple_designs <- expand_design(simple_designer, sample_size = c(100, 500, 1000), effect_size = 0.25)
```

Our simulation and diagnosis tools can take a set of expanded designs (an R list) and will simulate all of them at once, creating a column called `design_label` to keep them apart. For example:

```{r, eval = FALSE}
diagnose_design(simple_designs)
```

### Library of designs

In our `DesignLibrary` package, we have created a set of common designs as designers, so you can get started quickly and also easily set up a range of design variants for comparison. 

```{r, eval = FALSE}
library(DesignLibrary)

b_c_design <- block_cluster_two_arm_designer(N = 1000, N_blocks = 10)

diagnose_design(b_c_design)
```

