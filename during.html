<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 22 During | Research Design: Declare, Diagnose, Redesign</title>
<meta name="author" content="Graeme Blair, Alexander Coppock, and Macartan Humphreys">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.2.9002/tabs.js"></script><script src="libs/bs3compat-0.2.2.9002/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<link href="libs/bs4_book-1.0.0/dd_imgpopup.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/bs4_book-1.0.0/dd_imgpopup.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://hypothes.is/embed.js" async></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Research Design: Declare, Diagnose, Redesign</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li class="book-part">Introduction</li>
<li><a class="" href="preamble.html"><span class="header-section-number">1</span> Preamble</a></li>
<li><a class="" href="improving-research-designs.html"><span class="header-section-number">2</span> Improving research designs</a></li>
<li><a class="" href="primer.html"><span class="header-section-number">3</span> Software primer</a></li>
<li><a class="" href="part-i-exercises.html"><span class="header-section-number">4</span> Part I Exercises</a></li>
<li class="book-part">Declaration, Diagnosis, Redesign</li>
<li><a class="" href="declaration.html"><span class="header-section-number">5</span> Declaration</a></li>
<li><a class="" href="specifying-the-model.html"><span class="header-section-number">6</span> Specifying the model</a></li>
<li><a class="" href="defining-the-inquiry.html"><span class="header-section-number">7</span> Defining the inquiry</a></li>
<li><a class="" href="crafting-a-data-strategy.html"><span class="header-section-number">8</span> Crafting a data strategy</a></li>
<li><a class="" href="choosing-an-answer-strategy.html"><span class="header-section-number">9</span> Choosing an answer strategy</a></li>
<li><a class="" href="p2diagnosis.html"><span class="header-section-number">10</span> Diagnosis</a></li>
<li><a class="" href="redesign-2.html"><span class="header-section-number">11</span> Redesign</a></li>
<li><a class="" href="part-ii-exercises.html"><span class="header-section-number">12</span> Part II Exercises</a></li>
<li class="book-part">Research Design Library</li>
<li><a class="" href="research-design-library.html"><span class="header-section-number">13</span> Research Design Library</a></li>
<li><a class="" href="observational-designs-for-descriptive-inference.html"><span class="header-section-number">14</span> Observational designs for descriptive inference</a></li>
<li><a class="" href="experimental-designs-for-descriptive-inference.html"><span class="header-section-number">15</span> Experimental designs for descriptive inference</a></li>
<li><a class="" href="observational-designs-for-causal-inference.html"><span class="header-section-number">16</span> Observational designs for causal inference</a></li>
<li><a class="" href="experimental-designs-for-causal-inference.html"><span class="header-section-number">17</span> Experimental designs for causal inference</a></li>
<li><a class="" href="multi-study-designs.html"><span class="header-section-number">18</span> Multi-study designs</a></li>
<li><a class="" href="part-iii-exercises.html"><span class="header-section-number">19</span> Part III Exercises</a></li>
<li class="book-part">Research Design Lifecycle</li>
<li><a class="" href="research-design-lifecycle.html"><span class="header-section-number">20</span> Research Design Lifecycle</a></li>
<li><a class="" href="before.html"><span class="header-section-number">21</span> Before</a></li>
<li><a class="active" href="during.html"><span class="header-section-number">22</span> During</a></li>
<li><a class="" href="after.html"><span class="header-section-number">23</span> After</a></li>
<li><a class="" href="part-iv-exercises.html"><span class="header-section-number">24</span> Part IV Exercises</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="during" class="section level1">
<h1>
<span class="header-section-number">22</span> During<a class="anchor" aria-label="anchor" href="#during"><i class="fas fa-link"></i></a>
</h1>
<div id="p4piloting" class="section level2">
<h2>
<span class="header-section-number">22.1</span> Piloting<a class="anchor" aria-label="anchor" href="#p4piloting"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<!-- -- can't learn causal effect -->
<!-- -- what can you learn? about Y0, about M, about se -->
<!-- -- bring in blog post -->
<p>The designs and results of past studies are important guides for selecting M, I, D, and A. Our understanding of the nodes and edges in the causal graph of M, expected effect sizes, the distribution of outcomes, feasible randomization schemes, and many other features are directly selected from past research or chosen based on a literature review of the distribution over past studies. However, researchers face a problem in being guided by past research: the research context and our inquiries often differ in at least subtle ways from any past study. Even when we are replicating a past study, we are collecting data in a different time period and if effects vary over time then aspects of M may differ from the original study. To deal with this, we often run pilot studies. These take many forms: focus groups to learn about features of M or to learn how to ask survey questions; small-scale tests of measurement tools to verify our data collection technology works; up to mini studies with the planned design but on a smaller scale.</p>
<p>Pilot studies are constrained by our time and by money. If we were not constrained, we would run the full study and learn what is wrong with our design and then run a corrected design for the main study. Since we cannot due to our constraints, we run either smaller mini studies or test out only a subset of the elements of our planned design. This places us in a bind: we are running a design smaller or less complete than the study we imagine conducting, and so the properties of the pilot design will not measure up.</p>
<p>MIDA provides a framework for thinking about what can be learned from a pilot through research design diagnosis. Just like for a full study, we can define inquiries about the decisions we would make and the parameter estimates we would draw on in designing the full study.</p>
<p>In Figure <a href="during.html#fig:pilotingfig">22.1</a>, we display the results of a diagnosis of a 50-unit pilot study that we are conducting to prepare for a larger main study. We consider two strategies: (1) determining the sample size from a power analysis of the main study, selecting the minimum <span class="math inline">\(N\)</span> such that the study is 80% powered to detect the pilot study’s effect size); (2) setting a fixed <span class="math inline">\(N\)</span> determined by our budget constraint, in this case to 500, and using the standard deviation of units in the treated and control group from the pilot to determine the minimum detectable effect size of our 500-unit main study.</p>
<p>In the left panel is the sampling distribution of effect size estimates, i.e., a histogram of the effect estimates from the pilot. In the design, the standard deviation of the outcome is set to one, so effect estimates are in standard deviation units. The true effect size is set to 0.2. We can see that the sampling distribution has a huge range, from nearly -0.5 to nearly 0.75. The first problem with the sampling distribution is that many estimates, in fact nearly a quarter of them, are negative (the wrong sign!). This might lead us not only to choose the wrong sample size but to choose one-sided tests in the wrong direction. The second is that we have a high likelihood of guessing the effect size is <em>much</em> higher than it really is. If we obtain one of the estimates over 0.75 or even over 0.5, we would choose an <span class="math inline">\(N\)</span> too small to detect the true effect size of 0.2. In short, our estimates of the effect size from our 50-person pilot study are simple too variable to be useful in designing our main study.</p>
<p>However, there is good news: we can learn a lot about the power of our main study from the pilot study, just not from the effect estimates. In the right panel of Figure <a href="during.html#fig:pilotingfig">22.1</a>, we estimate the minimum detectable effect size of a 500-unit main study, relying on the estimated standard deviation in the control group and the estimated standard deviation in the treatment group to calculate the estimated standard error of the effect estimate in the main study. We then calculate the minimum detectable effect size using the approximation from <span class="citation">Gelman and Hill (<a href="references.html#ref-gelman2006data" role="doc-biblioref">2006</a>)</span>: 2.8 times the estimated standard error (pg. 441). We find that our estimates of the MDE for the full study are much more precise, tightly centered around 0.25. Since we don’t know if that is larger or smaller than the true effect size, we then must make an argument based on past studies’ effect sizes to justify whether that minimum size is sufficiently large or whether we should increase the sample size in order to detect even smaller effects. The reason the MDE is more precisely estimated is that the standard deviation of the control group is a much less variable estimate of the true standard deviation of the control potential outcome than the effect size estimate is of the true effect size.</p>
<div class="figure">
<span id="fig:pilotingfig"></span>
<img src="book_files/figure-html/pilotingfig-1.svg" alt="Learning from pilot studies." width="100%"><p class="caption">
Figure 22.1: Learning from pilot studies.
</p>
</div>
<p>By diagnosing our pilot studies in this way, we can learn what decisions can be made with confidence from pilot data and what should be shaped instead by expectations from past studies and qualitative knowledge. Diagnosis can also help us to decide how large a pilot study we need in order to estimate quantities like the MDE of the full study with precision.</p>
<p>Beyond estimating the MDE of studies, other facts that can often be usefully learned from pilot studies take the form of existence proofs. We often wish to study how variation in <span class="math inline">\(D\)</span> (a treatment) affects variation in <span class="math inline">\(Y\)</span> (an outcome), but in the absence of past data from these two variables we may not know even if there is variation in <span class="math inline">\(Y\)</span> to explain. In experimental studies, we can learn whether a treatment <em>can</em> be implemented, and in an observational study we can learn whether there is variation in the treatment variable.</p>
<p>Baseline measurement may often be used instead of a pilot study to learn about some empirical features. If our sample size is fixed and we are interested in learning whether some outcome measures vary across units or how they covary, we can measure them in the baseline and then make adjustments before a posttreatment survey. We will still control for our imperfect measures at baseline to improve efficiency.</p>
<!-- Diagnosing the pilot study on its own provides stark insights, which amount to: we cannot provide answers to the inquiry in the main study, and should not try to do so. There are also aspects of the logistics of research that within time and financial constraints we simply cannot learn until we run the main study. Science is imperfect, and also iterative, but these mistakes or suboptimal design choices also often lead to discoveries. -->
<!-- -- how does it help to diagnose the design together? the properties of the main study *change* when we do a pilot. This is because if we run the pilot study, we are doing so to make decisions about how to run the main study, and so our *design* of the main study and thus its results may depend on the *results* (and design) of the pilot study.  -->
<!-- In this section, we illustrate several general principles that flow from diagnosing pilot studies.  -->
<!-- Purposes of pilot studies: -->
<!-- Existence proofs: -->
<!-- -- is there variation in Y -->
<!-- -- is there variation in X -->
<!-- -- what are nodes in M -->
<!-- -- what are feasible D's, what are feasible treatments / can you implement the treatment (existence proof) -->
<!-- Harder questions requiring bigger sample sizes: -->
<!-- -- what is the distribution of X (helps select stratification proportions etc.) -->
<!-- -- what is the standard deviation of Y0 -->
<!-- #### Assessing a pilot design -->
<!-- declare pilot itself and diagnose just as if it were the main study -->
<!-- if you can't learn the answer, don't make any decisions based on it -->
<!-- #### Assessing a sequenced design -->
<!-- if you are making decisions about MIDA for main study based on pilot, diagnose the procedure of two studies, think about POs of pilot -->
<!-- #### Pilots and baselines -->
<!-- Designs can be reassessed after baselines and before treatment assignment -- so some of the questions you might do a pilot for can just be answered in a baseline -->
<!-- #### BLOG material -->
<!-- Data collection is expensive, and we often only get one bite at the apple. In response, we often conduct an inexpensive (and small) pilot test to help better design the study. Pilot studies have many virtues, including practicing the logistics of data collection and improving measurement tools. But using pilots to get noisy estimates in order to determine sample sizes for scale up comes with risks. -->
<!-- Pilot studies are often used to get a guess of the average effect size, which is then plugged into power calculators when designing the full study. -->
<!-- The procedure is: -->
<!-- 1. Conduct a small pilot study (say, N = 50) -->
<!-- 2. Obtain an estimate of the effect size (this is noisy, but better than nothing!) -->
<!-- 3. Conduct a power analysis for a larger study (say, N = 500) on the basis of the estimated effect size in the pilot -->
<!-- We show in this post that this procedure turns out to be dangerous: at common true effect sizes found in the social sciences, you are at risk of selecting an underpowered design based on the noisy effect estimate in your pilot study. -->
<!-- A different procedure has better properties: -->
<!-- 1. Conduct a small pilot study (say, N = 50) -->
<!-- 2. Obtain an estimate of the **standard deviation of the outcome variable** (again, this is a noisy estimate but better than nothing!) -->
<!-- 3. Estimate the minimum detectable effect (MDE) for a larger study (say, N = 500), using the estimated standard deviation -->
<!-- We show what happens in each procedure, using DeclareDesign. In each case, we'll think about a decision the researcher wants to make based on the pilot: should I move forward with my planned study, or should I go back to the drawing board? We'll rely on power to make that decision in the first procedure and the MDE in the second procedure. -->
<!-- [omitting code] -->
<!-- For each true effect size, the simulations will give us a distribution of estimated effects that a researcher might use as a basis for power analysis. For example, for a true effect size of 0 the researcher might still estimate an effect of 0.10, and so conduct their power analysis assuming that the true effect is 0.10. For each true effect, we can thus construct a distribution of *power estimates* a researcher might obtain from *estimated* effects. Since we know the true power for the true underlying effect, we can compare the distribution of post-hoc power estimates to the true power one would estimate if one knew the true effect size. -->
<!-- What did we find? In the plot, we show our guesses for the power of the main study based on our pilot effect size estimates.  -->
<!-- At high true effect sizes (top row), we do pretty well. Most of our guesses are above 80\% power, leading us to the correct decision that the study is powered. Indeed we often *underestimate* our power in these cases meaning that we run larger studies than we need to. -->
<!-- However, at low true effect sizes (bottom row) we show we are equally likely to find that the design is in fact powered as underpowered. We are equally likely to guess the power of the design is 90% as 10%. There is a good chance that we will falsely infer that our design is well powered just because we happened to get a high estimate from a noisy pilot. -->
<!-- ### How about estimating the standard deviation of the outcome? -->
<!-- Now, let's look at the second approach. Here, instead of using our pilot study to estimate the effect size for a power calculation, we estimate the **standard deviation of the outcome** and use this to calculate the main study's minimum detectable effect. The decision we want to make is: is this MDE small enough to be able to rule out substantively important effects? -->
<!-- We calculate the minimum detectable effect size using the approximation from [@gelman2006data, pg. 441], 2.8 times the estimated standard error. We estimate the standard error using Equation 3.6 from @gerber2012field.  -->
<!-- In summary, pilot studies can be valuable in planning research for many reasons, but power calculations based on noisy effect size estimates can be misleading. A better approach is to use the pilot to learn about the distribution of outcome variables. The variability of the outcome variable can then be plugged into MDE formulas or even power calculations with, say, the smallest effect size of political, economic, or social importance. -->
<!-- In the same spirit, pilot studies could also be used to learn the strength of the correlation between pre-treatment covariates and the outcome variable. With this knowledge in hand, researchers can develop their expectations about how much precision there is to be gained from covariate control or blocking. -->

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
<!-- start post here, do not edit above -->
</div>
<div id="implementation" class="section level2">
<h2>
<span class="header-section-number">22.2</span> Implementation<a class="anchor" aria-label="anchor" href="#implementation"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>Your design declaration is a road map for implementing your study. The data strategy tells you the procedure to use to sample units; how to assign treatments; and which variables to measure. Your answer strategy is the function that translates the realized data into a set of answers to your inquiries and statistics that communicate your confidence in those answers. If you have specified the data and answer strategies in sufficient detail in code, you can directly run the functions you declared to sample units and assign them to treatment and to analyze your data.</p>
<p>The road map is useful as a tool to learn where to go when things go right, but also to identify when you take a wrong turn and need to make decisions about how to get to an answer. In this sense, a design declaration should be a living document, updated to reflect the set of decisions you make along the way through the twists and turns of the research road. With the model of the world and an inquiry about it declared, when you are unable to collect a variable, treat a subset of units with treatment, or to reach some units for followup surveys, you can compare alternative ways of handling this deviation from your original plan on the same terms as you originally designed the experiment. These are all changes in your data strategy <span class="math inline">\(D\)</span>. You can assess options and also guide your decisionmaking about whether to continue your study at all or use the money for another better purpose. You can also use the comparison of diagnosands under alternative options as a tool to communicate with your research partners about why a change to their practices is needed. You can also use it to defend your intermediate data strategy choices when you are finished to reviewers and readers.</p>
<p>As you make changes to <span class="math inline">\(D\)</span>, changes in <span class="math inline">\(A\)</span> may also be required in order to follow the principle of analyzing as you sample, assign treatment, and measure. When you switch from an individual randomization to a cluster randomization because it is not logistically possible to individually assign units to treatment, you will typically want to adjust your answer strategy to account for clustering in the calculation of standard errors. By keeping both your data strategy and your answer strategy up to date as you implement your study, you may also identify new data that must be collected or new steps to take in order to still be able to provide credible answers.</p>
<p>You also learn more about your design as you go along, not because anything goes wrong but as a natural progression of the research. For example, you may not know how many units there are per cluster or per block, key details in assigning treatments and analyzing data from experiments. When you learn these details, change your data and answer strategies to reflect these new details — and diagnose the new design to be sure you still agree with your original choices. Beyond the data and answer strategies, you may also learn about new nodes or edges in the model during the course of research. When you learn about new confounders or mediators, update your model, but also consider whether changes to your data and answer strategy are necessitated to ensure you can answer your original inquiry.</p>
<p>In short, your design declaration is a living document that you can keep updated and use as a tool to guide you along the research path, not just as a document to write at the beginning of the study and revisit when you are writing up. This advice is in apparent tension with the idea of preanalysis plans, in which you precommit to your analysis choices before data is collected. It need not be. It is useful to keep your original design declaration and to preregister it, but it is also useful to keep the declaration updated as you make the changes along the way that inevitably happen. You will be in a better position to make good choices when things go awry, and also to communicate when and why you made changes to your design.</p>
<!-- outline: -->
<!-- -- use your MIDA to figure out how to implement -->
<!-- -- redesign as you go when you haven't gotten specific enough -->
<!-- -- consider the whole design -- ex ante declared, then changed -- and what *could have happened*, which may be known to you ex ante (there could or could not be attrition) or unknown (you learn during implementation that there are some kinds of units that won't comply, so you need to think not just about which ones did or did not comply but which ones *could* have). the whole process is a function of your interventions in the world (treatment or measurement), so write down the whole process and potential outcomes to understand what you can and cannot learn. -->
<!-- -- use your MIDA to help you *make* logistical choices, help it prevent you from making bad decisions and use as tool to communicate with partners and implementers about why you do or do not wnat to make different changes (or BETTER evaluate tradeoffs in those decisions) -->
<!-- idea bin: -->
<!-- -- MIDA is a roadmap for how to implement the study -->
<!-- -- when there is a part not specified, redesign to specify and diagnose again -->
<!-- -- lots of choices you make after you start, because it was not clear what decisions would have to be made ex ante: how to make these choices? (redesign and diagnose!).  -->
<!-- -- often randomization procedure will have to take into account specifities of the number of units (odd numbers), blocks with differing numbers of units, cluster of varying sizes, etc. that require revising D -->
<!-- -- unexpected constraints come in that affect D, and may require changes to D but also A. redesign. -->
<!-- -- how to make decisions about unexpected changes when things going wrong? (even if you don't have a PAP). often want to create multiple variants of the design incorporating what went wrong. common example: unexpected noncompliance or unexpectedly high rates of attrition. may want to change analysis plan, and register it, so can use redesign to develop that new plan. but also may discover diagnosands are not good enough, so may want to change data strategy midstream to mitigate these problems. -->
<!-- -- what to do when you run out of money or feasibility of sample size or other aspects of D becomes clear. redesign mountain subject to new cost constraints. -->
<!-- -- make go-no go decisions about whether to continue -->
<!-- -- how to know if your inquiry is no longer answerable -->
<!-- -- updating your PAP -->
<!-- -- assessing what you can learn based on the implementation challenges: these are potential outcomes, i.e. could be affected by treatment, so are often informative about what we can learn about the original research question -->
<!-- -- often need to convince partners to not change plans -- MIDA can be a tool for helping assess tradeoffs in learning and doing -->
<!-- -- Projects that succeed have direct researcher invovlement. Outsourcing too much of the design can lead to big troubles. -->
<p><strong>Related readings</strong>.</p>
<ul>
<li>Failure (<span class="citation">Karlan and Appel (<a href="references.html#ref-karlan2018failing" role="doc-biblioref">2018</a>)</span>)</li>
</ul>
<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book--><!-- start post here, do not edit above -->
</div>
<div id="p4populatedpap" class="section level2">
<h2>
<span class="header-section-number">22.3</span> Populated Preanalysis Plan<a class="anchor" aria-label="anchor" href="#p4populatedpap"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>Inevitably, authors of pre-analysis plans fail to anticipate how, eventually, the data generated by the study will be analyzed. Many of the reasons for the discrepancy were discussed in the previous section on implementation, but other reasons intervene as well. A common reason is that PAPs promise too many analyses – in the process of writing a paper, some analyses are dropped, others are combined, and still others are added during the writing and revision process. In the next section, we’ll describe how to reconcile analyses-as-planned with analyses-as-implemented, but this present section is about what to do with your analysis plan immediately after getting the data back.</p>
<p>We echo proposals made in <span class="citation">Banerjee et al. (<a href="references.html#ref-Banerjee2020" role="doc-biblioref">2020</a>)</span> and <span class="citation">Alrababa’h et al. (<a href="references.html#ref-alrababag_2020" role="doc-biblioref">2020</a>)</span> that researchers should produce short reports that fulfill the promises made in their PAPs. <span class="citation">Banerjee et al. (<a href="references.html#ref-Banerjee2020" role="doc-biblioref">2020</a>)</span> emphasize that writing PAPs is difficult and usually time constrained, so it is natural that the final paper will reflect further thinking about the full set of empirical approaches. A “populated PAP” serves simply to communicate the results of the promised analyses. <span class="citation">Alrababa’h et al. (<a href="references.html#ref-alrababag_2020" role="doc-biblioref">2020</a>)</span> cite the tendency of researchers to abandon publication of studies that return null results. In order to address the resulting publication bias, they recommend “null results reports” that share the results of the pre-registered analyses.</p>
<p>We recommend that authors include mock analyses in their PAPs using mock data. Doing so has the major benefit of being quite specific about the details of the answer strategy. A further benefit comes when it is time to produce a populated PAP, since the realized data can quite straightforwardly be swapped in for the mock data. Given the time invested in producing mock analyses for the PAP, writing up a populated PAP takes only as much effort as is needed to clean the data, which will need to be done in any case.</p>
<div id="example-18" class="section level3">
<h3>
<span class="header-section-number">22.3.1</span> Example<a class="anchor" aria-label="anchor" href="#example-18"><i class="fas fa-link"></i></a>
</h3>
<p>In Section <a href="before.html#p4planning">21.1</a>, we declared the design for <span class="citation">Bonilla and Tillery (<a href="references.html#ref-bonilla_tillery_2020" role="doc-biblioref">2020</a>)</span> following their preanalysis plan. In doing so, we declared an answer strategy in code. In our populated PAP, we can run that same answer strategy code, but swap out the simulated data for the real data collected during the study. We present first the regression table in Table <a href="#tab:bonilatillerypopulatedpapregressiontab"><strong>??</strong></a> and then the coefficient plot in Figure <a href="during.html#fig:bonilatillerypopulatedpapcoefplot">22.2</a>.</p>
<div class="inline-table"><table class="texreg" style="margin: 10px auto;border-collapse: collapse;border-spacing: 0px;caption-side: bottom;color: #000000;border-top: 2px solid #000000;">
<caption>
Statistical models
</caption>
<thead><tr>
<th style="padding-left: 5px;padding-right: 5px;">
 
</th>
<th style="padding-left: 5px;padding-right: 5px;">
Model 1
</th>
<th style="padding-left: 5px;padding-right: 5px;">
Model 2
</th>
<th style="padding-left: 5px;padding-right: 5px;">
Model 3
</th>
<th style="padding-left: 5px;padding-right: 5px;">
Model 4
</th>
</tr></thead>
<tbody>
<tr style="border-top: 1px solid #000000;">
<td style="padding-left: 5px;padding-right: 5px;">
(Intercept)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.84<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.41<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.61<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.54<sup>***</sup>
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.02)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.04)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.06)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.07)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Znationalism
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.01
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.00
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.02
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.09
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.02)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.02)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.08)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.09)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Zfeminism
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.04
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.01
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.01
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.02
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.02)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.02)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.08)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.09)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Zintersectional
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.04
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.03
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.08
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.01
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.02)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.02)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.08)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.10)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
female
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.03<sup>*</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.01)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
lgbtq
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.02
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.02)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
age
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.00
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.03)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
religiosity
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.01
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.02)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
income
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.00
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.03)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
college
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.02
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.02)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
linked_fate
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.27<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.30<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.03)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.07)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
blm_familiarity
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.07<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.10<sup>***</sup>
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.01)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.02)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Znationalism:linked_fate
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.04
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.09)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Zfeminism:linked_fate
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.05
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.09)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Zintersectional:linked_fate
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.05
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.09)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Znationalism:blm_familiarity
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.03
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.03)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Zfeminism:blm_familiarity
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.01
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.03)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Zintersectional:blm_familiarity
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.01
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.03)
</td>
</tr>
<tr style="border-top: 1px solid #000000;">
<td style="padding-left: 5px;padding-right: 5px;">
R<sup>2</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.00
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.20
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.14
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.09
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Adj. R<sup>2</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.00
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.19
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.13
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.09
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Num. obs.
</td>
<td style="padding-left: 5px;padding-right: 5px;">
849
</td>
<td style="padding-left: 5px;padding-right: 5px;">
849
</td>
<td style="padding-left: 5px;padding-right: 5px;">
849
</td>
<td style="padding-left: 5px;padding-right: 5px;">
849
</td>
</tr>
<tr style="border-bottom: 2px solid #000000;">
<td style="padding-left: 5px;padding-right: 5px;">
RMSE
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.23
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.20
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.21
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.22
</td>
</tr>
</tbody>
<tfoot><tr>
<td style="font-size: 0.8em;" colspan="5">
<sup><em><strong></strong></em></sup>p &lt; 0.001; <sup></sup>p &lt; 0.01; <sup></sup>p &lt; 0.05
</td>
</tr></tfoot>
</table></div>
<div class="figure">
<span id="fig:bonilatillerypopulatedpapcoefplot"></span>
<img src="book_files/figure-html/bonilatillerypopulatedpapcoefplot-1.svg" alt="Coefficient plot from Bonilla and Tillery design based on the study's realized data." width="100%"><p class="caption">
Figure 22.2: Coefficient plot from Bonilla and Tillery design based on the study’s realized data.
</p>
</div>

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
<!-- start post here, do not edit above -->
</div>
</div>
<div id="p4reconciliation" class="section level2">
<h2>
<span class="header-section-number">22.4</span> Reconciliation<a class="anchor" aria-label="anchor" href="#p4reconciliation"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>Inevitably, the research design as implemented will differ in some way from the research design as planned. Treatments cannot be implemented as conceived, some people cannot be found to interview, and sometimes what we learn from baseline measures informs how we measure later. An understanding of how your research design changed from conception to implementation is crucial to understanding what was learned from the design.</p>
<p>Suppose the original design described a three-arm trial: one control and two treatments, but the design as implemented drops all subjects assigned to the second treatment. Sometimes this is an entirely appropriate and reasonable design modification: perhaps it turns out that due to an implementation failure, the second treatment was simply not delivered. Other times, these modification is less benign – perhaps the estimate of the effect of the second treatment does not achieve statistical significance, so the author simply omits it from the analysis.</p>
<p>For this reason, explicitly <strong>reconciling</strong> the design as planned with the design as implemented should be the first step to writing up a paper. Having a publicly-posted preanalysis plan can make the reconciliation process especially credible – we know for sure what the planned design was because the preanalysis plan describes it pre-implementation. However, a preanalysis plan is not a prerequisite for engaging in reconciliation. The scientific enterprise is built in large measure on trust: we are ready to believe researchers who say, here is the design I though I would implement but due to unanticipated developments, here is the design I ended up implementing.</p>
<p>In some cases, reconciliation will lead to additional learning beyond what can be inferred from the final design itself. When some units could refused to be included in the study sample or some units refused measurement, we learn that important features about those units. Understanding sample exclusions, noncompliance, and attrition not only may inform future research design planning choices, but contribute substantively to our understanding of the social setting. A policy implemented in the same way the study would likely also not be able to work in the units who refused to participate, and future research could examine why or how to convince them of the policy’s benefits.</p>
<p>What belongs in a reconciliation? At a minimum, we need a full description of the planned design, a full description of the implemented design, and a list of the differences. This can be made explicit through the declaration of both design in computer code, then comparing the two design objects line-by-line.</p>
<p>In <code>DeclareDesign</code> we take the first steps of comparing designs for you:</p>
<div class="sourceCode" id="cb106"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">design1</span> <span class="op">&lt;-</span> <span class="fu">declare_population</span><span class="op">(</span>N <span class="op">=</span> <span class="fl">100</span>, U <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">declare_potential_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">Z</span> <span class="op">+</span> <span class="va">U</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">declare_estimand</span><span class="op">(</span>ATE <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">Y_Z_1</span> <span class="op">-</span> <span class="va">Y_Z_0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">declare_sampling</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">75</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">declare_assignment</span><span class="op">(</span>m <span class="op">=</span> <span class="fl">50</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">reveal_outcomes</span><span class="op">(</span><span class="va">Y</span>, <span class="va">Z</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">declare_estimator</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">Z</span>, estimand <span class="op">=</span> <span class="st">"ATE"</span><span class="op">)</span>

<span class="va">design2</span> <span class="op">&lt;-</span> <span class="fu">declare_population</span><span class="op">(</span>N <span class="op">=</span> <span class="fl">200</span>, U <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">declare_potential_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="fl">0.5</span><span class="op">*</span><span class="va">Z</span> <span class="op">+</span> <span class="va">U</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">declare_estimand</span><span class="op">(</span>ATE <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">Y_Z_1</span> <span class="op">-</span> <span class="va">Y_Z_0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">declare_sampling</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">declare_assignment</span><span class="op">(</span>m <span class="op">=</span> <span class="fl">25</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">reveal_outcomes</span><span class="op">(</span><span class="va">Y</span>, <span class="va">Z</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">declare_estimator</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">Z</span>, model <span class="op">=</span> <span class="va">lm_robust</span>, estimand <span class="op">=</span> <span class="st">"ATE"</span><span class="op">)</span>

<span class="fu">compare_designs</span><span class="op">(</span><span class="va">design1</span>, <span class="va">design2</span><span class="op">)</span>
<span class="fu">compare_design_code</span><span class="op">(</span><span class="va">design1</span>, <span class="va">design2</span><span class="op">)</span>
<span class="fu">compare_design_summaries</span><span class="op">(</span><span class="va">design1</span>, <span class="va">design2</span><span class="op">)</span>
<span class="fu">compare_design_data</span><span class="op">(</span><span class="va">design1</span>, <span class="va">design2</span><span class="op">)</span>
<span class="fu">compare_design_estimates</span><span class="op">(</span><span class="va">design1</span>, <span class="va">design2</span><span class="op">)</span>
<span class="fu">compare_design_estimands</span><span class="op">(</span><span class="va">design1</span>, <span class="va">design2</span><span class="op">)</span></code></pre></div>
<div id="example-19" class="section level3">
<h3>
<span class="header-section-number">22.4.1</span> Example<a class="anchor" aria-label="anchor" href="#example-19"><i class="fas fa-link"></i></a>
</h3>
<p>In Section <a href="before.html#p4planning">21.1</a>, we described the preanalysis plan registered by <span class="citation">Bonilla and Tillery (<a href="references.html#ref-bonilla_tillery_2020" role="doc-biblioref">2020</a>)</span>. We reconcile the set of conditional average treatment effect analyses planned in that PAP, the analyses reported in the paper, and those reported on in the appendix at the request of reviewers in Table <a href="during.html#tab:reconciliation">22.1</a>. In column two, we see that the authors planned four CATE estimates: effects by familiarity with Black Lives Matter; by gender; LGBT status; and linked fate. Only two of those are reported on in the paper, the others may have been excluded for space reasons. The two excluded analyses are not especially informative; they were not excluded on the basis of statistical significance. Another way to handle these uninteresting results would be to presented them in a populated PAP posted on their Web site or in the paper’s appendix.</p>
<p>In their appendix, the authors report on a set of analyses requested by reviewers. We see this as a perfect example of transparently presenting the set of planned analyses and highlighting the analyses that were added afterward and why they were added. They write:</p>
<blockquote>
<p>We have been asked to consider other pertinent moderations beyond gender and LGBTQ+ status. They are contained in the four following sections.</p>
</blockquote>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:reconciliation">Table 22.1: </span> Reconciliation of Bonilla and Tillery preanalysis plan.</caption>
<colgroup>
<col width="18%">
<col width="20%">
<col width="20%">
<col width="40%">
</colgroup>
<thead><tr class="header">
<th>Covariate</th>
<th>In the preanalysis plan</th>
<th>In the paper</th>
<th>In the appendix (at the request of reviewers)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Familiarity with BLM</td>
<td><span class="math inline">\(\checkmark\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Gender</td>
<td><span class="math inline">\(\checkmark\)</span></td>
<td><span class="math inline">\(\checkmark\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td>LGBT status</td>
<td><span class="math inline">\(\checkmark\)</span></td>
<td><span class="math inline">\(\checkmark\)</span></td>
<td></td>
</tr>
<tr class="even">
<td>Linked fate</td>
<td><span class="math inline">\(\checkmark\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Religiosity</td>
<td></td>
<td></td>
<td><span class="math inline">\(\checkmark\)</span></td>
</tr>
<tr class="even">
<td>Region</td>
<td></td>
<td></td>
<td><span class="math inline">\(\checkmark\)</span></td>
</tr>
<tr class="odd">
<td>Age</td>
<td></td>
<td></td>
<td><span class="math inline">\(\checkmark\)</span></td>
</tr>
<tr class="even">
<td>Education</td>
<td></td>
<td></td>
<td><span class="math inline">\(\checkmark\)</span></td>
</tr>
</tbody>
</table></div>
<!-- ### Scattered thoughts --><!-- - @ofosu2019pre --><!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book--><!-- start post here, do not edit above -->
</div>
</div>
<div id="writing" class="section level2">
<h2>
<span class="header-section-number">22.5</span> Writing<a class="anchor" aria-label="anchor" href="#writing"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>When writing up an empirical paper, the authors must convince reviewers and readers that the question is important and that the research design they selected provides useful answers to the question. This is where MIDA comes in. Elements of MIDA will appear in every section of a paper, and every element of MIDA should be described somewhere in the paper.</p>
<p>A common model for social science empirical papers has five sections: an introduction, theory and hypotheses, research design, results, and discussion. We outline how elements of MIDA can usefully fit into each section here, before providing an example paper highlighting where each element was described.</p>
<p>The introduction section should have a capitulation of each aspect of MIDA in brief. The reader is brought quickly up to speed on the whole research design, as well as expectations and actual findings.</p>
<p>The next section, theory and hypotheses, contains information about the causal model of the world (<span class="math inline">\(M\)</span>) and the research question about the world (<span class="math inline">\(I\)</span>) as well as guesses about <span class="math inline">\(a^M\)</span> (i.e., hypotheses!). The section should lay out all of the features of the model necessary to describe <span class="math inline">\(I\)</span>.</p>
<p>To motivate hypotheses, the theory section should outline our prior beliefs about <span class="math inline">\(a^W\)</span>, the true answer to the inquiry, based on past literature. A meta-analysis or systematic review of past evidence could provide a systematic summary of past answers to <span class="math inline">\(a^W\)</span>, or an informal literature review could be offered. These priors are used along with the study results to construct posterior beliefs reported in the discussion section, i.e., what we know after conducting the study. In summarizing the literature, it is important to consider the research designs of past studies (see Synthesis section). Meta-analyses often formally account for the quality of the research designs of past studies by weighting by the inverse of their precision (upweighting informative studies and down-weighting uninformative ones). Literature reviews may do so informally. Moreover, the summary of past literature is itself a research design, and so we should try to prevent common research design issues such as selection on the dependent variable by ensuring we discuss all literature and not only present views consonant with our hypotheses.</p>
<p>Though research questions are nearly ubiquitously included in the theory section, details of the model are often left out. Expected effect sizes, how effects vary by subgroups, expected proportions of subgroups, how variables are expected to be correlated, and the amount of variability in the outcome are some of the features of the model that will have important effects on how reviewers and readers judge the quality of the research design. Without specifying these portions of <span class="math inline">\(M\)</span>, a diagnosis cannot be conducted. Moreover, we describe in Reanalysis, when you define <span class="math inline">\(M\)</span> yourself in your paper, you can clarify the terms of the debate about alternative analysis strategies. When <span class="math inline">\(M\)</span> is undefined, the author of the reanalysis must infer your model or make up their own, and you may not agree.</p>
<p>The research design or methods section should have a description of <span class="math inline">\(D\)</span> and <span class="math inline">\(A\)</span> and a description of a diagnosis of the design. In this section, we defend our choice of <span class="math inline">\(D\)</span> and <span class="math inline">\(A\)</span> under <span class="math inline">\(M\)</span> and <span class="math inline">\(I\)</span>. Papers commonly have more than one <span class="math inline">\(D\)</span> and associated <span class="math inline">\(A\)</span> answering the same or related questions; both <span class="math inline">\(D\)</span> and <span class="math inline">\(A\)</span> for each should be described in this section.</p>
<p>The results section describes <span class="math inline">\(a^D\)</span>. Increasingly, results are presented visually as well as in text, in order to effectively communicate the results to the reader. Visualizing the modeled results as well as the raw data can both improve how the results are communicated and simultaneously help readers connect the research design, the data, and the results.</p>
<p>The discussion section is where we update our understanding of the model and form our posteriors about <span class="math inline">\(a^W\)</span> given our prior expectations and the results <span class="math inline">\(a^D\)</span>. We may learn from the study about new variables and new edges that matter in the model — new outcomes that are affected by a treatment. We also often learn more about the functional form of causal relationships between two variables, for example from new moderators or more precision on the size of the moderation. The discussion section is also a chance to point to new MIDAs that could be implemented to learn more about <span class="math inline">\(M\)</span>. These might relate to new nodes we discovered, or parts of the model that we did not yet learn enough about.</p>
<p>In the Figure below, we illustrate where elements of MIDA are incorporated into <span class="citation">Mousa (<a href="references.html#ref-mousa2020building" role="doc-biblioref">2020</a>)</span>. The study reports on the outcome of a randomized experiment in which Iraqi Christians were assigned either to an all-Christian soccer team or a team in which they would play alongside Muslims. The experiment tested whether being on a mixed team affected intergroup attitudes and behaviors, both among teammates and back at home after the games were over. We highlight in color areas discussing the model <span class="math inline">\(M\)</span> in yellow, the inquiry <span class="math inline">\(I\)</span> in green, the data strategy <span class="math inline">\(D\)</span> in blue, and the answer strategy <span class="math inline">\(A\)</span> in pink.</p>
<div class="figure">
<img src="figures/mousa-highlighted-sheet.png" alt=""><p class="caption">Paper with MIDA elements highlighted (Mousa 2020)</p>
</div>
<p>The model and the inquiry largely appear in the abstract and introductory portion of the paper, though aspects of the model are discussed later on. Much of the first three pages are devoted to the data strategy, while the answer strategy only appears briefly. This division makes sense: in this paper, the action is all in the experimental design whereas the answer strategy follows straightforwardly from it using the principles of analyze as you randomize. The paper mostly describes <span class="math inline">\(M\)</span> and <span class="math inline">\(D\)</span>, with only a small portion devoted to <span class="math inline">\(I\)</span> and <span class="math inline">\(A\)</span>. Finally, it is notable that the data strategy is interspersed with aspects of the model. The reason is that the author is justifying choices about randomization and measurement using features of the model. This highlights the deep connection between the two discussed in Part II.</p>
<p>Papers often report on the results from multiple data strategies and others on the answers to multiple related inquiries. Typically, a single <span class="math inline">\(M\)</span> should be described in the theory section, which describes how the nodes and edges used in each of the <span class="math inline">\(I\)</span>’s fit together. Each data and strategy should be described, and which inquiries each answer strategy is targeting. Each estimate should be linked to one or more inquiries. In some cases, the reason why multiple inquiries are studied in a single paper is that the aim of the paper is to falsify a model of the world. In this case, the model should be described and the diagnosis of the design should include an assessment of how good the <em>overall</em> design, with data and answer strategies to generate answers to each inquiry, is at falsifying the model. Psychology three-study papers often take this form: study 1 asks about the correlation between X and Y, in study 2 X is randomized, and in study 3 an analysis of the mechanisms that lead between X and Y are examined.</p>
<!-- Big ideas: -->
<!-- - make sure to have all of MIDA in your paper! -->
<!-- - please keep kosher.  Theory section material belongs in the theory section, not in the design or results section, etc. -->
<!-- 8. Reconciliation  -->
<!-- 9 Appendices and robustness -->

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
<!-- start post here, do not edit above -->
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="before.html"><span class="header-section-number">21</span> Before</a></div>
<div class="next"><a href="after.html"><span class="header-section-number">23</span> After</a></div>
</div></main><div id="on-this-page-nav" class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#during"><span class="header-section-number">22</span> During</a></li>
<li><a class="nav-link" href="#p4piloting"><span class="header-section-number">22.1</span> Piloting</a></li>
<li><a class="nav-link" href="#implementation"><span class="header-section-number">22.2</span> Implementation</a></li>
<li>
<a class="nav-link" href="#p4populatedpap"><span class="header-section-number">22.3</span> Populated Preanalysis Plan</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#example-18"><span class="header-section-number">22.3.1</span> Example</a></li></ul>
</li>
<li>
<a class="nav-link" href="#p4reconciliation"><span class="header-section-number">22.4</span> Reconciliation</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#example-19"><span class="header-section-number">22.4.1</span> Example</a></li></ul>
</li>
<li><a class="nav-link" href="#writing"><span class="header-section-number">22.5</span> Writing</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="download-code" href="./NA.R">Download R code <i class="fab fa-code"></i></a></li>
          
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Research Design: Declare, Diagnose, Redesign</strong>" was written by Graeme Blair, Alexander Coppock, and Macartan Humphreys. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Supported by the Laura and John Arnold Foundation and Evidence in Governance and Politics.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
