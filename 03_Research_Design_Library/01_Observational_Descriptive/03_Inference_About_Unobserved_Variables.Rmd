---
title: "Inference about unobserved variables "
output: html_document
bibliography: ../../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

## Inference about unobserved variables 


### Declaration

<!--
JC Comment: This setup seems a bit odd to me. I don't think anyone ever has the true average amount or score of democracy in mind as their inquiry, or thinks they're getting it by averaging indicators. It seems a bit trivial to show that anyone who sets out to do so gets the answer wrong if they don't anticipate an intercept in the DGP of one of the measures or make the wrong distributional assumptions. My sense is that there are two kinds of estimands people are usually interested in with designs such as these. First, do the things I measured "load" onto the underlying thing in the way I expect; second, do the relative levels stack up as they should (e.g., if Togo is truly less democratic than Benin then I want this to show up in the ordering). I've had a go at one design below that focuses on the second kind of estimand. Not entirely sure about it but I think it may be a step in the right direction and shows off DD flexibility.

```{r}
design <-
  declare_population(N = 100, Y_star = rnorm(N)) +
  declare_estimand(Y_bar = mean(Y_star)) + 
  declare_measurement(Y_1 = 0.1 * Y_star + rnorm(N, sd = 0.25),
                      Y_2 = Y_star + rnorm(N, sd = 0.25),
                      Y_3 = 1 + 0.5 * Y_star + rnorm(N, sd = 0.25),
                      Y_idx = (Y_1 + Y_2 + Y_3) / 3) + 
  declare_estimator(Y_idx ~ 1, model = lm_robust, estimand = "Y_bar")
```
-->

```{r}
design <-
  declare_population(N = 10, Y_star = rnorm(N), true_rank = rank(Y_star)) +
  declare_measurement(Y_1 = 0.1 * Y_star + rnorm(N, sd = 0.25),
                      Y_2 = Y_star + rnorm(N, sd = 0.25),
                      Y_3 = 1 + 0.5 * Y_star + rnorm(N, sd = 0.25),
                      Y_idx = (Y_1 + Y_2 + Y_3) / 3, 
                      ranking = rank(Y_idx)) 

# simulate_design(design) %>% 
#   summarize(ranking_correct = mean(true_rank == ranking))
```


### Dag


```{r, echo = FALSE}


dag <-
  dagify(Y_1 ~ Y_star, Y_2 ~ Y_star, 
         Y_3 ~ Y_star, 
         Y_idx ~ Y_1 + Y_2 + Y_3)

nodes <-
  tibble(
    name = c("Y_star", "Y_1", "Y_2", "Y_3", "Y_idx"),
    label = c("Y^*", "Y<sup>1</sup>", "Y<sup>2</sup>", "Y<sup>3</sup>", "I"),
    answer_strategy = "uncontrolled",
    annotation = c(
      "**Latent outcome**<br>unmeasurable",
      "**Measured outcome**",
      "",
      "",
      "**Constructed Index**"),
    x = c(1, 3, 3, 3, 5),
    y = c(2.5, 3.5, 2.5, 1.5, 2.5),
    nudge_direction = c("N", "N", "S", "N", "N")
  )

ggdd_df <- make_dag_df(dag, nodes, design)
base_dag_plot %+% ggdd_df
```

### Example


<!-- make sure to rename the section title below -->

```{r inference_about_unobserved_variables, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```




