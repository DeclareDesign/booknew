---
title: "Poststratification"
output: html_document
bibliography: ../../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE, fig.width = 7, fig.height = 5)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

## Poststratification

Poststratification is a tool for learning about a population when you have a sample whose units were drawn with unequal (and usually unknown) probabilities. In essence, if you know features of the population that you can measure in your own sample, you can reweight your sample to look like the population---at least along the dimensions you can measure. In its simplest form, poststratification just involves counting and dividing. Say you want to poststratify your sample so that, in terms of gender and age, it looks like all people in their twenties in the United States population in 2010. That gives twenty groups---one for each age and each gender---whose size you need to count in the 2010 Decennial census and in your sample. Then, simply weight each person in the sample by the size of their group in the population divided by the size of their group in the sample. As we illustrate with the declaration below, it turns out that these weights are equivalent to the inverse sampling probabilities one would obtain were one to construct the sample using groups as strata. That's where the "stratification" in poststratification comes from---it's "post" because the weights are constructed after the sampling has already taken place. In the online example, we illustrate how multi-level regression and poststratification (MRP) can help address the problem that, as the number of group-defining features increases, the sample may contain no information at all about some of the groups defined by the combination of those features. A multi-level regression model helps by partially pooling across strata to combat this sparsity problem.

### Declaration

<!-- 
JC comment: Original declaration doesn't have correlation between X and Y so this design works even if the estimator is just an intercept. Once I added the correlation, the design was biased. Don't quite understand the demeaning approach (doesn't appear to be using any population-level info?) so have just opted for a more conventional approach to poststratification that reweights to the population proportions. Have also called this poststratification since we are now only using MRP in the extended example. 

```{r}
fixed_population <- declare_population(N = 500, 
                                       X = sample(c("A", "B", "C"), N, replace = TRUE),
                                       Y = sample(1:7, N, replace = TRUE))()

design <- 
  declare_population(data = fixed_population) + 
  declare_estimand(Ybar = mean(Y)) + 
  declare_sampling(strata_prob = c(0.2, 0.1, 0.3), strata = X) + 
  declare_step(B_demeaned = (X == "B") - mean(X == "B"),
               C_demeaned = (X == "C") - mean(X == "C"), mutate) + 
  declare_estimator(Y ~ B_demeaned + C_demeaned, term = "(Intercept)", model = lm_robust, estimand = "Ybar")
```

-->

- **M**odel: We have a fixed, finite population comprised of two groups defined by a binary variable, $X$. There are 100 people who have $X = 0$ and 50 who have $X = 1$. The outcome, $Y$, takes one of three values, 0, 1, and 2, and is a function of $X$. 

- **I**nquiry: The researcher wants to know the true average of $Y$ in the population.

- **D**ata strategy: Ten individuals from each group are included in the sample. Thus, whereas 2/3 of the population belong to the $X = 0$ group, only 1/2 of the sample does. Conversely, while only 1/3 of the population belongs to the $X = 1$ group, 1/2 of the sample does.

- **A**nswer strategy: The answer strategy involves taking a weighted average of $Y$ in the sample, where each unit's weight is equal to the size of their group in the population divided by the size of their group in the sample. Specifically, those in the underrepresented group, $X = 0$, get a weight of 100/10 = 10, while the overrepresented group, $X = 1$, gets a weight of 50 / 10 = 5. When the poststratification groups perfectly line up with the sample strata, as they do here, the approach is equivalent to weighting by the inverse of the sampling probability: 1/(10/100) = 10 and 1/(10/50) = 5. In both cases, the weights tell us how many units in the population each unit in the sample represents. 

```{r}
fixed_population <-
  fabricate(
    group = add_level(
      N = 2,
      X = c(0, 1),
      population_n = c(100, 50)
    ),
    individual = add_level(N = population_n,
                           Y = X + sample(0:1, N, replace = TRUE))
  )

design <-
  declare_population(data = fixed_population) +
  declare_estimand(Ybar = mean(Y)) +
  declare_sampling(strata_n = c(10, 10), strata = X) +
  declare_step(handler = group_by, groups = X) +
  declare_step(handler = mutate,
               sample_n = n(),
               weight = population_n / sample_n) +
  declare_estimator(
    Y ~ 1,
    term = "(Intercept)",
    model = lm_robust,
    weights = weight,
    estimand = "Ybar"
  )
```

### Dag

```{r, echo=FALSE}
dag <- dagify(Y ~ S + X,
              S ~ X)
nodes <-
  tibble(
    name = c("X", "Y", "S"),
    label = c("X", "Y", "S"),
    annotation = c(
      "**Strata**<br>changes sampling probabilites",
      "**Outcome**<br>measured only for sampled units",
      "**Sampling indicator**<br>randomly set by designer"),
    x = c(1, 5, 1),
    y = c(4, 1, 1),
    nudge_direction = c("N", "S", "S"),
    data_strategy = c("unmanipulated", "unmanipulated", "sampling"),
    answer_strategy = "uncontrolled"
  ) 

ggdd_df <- make_dag_df(dag, nodes)

base_dag_plot %+% ggdd_df
```

### Exercises

- Add an unweighted estimator to the design and diagnose it. Explain why the unweighted estimator is biased, as well as the direction of the bias.
- Remove `X` from the definition of `Y`. Explain why the bias is now equivalent in the two approaches.
- Change the `strata_n` so that 4 people are sampled from the first group and 25 are sampled from the second group. 
  i. Calculate the poststratification weight for each group by hand (hint: you can check your answer using `draw_data(design)$weight`).
  ii. Calculate the sample inclusion probability for each group by hand (hint: you can check your answer using `draw_data(design)$S_inclusion_prob`). 
  iii. Calculate the inverse of the sampling probability for each group. These should be equal to the poststratification weights.

### Example


<!-- make sure to rename the section title below -->

```{r multilevel_regression_and_poststratification, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
library(lme4)
library(prediction)
```

MRP based on Lax and Philips APSR 2009

<!-- ```{r, echo = FALSE} -->
<!-- delaware_senate_districts_df <- read_rds("data/delaware.RDS") -->
<!-- kable(head(delaware_senate_districts_df, 5), booktabs = TRUE) -->
<!-- ``` -->

<!-- ```{r, eval = FALSE} -->

<!-- # US population -->
<!-- delaware_population_df <- fabricate( -->
<!--   data = delaware_senate_districts_df, -->
<!--   individuals = add_level( -->
<!--     N = population_size, -->
<!--     race_white = rbinom(N, 1, prob = prop_white), -->
<!--     race_black = rbinom(N, 1, prob = prop_black), -->
<!--     race_asian = rbinom(N, 1, prob = prop_black), -->
<!--     race_hispanic_other = rbinom(N, 1, prob = prop_hispanic_other), -->
<!--     pid_republican = rbinom(N, 1, prob = prop_republican), -->
<!--     pid_democrat = rbinom(N, 1, prob = prop_democrat) -->
<!--   ) -->
<!-- ) %>%  -->
<!--   select(-starts_with("prop_"), -population_size) -->

<!-- # population weights for MRP -->
<!-- mrp_weights <- delaware_population_df %>% -->
<!--   group_by(district, race_white, race_black, race_asian, race_hispanic_other, pid_republican, pid_democrat) %>%  -->
<!--   summarize(n_cell = n()) %>%  -->
<!--   group_by(district) %>%  -->
<!--   mutate(proportion_cell = n_cell/sum(n_cell)) %>%  -->
<!--   select(-n_cell) %>%  -->
<!--   ungroup  -->

<!-- delaware_population_df <- mrp_weights %>%  -->
<!--   select(district, proportion_cell) %>%  -->
<!--   right_join(delaware_population_df) -->

<!-- # Lax and Philips APSR 2009 -->
<!-- # Policies are coded dichotomously, 1 for the progay policy and 0 otherwise: Adoption (9 states allow second-parent adoption in all jurisdictions) -->

<!-- design <- -->
<!--   declare_population( -->
<!--     data = delaware_population_df,  -->

<!--     districts = modify_level(district_effect = rnorm(N)), -->

<!--     individuals = modify_level( -->
<!--       noise = rnorm(N, mean = district_effect), -->
<!--       policy_support = rbinom(N, 1, prob = pnorm( -->
<!--         0.25 + 0.2 * race_white - 0.1 * race_black - 0.2 * race_hispanic_other -  -->
<!--           0.1 * pid_democrat + 0.15 * pid_republican + noise)) -->
<!--     ) -->
<!--   ) +  -->

<!--   declare_estimand(handler = function(data) { -->
<!--     data %>% -->
<!--       group_by(district) %>% -->
<!--       summarize(estimand = mean(policy_support)) %>% -->
<!--       ungroup %>%  -->
<!--       mutate(estimand_label = "mean_policy_support") -->
<!--   }) + -->

<!--   declare_sampling(n = 500) + -->

<!--   declare_estimator(handler = tidy_estimator(function(data) { -->
<!--     data %>% -->
<!--       group_by(district) %>% -->
<!--       summarize(estimate = mean(policy_support)) -->
<!--   }), label = "strata_means", estimand = "mean_policy_support") +  -->

<!--   # this estimator owes code to https://timmastny.rbind.io/blog/multilevel-mrp-tidybayes-brms-stan/ -->
<!--   declare_estimator(handler = tidy_estimator(function(data) { -->

<!--     model_fit <- glmer( -->
<!--       formula = policy_support ~ race_white + race_black + race_asian + race_hispanic_other + -->
<!--         pid_democrat + pid_republican + (1 | district), -->
<!--       data = data, family = binomial(link = "logit")) -->

<!--     data %>% -->
<!--       mutate( -->
<!--         support_predicted = -->
<!--           prediction(model_fit, data = ., allow.new.levels = TRUE, type = "response"), -->
<!--         support_predicted_weighted = support_predicted * proportion_cell -->
<!--       ) %>% -->
<!--       group_by(district) %>% -->
<!--       summarize(estimate = sum(support_predicted_weighted)) -->

<!--   }), label = "mrp_mle", estimand = "mean_policy_support") -->

<!-- dat <- draw_data(design) -->

<!-- draw_estimates(design) -->

<!-- sims <- simulate_design(design, sims = 3) -->

<!-- diag <- diagnose_design(design, sims = 100, diagnosands = declare_diagnosands(bias = mean(estimate - estimand)), add_grouping_variables = "state") -->
<!-- ``` -->







