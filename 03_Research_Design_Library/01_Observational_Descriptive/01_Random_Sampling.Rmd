---
title: "Random sampling"
output:
  pdf_document: default
  html_document: default
bibliography: ../../bib/book.bib
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE, out.width = "100%")
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->
## Random sampling

```{r random_sampling, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 500
b_sims <- 20
```

Often, we are interested in features of a population, but data on the entire population is prohibitively expensive to collect. Instead, researchers obtain data on a small fraction of the population and use measurements taken on that sample to draw inferences about the population.

Imagine we seek to estimate the average political ideology of adult residents of the small town of Portola, California (population 2,100). Households include between 1 and 3 adults; adults living in the same households typically have similar ideologies, but differ somewhat. The *latent* ideology of each subject is therefore composed of a household-level shock as well as an idiosyncratic individual-level shock. Our data strategy will involve administering a survey that asks subjects to place themselves on a left-right scale that varies from 1 (most liberal) to 7 (most conservative). We approximate this measurement procedure with a function that "cuts" the latent ideology into 7 separate groups. Note that here we define the measurement *before* the sampling to let us simulate what we *would* measure for any member of the population were we to sample them.

Our inquiry is "data-dependent", since we are interested the population mean of the *measured* variable $Y$: $\frac{1}{N} \sum_1^N Y_i = \bar{Y}$ (or, what we would measure were we to be able to measure the population). Our first sampling strategy will be complete random sampling. We draw a sample of exactly $n = 100$, where every member of the population has an equal probability of inclusion in the sample, $\frac{n}{N}$. Our answer strategy is the sample mean estimator: $\widehat{\overline{Y}} = \frac{1}{n} \sum_1^n Y_i$, implemented here as an ordinary least squares regression to facilitate the easy calculation of auxiliary statistics like the standard error of the estimate and the 95% confidence interval.

### Declaration

```{r}
portola <-
  fabricate(
    households = add_level(N = 500, 
                           n_adults = sample(1:3, N, replace = TRUE),
                           household_shock = rnorm(N, mean = 1)),
    adults = add_level(N = n_adults, 
                       individual_shock = rnorm(N, sd = 0.1),
                       Ystar = household_shock + individual_shock)
    )

design <- 
  declare_model(data = portola) + 
  declare_measurement(Y = as.numeric(cut(Ystar, 7))) + 
  declare_inquiry(Y_bar = mean(Y)) + 
  declare_sampling(n = 100) + 
  declare_estimator(Y ~ 1, model = lm_robust, inquiry = "Y_bar")
```

### DAG

```{r, echo=FALSE}
dag <- dagify(Y ~ Q + Ystar + S)

nodes <-
  tibble(
    name = c("Y", "S", "Q", "Ystar"),
    label = c("Y", "S", "Q", "Y^*"),
    annotation = c("**Measured outcome**<br>observed only for sampled units",
                   "**Sampling indicator**<br>randomly set by designer",
                   "**Survey Question**",
                   "**Latent outcome**"),
    x = c(5, 1, 5, 1),
    y = c(1.5, 3.5, 3.5, 1.5), 
    nudge_direction = c("S", "N", "N", "S"),
    data_strategy = c("unmanipulated", "sampling", "measurement", "unmanipulated"),
    answer_strategy = "uncontrolled"
  )

ggdd_df <- make_dag_df(dag, nodes)

base_dag_plot %+% ggdd_df
```

#### Diagnosis

Two main diagnosands for the simple random sampling design are bias and rmse. We want to know if we get the right answer on average and we want to know, on average, how far off from the truth we are.

```{r, eval = FALSE}
diagnosands <- declare_diagnosands(
  bias = mean(estimate - estimand),
  rmse = sqrt(mean((estimate - estimand) ^ 2))
)
diagnosis <- diagnose_design(design, diagnosands = diagnosands) 
```


```{r, echo = FALSE, eval = do_diagnosis & !exists("do_bookdown")}
diagnosands <- declare_diagnosands(
  bias = mean(estimate - estimand),
  rmse = sqrt(mean((estimate - estimand) ^ 2))
)
diagnosis <- diagnose_design(design, sims = sims, bootstrap_sims = b_sims, diagnosands = diagnosands) 
```

```{r, echo = FALSE, purl = FALSE}
# figure out where the dropbox path is, create the directory if it doesn't exist, and name the RDS file
rds_file_path <- paste0(get_dropbox_path("Random_Sampling"), "/simple_random_sampling_sims.RDS")
if (do_diagnosis & !exists("do_bookdown")) {
  write_rds(diagnosis, path = rds_file_path)
}
diagnosis <- read_rds(rds_file_path)
```

```{r completerandomsampling, echo = FALSE}
diagnosis %>%
  reshape_diagnosis() %>%
  select(Bias, RMSE) %>%
  kable(digits = 3, booktabs = TRUE, caption = "Complete random sampling design diagnosis")
```

The diagnosis in table \@ref(tab:completerandomsampling) indicates that under complete random sampling, the sample mean estimator of the population mean is unbiased and that the root mean squared error is manageable at `r round(diagnosis$diagnosands_df$rmse,2)`.

#### Exercises

1. Can you modify the design to define the estimand as the mean of the latent variable `Y_star`? What happens if you diagnose this design?
2. Can you modify the design to allow for the possibility of measurement error? 
2. Can you modify the design to allow for the possibility of sampling error? 


### Clustered random sampling

Researchers often cannot randomly sample at the individual level because it may, among other reasons, be too costly or logistically impractical. Instead, they may choose to randomly sample households, political precincts, or any group of individuals in order to draw inferences about the population. This strategy may be cheaper and simpler but may also introduce risks of less precise estimates.

Let's modify our first design to sample at the household level, rather than at the individual level. We'll also add an additional estimator that clusters standard errors at the level of sampling, the household to compare to the estimator that ignores clustering. We'll also add a new diagnosand, coverage, which will indicate whether the confidence intervals we construct (which depend on the flavor of standard errors we estimate) indeed include the true value of the inquiry 95\% of the time.

```{r}
design <-
  declare_model(data = portola) +
  declare_measurement(Y = as.numeric(cut(Ystar, 7))) +
  declare_inquiry(Y_bar = mean(Y)) +
  declare_sampling(clusters = households, n = 50) +
  declare_estimator(Y ~ 1,
                    model = lm_robust,
                    estimand = "Y_bar",
                    label = "Standard errors not clustered") +
  declare_estimator(Y ~ 1,
                    clusters = households,
                    model = lm_robust,
                    estimand = "Y_bar",
                    label = "Standard errors clustered")

diagnosands <- declare_diagnosands(
  bias = mean(estimate - estimand),
  rmse = sqrt(mean((estimate - estimand) ^ 2)),
  coverage = mean(estimand <= conf.high & estimand >= conf.low)
)
diagnosis <- diagnose_design(design, diagnosands = diagnosands) 
```

```{r, echo = FALSE, purl = FALSE}
# figure out where the dropbox path is, create the directory if it doesn't exist, and name the RDS file
rds_file_path <- paste0(get_dropbox_path("Random_Sampling"), "/cluster_random_sampling_sims.RDS")
if (do_diagnosis & !exists("do_bookdown")) {
  write_rds(diagnosis, path = rds_file_path)
}
diagnosis <- read_rds(rds_file_path)
```

```{r clusterrandomsampling, echo = FALSE}
diagnosis %>%
  reshape_diagnosis() %>%
  select(`Estimator Label`, Bias, RMSE, Coverage) %>%
  kable(digits = 3, booktabs = TRUE, caption = "Cluster random sampling design diagnosis")
```

The diagnosis shows the effect of clustering on the quality of our estimates. While the design remains unbiased for the population mean, the RMSE has gone up. We still interview (on average) 100 people in each sample, but since under the clustered design, we interview all adults in the household, the sampling distribution of the estimates has higher variance. The diagnosis also highlights the importance of matching your answer strategy to your data strategy. The sampling was clustered by household. The answer strategy that fails to account for clustering yields confidence intervals that are too small, as evidenced by the coverage rate well below the nominal 95\%. When we estimate clustered standard errors instead, the coverage improves.


#### Exercises

1. Here the clusters were defined as part of the model, but they could be defined as part of the data strategy.  Can you modify the design and generate sampling clusters by putting neighboring households into the same cluster. Your data will have a household identifier `households` so you could try making a single cluster out of each pair (for instance households `001` and `002`). How does sampling using pairs of households together affect your estimated rmse?    

<!-- #### Exercises -->

<!-- 1. Modify the declaration to change the distribution of $Y$ from being uniform to something else: perhaps imagine that more extreme ideologies are more prevalent than moderate ones. Is the sample mean estimator still unbiased? Interpret your answer. -->
<!-- 2. Change the sampling procedure to favor units with higher values of ideology. Is the sample mean estimator still unbiased? Interpret your answer. -->
<!-- 3. Modify the estimation function to use this formula for the standard error: $\widehat{se} \equiv \frac{\widehat\sigma}{\sqrt{n}}$. This equation differs from the one used in our declaration (it ignores the total population size $N$). Check that the coverage of this new design is incorrect when $N=n$. Assess how large $N$ has to be for the difference between these procedures not to matter.  -->




