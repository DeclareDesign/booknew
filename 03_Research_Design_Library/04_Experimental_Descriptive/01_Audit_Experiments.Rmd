---
title: "Audit experiments"
output: html_document
bibliography: ../../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

<!-- make sure to rename the section title below -->

```{r audit_experiments, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```

## Audit experiments

Audit experiments are used to measure whether requests that vary on some dimension of interest receive equal treatment. The design is used commonly in employment settings to measure whether job applications that are otherwise similar but come from candidates from different genders, races, or social backgrounds receive the same rate of job interview invitations. The same approach has been applied to a very wide range of settings, including education, housing, and requests to politicians.

The goal can be thought of a measurement problem: measuring the level of discrimination. But insofar as acts of discrimination are themselves responses to stimuli they can be addressed using methods of causal inference.  

For example, @WHITE_NATHAN_FALLER_2015 seek to measure discrimination by assessing the effects of an email from a Latino name (versus a White name) on *whether* and *how well* election officials respond to requests for information. 

### Declaration

- **M**odel: 
    
    The model has two outcome variables, $R_i$ and $Y_i$. $R_i$ stands for "response" and is equal to 1 if a response is sent, and 0 otherwise. $Y_i$ is the tone of the response and is normally distributed when it is defined. $Z_i$ is the treatment and equals 1 if the email is sent using a Latino name and 0 otherwise. The table below shows the potential outcomes for four possible types of subjects, depending on the potential outcomes of $R_i$. *A* types always respond regardless of treatment and *D* types never respond, regardless of treatment. *B* types respond if and only if they are treated, whereas *C* types respond if and only if they are *not* treated. The table also includes columns for the potential outcomes of $Y_i$, showing which potential outcome subjects would express depending on their type. The key thing to note is that for the B, C, and D types, the effect of treatment on $Y_i$ is *undefined* because messages never sent have no tone. The last (and very important) feature of our model is that the outcomes $Y_i$ are possibly correlated with subject type. Even though both $\E[Y_i(1) | \text{Type} = A]$ and $\E[Y_i(1) | \text{Type} = B]$ exist, there's no reason to expect that they are the same. 
    In the design, we assume a distribution of types with  40% *A*, 5% *B*, 10% *C*, and 45% *D*.

| Type | $R_i(0)$ | $R_i(1)$ | $Y_i(0)$  | $Y_i(1)$ |
| ---- | -------- | -------- | --------- | -------- |
| A    | 1        | 1        | $Y_i(0)$  | $Y_i(1)$ |
| B    | 0        | 1        | NA        | $Y_i(1)$ |
| C    | 1        | 0        | $Y_i(0)$  | NA       |
| D    | 0        | 0        | NA        | NA       |

Table: (\#tab:auditcausaltypes) Causal Types 

- **I**nquiry: 

    We have two inquiries. The first is straightforward: $\E[R_i(1) - R_i(0)]$ is the Average Treatment Effect on response. The second inquiry is the undefined inquiry that does not have an answer: $\E[Y_i(1) - Y_i(0)]$. We will also consider a third inquiry, which *is* defined: $\E[Y_i(1) - Y_i(0) | \mathrm{Type} = A]$, which is the average effect of treatment on tone among $A$ types.

- **D**ata strategy: 

    The data strategy will be to use complete random assignment to assign 250 of 500 units to treatment.

- **A**nswer strategy: 

    We'll try to answer all three inquiries with the difference-in-means estimator, but as the diagnosis will reveal, this strategy works well for some inquiries but not others.

```{r}
design <- 
  declare_population(N = 100,
                     U = rnorm(N)) +
  declare_potential_outcomes(
    R ~ if_else(Z + U > 0.5, 1, 0), conditions = list(Z = c(0, 1))) +
  declare_potential_outcomes(
    Q ~ if_else(R == 1, Z + U, NA_real_), 
    conditions = list(Z = c(0, 1), R = c(0, 1))) +
  declare_estimand(ATE_R = mean(R_Z_1 - R_Z_0)) + 
  declare_estimand(CATE_ar = mean(Q_Z_1_R_1 - Q_Z_0_R_1), 
                   subset = (R_Z_1 == 1 & R_Z_0 == 0)) + 
  declare_assignment(prob = 0.5) +
  declare_reveal(R, Z) +
  declare_reveal(Q, c(Z, R)) +
  declare_estimator(R ~ Z, estimand = "ATE_R", label = "ATE_R") +
  declare_estimator(Q ~ Z, subset = (R == 1), 
                    estimand = "CATE_ar", 
                    label = "CATE_ar")
```


### DAG

```{r, echo = FALSE, fig.height = 4, fig.width = 7}
dag <- dagify(
  Q ~ R + Z + U,
  R ~ Z + U
)

nodes <-
  tibble(
    name = c("Z", "R", "Q", "U"),
    label = c("Z", "R", "Q", "U"),
    annotation = c(
      "**Random assignment**<br> Subject sent email",
      "**Outcome 1**<br>Subject replies to email",
      "**Outcome 2**<br>Email quality",
      "Unknown<br>heterogeneity"),
    x = c(1, 3, 3, 5),
    y = c(2.5, 3.5, 1.5, 2.5), 
    nudge_direction = c("N", "N", "S", "N"),
    data_strategy = c("assignment", "unmanipulated", "unmanipulated", "unmanipulated"),
    answer_strategy = c("uncontrolled", "controlled", "uncontrolled", "uncontrolled")
  )

ggdd_df <- make_dag_df(dag, nodes)

base_dag_plot %+% ggdd_df + coord_fixed(xlim = c(0.5, 5.5))
```

### Takeaways

- The effect on response is identified by the design
- This is a "descriptive" quantity in the sense that we seek to estimate the fraction of bureaucrats that discriminate against Latinos. We only learn this if the treatment effect on response is "monotonic"


<!-- ### Example -->




<!-- We learn three things from the design diagnosis. First, as expected, our experiment is unbiased for the average treatment effect on response. -->

<!-- Next, we see that our second inquiry, as well as our diagnostics for it, are undefined. The diagnosis tells us that our definition of potential outcomes produces a definition problem for the estimand. Note that the diagnosands that are defined, including power, depend only on the answer strategy and not on the estimand. -->

<!-- Finally, our third estimand -- the average effects for the $A$ types -- is defined but our estimates are biased. The reason for this is that we cannot tell from the data which types are the $A$ types: we are not conditioning on the correct subset. Indeed, we are unable to condition on the correct subset. If a subject responds in the treatment group, we don't know if she is an $A$ or a $B$ type; in the control group, we can't tell if a responder is an $A$ or a $C$ type. Our difference-in-means estimator of the ATE on $Y$ among $A$s will be off whenever $A$s have different outcomes from $B$s and $C$s. -->

<!-- In some cases, the problem might be resolved by changing the inquiry. Closely related estimands can often be defined, perhaps by redefining $Y$ (e.g., emails never sent have a tone of zero). Some redefinitions of the problem, as in the one we examine above, require estimating effects for unobserved subgroups which is a difficult challenge. -->

<!-- ### Applications -->

<!-- This kind of problem is surprisingly common. Here are three more distinct instances of the problem: -->

<!-- 1. $Y$ is the decision to vote Democrat ($Y=1$) or Republican ($Y=0$), $R$ is the decision to turn out to vote and $Z$ is a campaign message. The decision to vote may depend on treatment but if subjects do not vote then $Y$ is undefined. -->
<!-- 2. $Y$ is the weight of infants, $R$ is whether a child is born and $Z$ is a maternal health intervention. Fertility may depend on treatment but the weight of unborn (possibly never conceived) babies is not defined. -->
<!-- 2. $Y$ is the charity to whom contributions are made during fundraising and $R$ is whether anything is contributed and $Z$ is an encouragement to contribute. The identity of beneficiaries is not defined if there are no contributions.  -->

<!-- All of these problem exhibit a form of post treatment bias (see section **Post treatment bias**) but the issue goes beyond picking the right estimator. Our problem here is conceptual: the effect of treatment on the outcome just doesn't exist for some subjects. -->

<!-- ### Exercises -->

<!-- 1. The amount of bias on the third estimand depends on both the distribution of types and the correlation of types with the potential outcomes of Y. Modify the declaration so that the estimator of the effect on Y is unbiased, changing only the distribution of types. Repeat the exercise, changing only the correlation of type with the potential outcomes of $Y$.   -->

<!-- 2. Try approaching the problem by redefining the inquiry, seeking to assess the effect of treatment on the share of responses with positive tone.  -->





