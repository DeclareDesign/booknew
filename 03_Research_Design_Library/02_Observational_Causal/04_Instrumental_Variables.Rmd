---
title: "Instrumental variables"
output:
  pdf_document: default
  html_document: default
bibliography: ../../bib/book.bib
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

<!-- make sure to rename the section title below -->

```{r instrumental_variables, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```

## Instrumental variables {#p3iv}

When we are unwilling or unable to credibly assert that we have blocked all back-door paths between a treatment $D$ and the outcome $Y$ -- that is, when the selection-on-observables assumption fails -- we might have to give up on our goal of drawing causal inferences. 

But occasionally, the world yields an opportunity to sidestep unobserved confounding by generating as-if random variation in a variable that itself affects the treatment variable. We call the variable that is as-if randomly assigned by the world an "instrument." 

Before we delve into the intricacies of the instrumental variables design -- and there are many -- it's worth considering what a special thing an instrument is. Instruments are variables that are randomly assigned by nature, the government, or other powers-that-be. Usually, genuine random assignments have to be crafted by researchers as part of a deliberate data strategy. Experimenters go to great lengths to randomly expose some units but not others to treatments. When the world provides bonafide random variation in something, it's a rare and valuable opportunity. By virtue of as-if random assignment, we can learn about the average causal effects of the instrument itself without any further consternation. Conditional on geography and season, weather conditions are as-if randomly assigned, so we can learn about the average effects of rainfall on many outcomes, like crop yields, voter turnout, and attendance at sporting events. Conditional on gender and birth year, draft numbers are randomly assigned by the government, so we can learn about the average effects of being drafted on educational attainment, future earnings, or public policy preferences. In the argot of instrument variables, the effect of the instrument is called the "reduced form" or the "intention-to-treat" (ITT) effect. If it's really true that the instrument is randomly assigned by the world, estimation of the reduced form effect is straightforward.

The trouble comes when we want to leverage the random assignment of the instrument ($Z$) to learn about the average causal effects of a treatment variable ($D$) on the outcome ($Y$). To do so, we first need to change the inquiry from the average treatment effect of $D$ on $Y$ to the "local" average treatment effect, or LATE. The name of the inquiry reflects the idea that the effect applies only to the specific group of units whose treatment status changes as a result of the instrument. This group is often called the "compliers." The LATE is $\E[Y_i(D_i = 1) - Y_i(D_i = 0) | D_i(Z_i = 1) > D_i(Z_i = 0)]$ -- the average treatment effect among the group of people whose value of the treatment is higher as a result of the treatment. The LATE is different from the ATE because it does not average over those units whose value of the treatment does not depend on the instrument. Secondly, we need to assure ourselves of the five (5) instrumental variables assumptions. In the case of a binary instrument and a binary treatment, these are:

1. Exogeneity of the instrument: $Y_i(D_i = 1), Y_i(D_i = 0), D_i(Z_i = 1), D_i(Z_i = 0) \indep Z_i | X_i$. Substantively, this assumption requires that (possibly conditional on observed covariates in $X$) the instrument is as-if randomly, so it is jointly independent of the treated and untreated potential outcomes as well as the potential values the treatment variable $D$ would take on depending on the values of the instrument $Z$. Exogeneity is usually justified on the basis of qualitative knowledge of why as-if random assignment is a reasonable assumption to make. The assumption can be bolstered with design checks like the balance on pre-treatment values of the covariates according to the levels of the instrument.

2. Excludability of the instrument: $Y_i(D_i(Z_i), Z_i) = Y_i(D_i(Z_i))$. We can "exclude" the instrument from the potential outcomes function $Y_i()$ -- the only relevant argument is the value of the treatment variable. Another way of thinking about this exclusion restriction is to conceive of it as the "total mediation assumption," by which we mean that $Z$ has exactly no effect on $Y$ except by changing the value of $D$. Under the exclusion restriction, the effect of the instrumental variable is wholly mediated by the treatment variable. The exclusion restriction cannot be demonstrated empirically and typically must be asserted on qualitative grounds. Since the reduced form of the instrument can be estimated for many different outcome variables, one piece of evidence that can bolster the exclusion restition is to show how the instrument does not affect other plausible causal precedents of the outcome variable. If it does affect other variables that might, in turn, affect the outcome, doubt may be cast on the exclusion restriction.

3. Non-interference: $Y(D_i(Z_i), D_{-i}, Z_{-i}) = Y(D_i(Z_i))$. Like any non-interference assumption, here we assert that for any particular unit, other units' values of the instrument or the treatment do not affect the outcome. 

4. Monotonicity: $D_i(Z_i = 1) \geq D_i(Z_i = 0), \forall_i$. This assumption states that the effect of the instrument on the treatment is either zero or is positive for all units. Monotonicity rules odd types (called "defiers") who would have $D = 1$ if $Z = 0$ but would have $D = 0$ if $Z = 1$. Monotonicity is usually quite plausible (it's tough to imagine a person who would serve in the military if not drafted but *would* serve if drafted!), but it's not possible to affirm empirically. An empirical test that demonstrates a positive effect of the instrument on the treatment for one group but a negative effect for a different group could, however, falsify the monotonicity assumption.

5. Non-zero effect of the instrument on the treatment. If the instrument does not affect the treatment, then it is useless for learning about the effects of the treatment on the outcome, simply because it generates no compliers. If there are no compliers, the LATE itself is undefined. 

If all five of these assumptions are met, it can be shown that $LATE = \frac{\text{Reduced Form}}{\text{First Stage}}$. This expression underlines the importance of assumption 5 -- if the instrument doesn't affect the treatment, the first stage is equal to zero and the ratio is undefined. A plug-in estimator of the LATE is the difference-in-means of the outcome according to the instrument divided by the difference-in-means of the treatment according to the instrument. Equivalently, we can use two-stage least squares, which will yield the identical answer as the ratio of the difference-in-means estimates in the no covariate-adjustment case. 

The instrumental variables setup is perfectly analogous to a randomized experiment with noncompliance. The instrument is equivalent to the random *assignment*. If some units do not comply with their assignment (some in the treatment group don't take treatment or some in the control group *do* take treatment), then a comparison of groups according to the treatment variable will be biased by unobserved confounding. The best we can do under noncompliance is to redefine the estimand to be the complier average causal effect (equivalent to the LATE), then estimate it via two-stage least squares. The required excludability assumption is that the assignment to treatment can't affect the outcome except through the realized treatment variable, which may or may not hold in a given experimental setting.

### Declaration

```{r}
design <-
  declare_model(N = 100, U = rnorm(N)) +
  declare_potential_outcomes(D ~ if_else(Z + U > 0, 1, 0), 
                             assignment_variables = Z) + 
  declare_potential_outcomes(Y ~ 0.1 * D + 0.25 + U, 
                             assignment_variables = D) +
  declare_inquiry(LATE = mean(Y_D_1[D_Z_1 == 1 & D_Z_0 == 0] - 
                                 Y_D_0[D_Z_1 == 1 & D_Z_0 == 0])) +
  declare_assignment(prob = 0.5) +
  declare_reveal(D, Z) + 
  declare_reveal(Y, D) + 
  declare_estimator(Y ~ D | Z, model = iv_robust, estimand = "LATE") 
```

### DAG

```{r, echo = FALSE}
dag <- dagify(Y ~ D + U,
              D ~ Z + U)

nodes <-
  tibble(
    name = c("Z", "D", "U", "Y"),
    label = c("Z", "D", "U", "Y"),
    annotation = c(
      "**Exogenous variable**<br>Instrument",
      "**Endogenous variable**",
      "**Unknown heterogeneity**",
      "**Outcome**"
    ),
    x = c(1, 3, 5, 5),
    y = c(1.5, 1.5, 3.5, 1.5), 
    nudge_direction = c("S", "S", "N", "S"),
    data_strategy = "unmanipulated",
    answer_strategy = "uncontrolled"
  )

ggdd_df <- make_dag_df(dag, nodes)

base_dag_plot %+% ggdd_df
```

### Redesign

- excludability violations
- if you do, go $ITT_d$ and $ITT_y$

### Example

Instrument is the gender match of the second child with the first child
treatment is family size
outcome variable is labor force participation.

The treatment causes decreases in labor for participation for women parents but not men parents.


### Further reading

-- discussion of Deaton and Cartwright's critique of IV (our reiterpretation is they are saying IV is biased for ATE; response is that IV targets LATE and is unbiased for late; if we are clear about inquiry and data+answer strategy we can be more clear about the debate)

Applications

- Mo, Cecilia Hyunjung, Katherine Conn, Georgia Anderson-Nilsson. 2019. “Can National Service Activism Activate Women’s Political Ambition? Evidence from Teach For America.”  Politics, Groups, and Identities 7(4): 864-877.

Methodological literature

- @angrist2008mostly ch. 4 on instrumental variables estimation
- @Gerber2012 ch. 5 and ch. 6 on the connection between IV and noncompliance in an experiment
<!-- - @heckman2006understanding -->
- @deaton2009instruments for a critique of the LATE as an estimand and @imbens2010better for a rejoinder.


