---
title: "Regression Discontinuity"
output: html_document
bibliography: ../../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

```{r regression_discontinuity, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```

## Regression Discontinuity {#RDD}

### Declaration

Regression discontinuity designs exploit substantive knowledge that treatment is assigned in a particular way: everyone above a threshold is assigned to treatment and everyone below it is not. Even though researchers do not control the assignment, substantive knowledge about the threshold serves as a basis for a strong identification claim.

Thistlewhite and Campbell introduced the regression discontinuity design in the 1960s to study the impact of scholarships on academic success. Their insight was that students with a test score just above a scholarship cutoff were plausibly comparable to students whose scores were just below the cutoff, so any differences in future academic success could be attributed to the scholarship itself.

Regression discontinuity designs identify a *local* average treatment effect: the average effect of treatment *exactly at the cutoff*. The main trouble with the design is that there is vanishingly little data exactly at the cutoff, so any answer strategy needs to use data that is some distance away from the cutoff. The further away from the cutoff we move, the larger the threat of bias.

We'll consider an application of the regression discontinuity design that examines party incumbency advantage -- the effect of a party winning an election on its vote margin in the next election.

#### Declaration

  - **M**odel: Regression discontinuity designs have four components: A running variable, a cutoff, a treatment variable, and an outcome. The cutoff determines which units are treated depending on the value of the running variable.
  
    In our example, the running variable $X$ is the Democratic party's margin of victory at time $t-1$; and the treatment, $D$, is whether the Democratic party won the election in time $t-1$. The outcome, $Y$, is the Democratic vote margin at time $t$. We'll consider a population of 1,000 of these pairs of elections.
    
    A major assumption required for regression discontinuity is that the conditional expectation functions for both treatment and control potential outcomes are continuous at the cutoff.^[An alternative motivation for some designs that do not rely on continuity at the cutoff is "local randomization".] To satisfy this assumption, we specify two smooth conditional expectation functions, one for each potential outcome. The figure plots $Y$ (the Democratic vote margin at time $t$) against $X$ (the margin at time $t-1$). We've also plotted the true conditional expectation functions for the treated and control potential outcomes. The solid lines correspond to the observed data and the dashed lines correspond to the unobserved data.
    
```{r,include=FALSE, echo = FALSE}

cutoff <- 0.5
control <- function(X) {
  as.vector(poly(X, 4, raw = TRUE) %*% c(.7, -.8, .5, 1))}
treatment <- function(X) {
  as.vector(poly(X, 4, raw = TRUE) %*% c(0, -1.5, .5, .8)) + .15}

design <-
  declare_population(
    N = 1000,
    U = rnorm(N, 0, 0.1),
    X = runif(N, 0, 1) + U - cutoff,
    D = 1 * (X > 0)
  ) +
  declare_potential_outcomes(
    Y ~ D * treatment(X) + (1 - D) * control(X) + U,
    assignment_variable = D
  ) +
  declare_estimand(LATE = treatment(0) - control(0)) +
  declare_reveal(Y, D) +
  declare_estimator(
    Y ~ poly(X, 4) * D, model = lm_robust, estimand = "LATE"
  )

mock_data <- draw_data(design)
X <- seq(-.5, .5, .005)
treatment_frame <-
  data.frame(
    X = X,
    Y = treatment(X),
    observed = ifelse(X > 0, "a", "b"),
    D = 1
  )
control_frame <-
  data.frame(
    X = X,
    Y = control(X),
    observed = ifelse(X <= 0, "a", "b"),
    D = 0
  )
plot_frame <-
  rbind(treatment_frame, control_frame)
```

```{r,echo=FALSE, warning=FALSE}
ggplot(plot_frame, aes(x = X, y = Y, color = as.factor(D))) +
  geom_line(aes(linetype = observed)) +
  geom_point(data = mock_data, alpha = .2, size = .5) +
  scale_linetype_discrete(name = "", labels = c("Observable", "Unobservable")) +
  scale_color_manual(name = "", values = c(dd_light_blue, dd_orange), labels = c("Untreated","Treated")) +
  geom_vline(xintercept = 0, size = .05) +
  xlab("Running Variable") +
  geom_segment(aes(
    x = 0,
    xend = 0,
    y = control(0),
    yend = treatment(0)
  ), color = "black") +
 dd_theme()
```

- **I**nquiry: Our estimand is the effect of a Democratic win in an election on the Democratic vote margin of the next election, when the Democratic vote margin of the first election is zero. Formally, it is the difference in the conditional expectation functions of the control and treatment potential outcomes when the running variable is exactly zero. The black vertical line in the plot shows this difference.

- **D**ata strategy: We collect data on the Democratic vote share at time $t-1$ and time $t$ for all 1,000 pairs of elections. There is no sampling or random assignment.

- **A**nswer strategy: We will approximate the treated and untreated conditional expectation functions to the left and right of the cutoff using a flexible regression specification estimated via OLS. In particular, we fit each regression using a fourth-order polynomial. Much of the literature on regression discontinuity designs focuses on the tradeoffs among answer strategies, with many analysts recommending against higher-order polynomial regression specifications. We use one here to highlight how well such an answer strategy does when it matches the functional form in the model. We discuss alternative estimators in the exercises. 

```{r}
cutoff <- 0.5
control <- function(X) {
  as.vector(poly(X, 4, raw = TRUE) %*% c(.7, -.8, .5, 1))}
treatment <- function(X) {
  as.vector(poly(X, 4, raw = TRUE) %*% c(0, -1.5, .5, .8)) + .15}

design <-
  declare_population(
    N = 1000,
    U = rnorm(N, 0, 0.1),
    X = runif(N, 0, 1) + U - cutoff,
    D = 1 * (X > 0)
  ) +
  declare_potential_outcomes(
    Y ~ D * treatment(X) + (1 - D) * control(X) + U, 
    assignment_variable = D
  ) +
  declare_estimand(LATE = treatment(0) - control(0)) +
  declare_reveal(Y, D) +
  declare_estimator(
    Y ~ poly(X, 4) * D, 
    model = lm_robust, 
    estimand = "LATE"
  )
```


### DAG

```{r, echo = FALSE}
dag <- dagify(Y ~ D + X + U,
              D ~ X,
              X ~ U)

nodes <-
  tibble(
    name = c("U", "X", "D", "Y"),
    label = c("U", "X", "D", "Y"),
    annotation = c(
      "**Unknown heterogeneity**",
      "**Exogenous variable**",
      "**Treatment**",
      "**Outcome variable**"
    ),
    x = c(5, 1, 4, 5),
    y = c(4, 2.5, 2.5, 1), 
    nudge_direction = c("N", "S", "N", "S"),
    data_strategy = "unmanipulated",
    answer_strategy = c("uncontrolled", "controlled", "uncontrolled", "uncontrolled")
  )

ggdd_df <- make_dag_df(dag, nodes)

base_dag_plot %+% ggdd_df
```

### Example


### Exercises

1. @gelman2017high point out that higher order polynomial regression specifications lead to extreme regression weights. One approach to obtaining better estimates is to select a bandwidth, $h$, around the cutoff, and run a linear regression. Declare a sampling procedure that subsets the data to a bandwidth around the threshold, as well as a first order linear regression specification, and analyze how the power, bias, RMSE, and coverage of the design vary as a function of the bandwidth. 
  
2. The `rdrobust` estimator in the `rdrobust` package implements a local polynomial estimator that automatically selects a bandwidth for the RD analysis and bias-corrected confidence intervals. Declare another estimator using the `rdrobust` function and add it to the design. How does the coverage and bias of this estimator compare to the regression approaches declared above?

3. Reduce the number of polynomial terms of the `treatment()` and `control()` functions and assess how the bias of the design changes as the potential outcomes become increasingly linear as a function of the running variable.
  
4. Redefine the population function so that units with higher potential outcome are more likely to locate just above the cutoff than below it. Assess whether and how this affects the bias of the design.

### Further Reading

<!-- Since its rediscovery by social scientists in the late 1990s, the regression discontinuity design has been widely used to study diverse causal effects such as: prison on recidivism (@Ojmarrh2017); China's one child policy on human capital (@qin2017); eligibility for World Bank loans on political liberalization (@carnegie2017international); and anti-discrimination laws on minority employment (@hahn1999evaluating). -->

<!-- We've discussed a "sharp" regression discontinuity design in which all units above the threshold were treated and all units below were untreated. In fuzzy regression discontinuity designs, some units above the cutoff remain untreated or some units below take treatment. This setting is analogous to experiments that experience noncompliance and may require instrumental variables approaches to the answer strategy. -->

<!-- Geographic regression discontinuity designs use distance to a border as the running variable: units on one side of the border are treated and units on the other are untreated. @keele2016natural use such a design to study whether voters are more likely to turn out when they have the opportunity to vote directly on legislation on so-called ballot initiatives. A complication of this design is how to measure distance to the border in two dimensions. -->

<!-- - @sekhon2016understanding -->
<!-- - @delacuesta2016 -->

