---
title: "Structural estimation"
output: html_document
bibliography: ../../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

<!-- make sure to rename the section title below -->

```{r structural-estimation, echo = FALSE, output = FALSE, purl = FALSE, message = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.


packages <- c("bbmle")

invisible(lapply(packages, function(x) if (!require(x, character.only=T)){install.packages(x);library(x, character.only = T)}))

rm(packages)

do_diagnosis <- FALSE
sims <- 1000
b_sims <- 1000
```

```{r, echo = FALSE, include = FALSE}
library(metafor)
library(car)
```

## Structural estimation

Structural estimation is used in situations where researchers have a general model in mind for how processes work and their goal is to fit the parameters of the model. With the fitted model they might then estimate levels of unobserved variables, treatment effects, or other quantities. They might even extrapolate to estimate counterfactual quantities, such as the effects of interventions that have not been implemented [@reiss2007structural]. 

We illustrate using an example of a model of bargaining between pairs of players, drawing on an example use in  @wilke2020field. 

@wilke2020field imagine a bargaining game with payments from customer $i$ to a taxi driver given by:

$$\pi_i =  \theta_i(z_iy + (1-z_i)(1-y)) + (1-\theta_i)\chi$$

Here  $y = \sum_{j = 2}^n(-1^{j})\delta^{j-1}$ is the equilibrium offer made by the first mover as predicted by the @rubinstein1982perfect alternating offers bargaining model with $n$ possible bargaining rounds given discount factor  $\delta$. The  customer's payoff  depends on whether she goes first ($z_i = 1$) or second ($z_i = 0$). Non-rational customers ($\theta_i = 0$) do not engage in bargaining but successfully invoke a norm, insisting on giving the driver some share $\chi$ of their endowment, irrespective of whether they go first or second. We let $q$ denote the probability that $\theta = 1$.

To allow for a disturbance we assume that *measured* payments are a draw from a Beta distribution with expectation given by the expected payment and variance parameterized by $\kappa$. 

We imagine that $Z$ is randomly assigned and we have access to data on payments, $\pi$. We will also assume we know price $\chi$. Our goal however is not simply to measure the effect of $Z$ on $\pi$ but to estimate the model parameters, $q$,  $\delta$, $\kappa$, which themselves can be used to estimate this effect and other counterfactual quantities (if we assume the model is true).

### Design

-  **M**odel. In this declaration we will assume that the data is indeed produced by a process similar to that assumed at the estimation stage. 

- **I**nquiries. Our inquiries will include parameters `k`, `d`, and `q` corresponding to $\kappa$, $\delta$ and $q$ in the model (we will treat $\chi$ as known). In addition we will be interested in the effect of $Z$ on payments in a two period game and in the game of indefinite duration.   

- **D**ata. First mover position, $Z$, is randomly assigned. Payments are measured with some error (in this model however we cannot distinguish between measurement error and decision making error). We imagine that we have access to data from games with $n=2$ and games with $n=\infty$ in order to compare the performance of estimators in both conditions.

- **A**nalysis is implemented using maximum likelihood to identify which parameter values are most consistent with the data (which collection of parameter values produce the observed data with greatest likelihood). In this declaration the model employed in **A** is the same as that employed in **M**. We will report analysis results from both differences in means and structural estimation generated both from using the $n=2$ data (`DIM_two, Struc_two`) and from using $n=\infty$ data (`DIM_inf, Struc_inf`) 

The most complex part of the design is the specification of the estimator, shown next:

```{r}

structural_estimator <- function(data, pi, y, chi = 3/4){
  
  # Define negative log likelihood as a function of k, d and q
  LL  <- function(k, d, q) {
    m <- with(data, y(Z, d))
    R <- q * dbeta(data[pi][[1]], k * chi, k * (1- chi)) +
      (1 - q) * dbeta(data[pi][[1]], k * m, k * (1 - m))
    - sum(log(R))
  }
  
  # Estimation
  M <- mle2(
    LL,
    method = "L-BFGS-B",
    start = list(k = 2, d = 0.50,  q = 0.50),
    lower = c(k = 1,    d = 0.01,  q = 0.01),
    upper = c(k = 1000, d = 0.99,  q = 0.99)
  )
  
  # Format output from estimation
  out <- data.frame(coef(summary(M)), outcome = pi)
  
  names(out) <- c("estimate", "std.error", "statistic", "p.value", "outcome")
  
  # Use estimates of q and delta to predict average treatment effects (ATEs)
  # Predicted ATE for n=2
  out[4, 1] <- (1 - out["q", "estimate"]) * (2 * out["d", "estimate"] - 1)
  
  # Predicted ATE for n=infinity
  out[5, 1] <- (1 - out["q", "estimate"]) * (2 * out["d", "estimate"] /
                                               (1 + out["d", "estimate"]) - 1)
  
  out
}
```

The design makes use of this estimator to estimate parameter values as well as treatment effects. It is accompanied by a simpler difference in means estimator of treatment effects.

An attraction of structural estimation is that, with a fitted model, one can generate estimates of effects of treatments that have not been implemented. In this case the 
same parameters that describe the equilibrium outcomes in a two round game are sufficient to describe outcomes in the infinitely repeated game. So if you understand the effects of a treatment in one case you understand it in the other. At least if the model is correct.  In the design below we generate such estimates for the effects of unimplemented treatments. 


```{r}
# Declare the design ----------------------------------------------------------

# Define parameter values:
d = 0.8       # True delta (unknown)
k = 6         # Parameter to governance variance (unknown)
q = 0.5       # Share of behavioral types in the population (unknown)
chi = 0.75    # Price paid by norm following ("behavioral" customers) (known)

# Design declaration:

design <- 
  
  declare_model(
    
    # Define the population: indicator for behavioral type (norm = 1)
    N = 500, norm = rbinom(N, 1, q),
    
    # Define mean potential outcomes for n = 2 
    potential_outcomes(
      pi_two ~ norm*chi + (1-norm)*(Z*d + (1-Z)*(1-d))
    ),
    
    # Define mean potential outcomes for n = infinity
    potential_outcomes(
      pi_inf ~ norm*chi + (1-norm)*(Z*d/(1+d) + (1-Z)*(1-d/(1+d)))
    )
  ) +
  
  # Define estimands (quantities we want to estimate)
  declare_inquiry(ATE_two = mean(pi_two_Z_1 - pi_two_Z_0), # ATE n = 2
                  ATE_inf = mean(pi_inf_Z_1 - pi_inf_Z_0), # ATE n = infinity
                  k = k,                                   # kappa
                  d = d,                                   # delta
                  q = q) +                                 # q
  
  # Declare assignment process 
  declare_assignment(Z = complete_ra(N), legacy = FALSE) +
  
  declare_measurement(
    # Declare revealed potential outcomes
    pi_two = reveal_outcomes(pi_two ~ Z),
    pi_inf = reveal_outcomes(pi_inf ~ Z),
    
    # Get draws from beta distribution given means for n = 2 and n = infinity
    pi_two_obs = rbeta(N, pi_two*k, (1-pi_two)*k),      
    pi_inf_obs = rbeta(N, pi_inf*k, (1-pi_inf)*k)
  ) +
  
  # Declare estimators
  # Difference-in-means for n = 2
  declare_estimator(pi_two_obs ~ Z, inquiry = "ATE_two", label = "DIM_two") +
  
  # Difference-in-means for n = infinity
  declare_estimator(pi_inf_obs ~ Z, inquiry = "ATE_inf", label = "DIM_inf") +
  
  # MLE for n = 2
  declare_estimator(handler = tidy_estimator(structural_estimator), 
                    pi = "pi_two_obs", 
                    y = function(Z, d) Z * d + (1 - Z) * (1 - d), 
                    inquiry = c("k","d", "q", "ATE_two", "ATE_inf"), 
                    label = "Struc_two") +
  
  # MLE for n = infinity
  declare_estimator(handler = tidy_estimator(structural_estimator),
                    pi = "pi_inf_obs", 
                    y = function(Z, d) Z*d/(1+d) +  (1-Z)*(1-d/(1+d)),
                    inquiry = c("k","d","q","ATE_two", "ATE_inf"), 
                    label = "Struc_inf") 
```


```{r, echo = FALSE, eval = do_diagnosis & !exists("do_bookdown")}
diagnosis <- diagnose_design(design, sims = sims, bootstrap_sims = b_sims) 
```


```{r, echo = FALSE, purl = FALSE}
# figure out where the dropbox path is, create the directory if it doesn't exist, and name the RDS file
rds_file_path <- paste0(get_dropbox_path("structural"), "/humphreys_wilke.RDS")
if (do_diagnosis & !exists("do_bookdown")) {
  write_rds(diagnosis, path = rds_file_path)
}
diagnosis <- read_rds(rds_file_path)
```

Now for the diagnosis. 
```{r structuraldiagnosis, echo = FALSE}
diagnosis %>%
  reshape_diagnosis() %>%
  select(-Coverage, -'Mean Se', - 'N Sims', - 'Type S Rate', - Term) %>%
  kable(digits = 3, booktabs = TRUE, caption = "Complete random sampling design diagnosis")
```

We see here that we do a good job in recovering parameter values and we also recover treatment effects. When using two period data the estimate for the `ATE_two` is as good when estimated using the structural and design based approaches. In the case with data from $n=\infty$ games however the estimate from the structural model is less precise, though unbiased. In contrast we have no estimate using design based methods for this estimand. Finally, $\delta$, we see, is better estimated using data from the 2 period games; the estimate for $\kappa$ is biased though the bias is small.


### Exercises

- Declare and diagnose a version of this design where the benchmark model is different to the analysis model. How do you define parameter estimands in this case?
