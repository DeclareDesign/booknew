---
title: "Designs encountering noncompliance"
output: html_document
bibliography: ../../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

<!-- make sure to rename the section title below -->

```{r encouragement, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```


## Designs encountering noncompliance

- designs with noncompliance
- encouragement designs
- placebo-controlled design (note one part is measurement one half is causal)


Experiments encounter noncompliance when treatment *status* differs from treatment *assignment*. A common form of noncompliance is one-sided noncompliance, which occurs when some units in the assigned treatment group fail to take treatment and all units in the control group remain untreated. One-sided noncompliance is common when experimenters "do nothing" to the control group but try (and sometimes fail) to deliver treatment to the treatment group.  

Any time a data strategy entails contacting subjects in order to deliver a treatment like a bundle of information or some good, noncompliance is a potential problem. Emails go undelivered, unopened, and unread. Letters get lost in the mail. Phone calls are screened, text messages get blocked, DMs are ignored. People don't come to the door when you knock, either because they aren't home or they don't trust strangers. 

Experimenters who anticipate noncompliance should make compensating adjustments to their research designs (relative to the canonical two arm design). These adjustments ripple through M, I, D, and A. 

The biggest change to M is developing beliefs about compliance types, also called "principal strata" (cite rubin). In a two-arm trial, subjects can be one of four compliance types, depending on how their treatment status responds to their treatment assignement. The four types are described in Table XXX. $D_i(Z = 0)$ is a potential outcome -- it is the treatment status that unit $i$ would express if assigned to control. Likewise, $D_i(Z = 1)$ is the treatment status that unit $i$ would express if assigned to treatment. These potential outcomes can take each take on a value of 0 or 1, so their intersection allows for four types.  For Always-takers, $D_i$ is equal to 1 regardless of the value of $Z$ -- they always take treatment. Never-takers are the opposite -- $D_i$ is equal to 0 regardless of the value of $Z$. For Always-takers and Never-takers, assignment to treatment *does not change* whether they take treatment. 

Compliers are units that take treatment if assigned to treatment and do not take treatment if assigned to control. Their name "compliers" connotes that someething about their disposition as subjects makes them "compliant" or otherwise docile, but this connotation is misleading. Compliance types are generated by the confluence of subject behavior and data strategy choices. Whether or not a subject answers the door when the canvasser comes calling is at least in part a function of whether the subject is at home. Data strategies that attempt to deliver treatment in the evenings and on weekends might generate more (or different) compliers than those that attempt treatment during working hours.


| Compliance Type | $D_i(Z = 0)$  | $D_i(Z = 1)$  |
| --------------- | ------------- | ------------- |
| Always-taker    | 1             | 1             |
| Complier        | 0             | 1             |
| Defier          | 1             | 0             |
| Never-taker     | 0             | 0             |

The last compliancce type to describe are defiers. These strange birds refuse treatment when assigned to treatment, but find a way to obtain treatment when assigned to control. Whether or not "defiers" exist turns out to be a consequential assumption that must be made in the model. We have good reason to believe that defiers are rare -- assignment to treatment almost always has a positive average effect on treatment take-up, and we are aware of no cases in which assignment caused a decrease in take-up, even among a subgroup.

Without further assumptions, we can never be sure of any unit's compliance type. Subjects assigned to the control group who take take treatment ($D_i(0) = 1$) could be defiers or always-takers. Subjects assigned to the treatment group who do not take treatment ($D_i(1) = 0$) could be defiers or never-takers. Our inability to be sure of compliance types is another facet of the fundamental problem of causal inference. Even though a subject's compliance type (with respect to a given design) is a stable trait, it is defined by how the subject would act in multiple counterfactual worlds. We can't tell what type a unit is because we would need to see whether they take treatment when assigned to treatment and when assigned to control. 

The inclusion of noncompliance and compliance types to the model also necessitate changes to the inquiry. Always-takers and Never-takers present a real problem for causal inference. Even with the power to randomly assign, we can't change what treatments these units take. As a result, *we don't get to learn* about the effects of treatment among these groups. Even if our inquiry were the average effect of treatment among the never-takers, the experiment (as designed) would not be able to generate emprical estimates of it.^[We write "as designed" because compliance types are defined with respect to a particular design. If it were possible to induce the never-takers to take treatment (i.e., under a different data strategy, these units might be compliers), this inquiry would not *necessarily* be out of reach.] Our inquiry has to fall back to the average effects among those units that whose treatment status we can successfully manipulate -- the compliers.

We call this inquiry the complier average causal effect (the CACE). It is mathematically identical to the local average treatment effect (LATE) described in chapter XXX. Whether we write CACE or LATE sometimes depends on academic discipline, 







### Declaration

```{r}
direct_effect_of_encouragement <- 0.0
proportion_defiers <- 0.0

design <-
  declare_population(
    N = 100,
    type = sample(
      x = c("Always-Taker", "Never-Taker", "Complier", "Defier"),
      prob = c(0.1, 0.1, 0.8, 0.0),
      size = N, replace = TRUE
    ),
    U = rnorm(N)
  ) +
  declare_potential_outcomes(
    D ~ case_when(
      Z == 1 & type %in% c("Always-Taker", "Complier") ~ 1,
      Z == 1 & type %in% c("Never-Taker", "Defier") ~ 0,
      Z == 0 & type %in% c("Never-Taker", "Complier") ~ 0,
      Z == 0 & type %in% c("Always-Taker", "Defier") ~ 1
    )
  ) +
  declare_potential_outcomes(
    Y ~ 0.5 * (type == "Complier") * D +
      0.25 * (type == "Always-Taker") * D +
      0.75 * (type == "Defier") * D +
      # Building in NO excludability violation
      0 * Z + U,
    assignment_variables = c("D", "Z")
  ) +
  declare_estimand(CACE = mean(Y_D_1_Z_1 - Y_D_0_Z_0),
                   subset = type == "Complier") +
  declare_assignment(prob = 0.5) +
  reveal_outcomes(D, assignment_variable = "Z") +
  reveal_outcomes(Y, assignment_variables = c("D", "Z")) +
  declare_estimator(Y ~ D | Z, model = iv_robust, estimand = "CACE")
```

### DAG

```{r, echo = FALSE}
dag <- dagify(Y ~ D + type + U,
              D ~ Z + type + U,
              type ~ U)

nodes <-
  tibble(
    name = c("Z", "D", "U", "Y", "type"),
    label = c("Z", "D", "U", "Y", "C"),
    annotation = c(
      "**Random assignment**",
      "**Treatment received**",
      "**Unknown heterogeneity**",
      "**Outcome**",
      "**Principal stratum**<br>Compliance type"
    ),
    x = c(1, 3, 4, 5, 2),
    y = c(1, 1, 4, 1, 4),
    nudge_direction = c("S", "S", "N", "S", "N"),
    data_strategy = c("assignment", "unmanipulated", "unmanipulated", "unmanipulated", "unmanipulated"),
    answer_strategy = "uncontrolled", 
  )

ggdd_df <- make_dag_df(dag, nodes)

base_dag_plot %+% ggdd_df
```

### Example

To do: demonstrate how violations of no defiers and excludability leads to bias.

```{r}
types <- c("Always-Taker", "Never-Taker", "Complier", "Defier")
direct_effect_of_encouragement <- 0.0
proportion_defiers <- 0.0

design <-
  declare_population(
    N = 500,
    type = sample(
      types,
      N,
      replace = TRUE,
      prob = c(0.1, 0.1, 0.8 - proportion_defiers, proportion_defiers)
    ),
    noise = rnorm(N)
  ) +
  declare_potential_outcomes(
    D ~ case_when(
      Z == 0 & type %in% c("Never-Taker", "Complier") ~ 0,
      Z == 1 & type %in% c("Never-Taker", "Defier") ~ 0,
      Z == 0 & type %in% c("Always-Taker", "Defier") ~ 1,
      Z == 1 & type %in% c("Always-Taker", "Complier") ~ 1
    )
  ) +
  declare_potential_outcomes(
    Y ~ 0.5 * (type == "Complier") * D +
      0.25 * (type == "Always-Taker") * D +
      0.75 * (type == "Defier") * D +
      direct_effect_of_encouragement * Z + noise,
    assignment_variables = c("D", "Z")
  ) +
  declare_estimand(CACE = mean((Y_D_1_Z_1 + Y_D_1_Z_0) / 2 -
                                 (Y_D_0_Z_1 + Y_D_0_Z_0) / 2),
                   subset = type == "Complier") +
  declare_assignment(prob = 0.5) +
  reveal_outcomes(D, assignment_variable = "Z") +
  reveal_outcomes(Y, assignment_variables = c("D", "Z")) +
  declare_estimator(Y ~ D | Z, model = iv_robust, estimand = "CACE")

```

```{r, eval = do_diagnosis & !exists("do_bookdown")}
designs <- redesign(
  design,
  proportion_defiers = seq(0, 0.3, length.out = 5),
  direct_effect_of_encouragement = seq(0, 0.3, length.out = 5)
)

simulations_df <- simulate_design(designs, sims = sims)
```

```{r, echo = FALSE, purl = FALSE}
# figure out where the dropbox path is, create the directory if it doesn't exist, and name the RDS file
rds_file_path <- paste0(get_dropbox_path("04_Encouragement_Designs.Rmd"), "/simulations_df.RDS")
if (do_diagnosis & !exists("do_bookdown")) {
  write_rds(simulations_df, path = rds_file_path)
}
simulations_df <- read_rds(rds_file_path)
```


```{r, echo = FALSE}
gg_df <-
  simulations_df %>%
  group_by(proportion_defiers,
           direct_effect_of_encouragement) %>%
  summarize(bias = mean(estimate - estimand))

ggplot(gg_df,
       aes(
         proportion_defiers,
         bias,
         group = direct_effect_of_encouragement,
         color = direct_effect_of_encouragement
       )) +
  geom_point() +
  geom_line() + 
  dd_theme() + 
  theme(legend.position = "bottom")
```





