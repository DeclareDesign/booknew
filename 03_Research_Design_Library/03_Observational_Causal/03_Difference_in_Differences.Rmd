---
title: "Difference-in-differences"
output: html_document
bibliography: ../../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

## Difference-in-differences

### Declaration

```{r}

design <- 
  declare_population(
    unit = add_level(N = 2, X = rnorm(N, sd = 0.5)),
    period = add_level(N = 2, nest = FALSE),
    unit_period = cross_levels(by = join(unit, period), U = rnorm(N, sd = 0.01))
  ) + 
  declare_potential_outcomes(Y ~ X + 0.5 * as.numeric(period) + Z + U) + 
  declare_estimand(ATE = mean(Y_Z_1 - Y_Z_0), subset = period == 2) + 
  declare_step(Z = X == max(X), handler = mutate) + 
  reveal_outcomes(Y = if_else(Z == 0 | period == 1, Y_Z_0, Y_Z_1), handler = mutate) +
  declare_estimator(Y ~ Z * period, model = lm_robust, se_type = "none")
```

### Dag


```{r, echo=FALSE}
dag <- dagify(Y ~ X + period + Z + U,
              Z ~ X)


nodes <-
  tibble(
    name = c("U", "X", "period", "Z", "Y"),
    label = c("U", "X", "T", "Z", "Y"),
    annotation = c(
      "**Unknown heterogeneity**",
      "**Unit effect**",
      "**Time period**",
      "**Treatment assignment**",
      "**Outcome variable**"
    ),
    x = c(5, 1, 1, 3, 5),
    y = c(1.5, 3.5, 1, 2.5, 2.5),
    nudge_direction = c("S", "N", "S", "S", "N"),
    answer_strategy = "uncontrolled"
  )

ggdd_df <- make_dag_df(dag, nodes, design)

base_dag_plot %+% ggdd_df
```

### Example


```{r difference_in_difference, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 1000
b_sims <- 1000
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```

### Two-period two-group setting

- Show that comparison of T and C in period 2 is biased and comparison of T between period 1 and 2 is biased, but DiD unbiased in presence of confounding in treatment assignment (unit with higher unit shock is always treated) and time trends

```{r}
N_units <- 2
N_time_periods <- 2

two_period_two_group_design <- 
  
  declare_population(
    units = add_level(N = N_units, unit_shock = rnorm(N, sd = 0.5)),
    periods = add_level(N = N_time_periods, nest = FALSE,
                        time = (1:N_time_periods) - N_time_periods + 1),
    unit_period = cross_levels(by = join(units, periods), unit_time_shock = rnorm(N, sd = 0.01))
  ) + 
  
  # internal note: the unbiasedness obtains whether or not there is a unit-time shock
  declare_potential_outcomes(
    Y_Z_0 = unit_shock + 0.5 * time + unit_time_shock, # common pretreatment trend
    Y_Z_1 = Y_Z_0 + 1) +
  
  declare_estimand(ATE = mean(Y_Z_1 - Y_Z_0), subset = time == 1) + 
  
  declare_assignment(Z = unit_shock == max(unit_shock), handler = mutate) + 
  
  reveal_outcomes(
    Y = case_when(Z == 0 | time < 1 ~ Y_Z_0, TRUE ~ Y_Z_1), handler = mutate) +
  
  declare_estimator(estimate = (mean(Y[Z == 1 & time == 1]) - mean(Y[Z == 0 & time == 1])) -
                      (mean(Y[Z == 1 & time == 0]) - mean(Y[Z == 0 & time == 0])),
                    estimator_label = "DiD", handler = summarize, label = "DiD") +
  
  declare_estimator(estimate = mean(Y[Z == 1 & time == 1]) - mean(Y[Z == 1 & time == 0]),
                    estimator_label = "Diff", handler = summarize, label = "Over-Time") +
  
  declare_estimator(estimate = mean(Y[Z == 1 & time == 1]) - mean(Y[Z == 0 & time == 1]),
                    estimator_label = "DiM", handler = summarize, label = "DiM")
```

```{r, eval = do_diagnosis & !exists("do_bookdown")}
diagnosis_two_period_two_group <- diagnose_design(
  two_period_two_group_design, diagnosands = declare_diagnosands(select = bias),
  sims = sims, bootstrap_sims = b_sims)
```

```{r, echo = FALSE, purl = FALSE}
# figure out where the dropbox path is, create the directory if it doesn't exist, and name the RDS file
rds_file_path <- paste0(get_dropbox_path("difference_in_differences"), "/diagnosis_two_period_two_group.RDS")
if (do_diagnosis & !exists("do_bookdown")) {
  write_rds(diagnosis_two_period_two_group, path = rds_file_path)
}
diagnosis_two_period_two_group <- read_rds(rds_file_path)
```

```{r}
kable(get_diagnosands(diagnosis_two_period_two_group))
```

### Parallel trends assumption

- Introduce assumption and visual test

```{r}
# add an additional pretreatment time period in order to visually test for parallel pre-trends
three_period_two_group_design <- redesign(two_period_two_group_design, N_time_periods = 3)
```

```{r}
draw_data(three_period_two_group_design) %>% 
  group_by(Z, time) %>% 
  summarize(Y = mean(Y)) %>% 
  mutate(Z_color = factor(Z, levels = c(FALSE, TRUE), labels = c("Untreated", "Treated"))) %>% 
  ggplot(aes(time, Y, color = Z_color)) + 
  geom_line() + 
  scale_color_discrete("") +
  scale_x_discrete("Time", limits = c(-1, 0, 1))
```

- Formal test (DID on T = -1 and T = 0 periods, i.e. a year backward from the DiD)
- There is a result that shows that the two-step procedure of the parallel trends assumption then DID if test passes that shows poor coverage of SEs in final DID (https://arxiv.org/abs/1804.01208). Cite here.

### Multi-period design

- Switch to regression context with 20 periods, 100 units and show same results hold with two-way FE (controlling for one period before T is insufficient to remove bias)

```{r}
N_units <- 20
N_time_periods <- 20

multi_period_design <- 
  
  declare_population(
    units = add_level(N = N_units, 
                      unit_shock = rnorm(N), 
                      unit_treated = 1*(unit_shock > median(unit_shock)), 
                      unit_treatment_start = 
                        sample(2:(N_time_periods - 1) - N_time_periods + 1, N, replace = TRUE)),
    periods = add_level(N = N_time_periods, nest = FALSE, 
                        time = (1:N_time_periods) - N_time_periods + 1),
    unit_period = cross_levels(by = join(units, periods),
                               noise = rnorm(N), 
                               pretreatment = 1*(time < unit_treatment_start))
  ) + 
  
  declare_potential_outcomes(
    Y_Z_0 = unit_shock + 0.5 * time + noise, # common pretreatment trend
    Y_Z_1 = Y_Z_0 + 0.2) +
  
  declare_estimand(ATE = mean(Y_Z_1 - Y_Z_0), subset = time == 1) + 
  
  declare_assignment(Z = 1*(unit_treated & pretreatment == FALSE), handler = fabricate) + 
  reveal_outcomes(Y, Z) + 
  
  declare_estimator(Y ~ Z + time, fixed_effects = ~ units + periods, 
                    model = lm_robust, label = "twoway-fe", estimand = "ATE") 
  
```

```{r, eval = do_diagnosis & !exists("do_bookdown")}
diagnosis_multi_period_multi_group <- diagnose_design(multi_period_design, diagnosands = declare_diagnosands(select = bias), sims = sims, bootstrap_sims = b_sims)
```

```{r, echo = FALSE, purl = FALSE}
# figure out where the dropbox path is, create the directory if it doesn't exist, and name the RDS file
rds_file_path <- paste0(get_dropbox_path("difference_in_differences"), "/diagnosis_multi_period_multi_group.RDS")
if (do_diagnosis & !exists("do_bookdown")) {
  write_rds(diagnosis_multi_period_multi_group, path = rds_file_path)
}
diagnosis_multi_period_multi_group <- read_rds(rds_file_path)
```

```{r}
kable(get_diagnosands(diagnosis_multi_period_multi_group))
```

- Show that in case where some units switch back and forth between T and C during panel there is bias (point to Imai and Kim appear with weighted FE estimator to fix this)



