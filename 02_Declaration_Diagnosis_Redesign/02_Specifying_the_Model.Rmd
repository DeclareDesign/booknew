---
title: "Specifying the model"
output:
  html_document:
    toc: true
    toc_depth: 2
---

<!-- note do_bookdown is set in index.rmd, so we know if you are running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

# Specifying the model

<!-- make sure to rename the section title below -->

```{r specifying_the_model, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
library(dagitty)
library(dddag)
library(ggraph)
```

Any research design -- whether the research question is fundamentally causal or descriptive -- implicitly relies on a causal model of the world. These models include beliefs about what variables are important and how they interrelate. Even if the model is hazy, researchers carry with them a model of the world that could in principle be expressed as a probablistic causal model. As described in the previous chapter, probabalistic causal models are described by a set of exogeneous and endogenous variables, a set of functional relationships between the variables, and a probability distribution over the exogenous variables. 

In order to design a strong research study, we need to introspect about our causal beliefs. We need to make the explicit the design-relevant features of the implicit causal models in our heads. This chapter is about how to go about this difficult task. 

We'll make use of two different formal languages for describing causal models: DAGs and potential outcomes. DAGs are "directed acyclic graphs," where each node on a graph is a variable and the edges that connect them represent causal effects. DAGs emphasize a mechanistic notion of causality: when the exposure variable changes, the outcome variable changes as a result. DAGs are *nonparametric*. This means that they do not encode all the beliefs about the full causal model. They don't show *how* variables are related, just *that* they are related.

The potential outcomes formalization emphasizes a counterfactual notion of causality. $Y_i(Z = 0)$ is the outcome for unit $i$ when the causal variable equal to zero and $Y_i(Z = 1)$ is the outcome when it is set to one. The difference between them is the effect of the treatment on the outcome for unit $i$. Since at most only one potential outcome can ever be revealed, at least one of the two potential outcomes is necessarily counterfactual. Usually, the potential outcomes function $Y_i()$ has just one argument -- $Z$ -- because it elides all other determinants of the outcome to focus only on the outcome that would occur depending on the level of the main causal variable of interest.

Despite what you may have inferred from the sometimes heated disagreements between scholars who prefer one formalization to the other, DAGs and potential outcomes are compatible systems for thinking about causality. We *could* use only the language of causal graphs or we *could* use only the language of potential outcomes. We choose to use both languages because they are useful for expressing different facets of research design. We use DAGs to describe the web of causal interrelations in a concise way (writing out the potential outcomes for every relationship in the model is tedious). We use potential outcomes when we want to zoom in on *particular* causal relationships and to make fine distinctions between inquiries that apply to different sets of units (it's difficult to describe effect heterogeneity with graphical models). 

## What variables belong in the causal model?

Ultimately our goal as researchers is to learn more and more about how the world works or in other words, to fill in more and more of a large causal model. There are an infinite number of nodes and edges in this model --- from how people vote to how they save and spend money to how they find romantic partners, all of which are interrelated. However, social science has not yet filled in much of the model yet. Thankfully, in order to declare a research design and learn about it, we don't need to specify every part of the world's causal model. 

The variables that we need to specify in $M$ are those we will need in the latter three elements in our research design: our inquiry $I$, data strategy $D$, and answer strategy $A$. 

In order to reason about whether the data we collect will be able to provide an answer to our inquiry, we need to define all of the variables used to construct our inquiry. In descriptive research, this will mean the variables we will summarize. In causal research, this will mean the potential outcomes under different states of the world, such as treatment and control. For example, if we are studying the effects of a voter mobilization campaign on vote choice between the three candidates running in a primary election, we should define a vote choice variable and the values it takes on in two circumstances: in the presence of the voter mobilization campaign (treatment) and without it (control). 

The data strategy --- sampling, treatment assignment, and measurement --- defines many of the variables we need to specify in the model. Sampling procedures often involve stratification (e.g., sampling equal proportions of men and women), clustering (e.g., sampling all of the individuals in a household to participate in the research), or both. In the model, we need to define the variables that will be used to stratify and cluster. Similarly, treatment assignment can involve assigning treatments within blocks and cluster assignment where all units are assigned to the same status. The variables that are used to construct blocks and that will form clusters will be defined in the model. Finally, all of the variables that will be measured should also be defined in the model. When we measure latent variables imperfectly, for example sensitive questions where a true characteristic exists but respondent do not always admit it, we should define both the latent trait and measured responses.

Finally, answer strategies rely on collected data to provide an answer to the inquiry, and so any variable in the collected data should be defined in the model. (Any of these variables should also be defined in the measurement strategy.) Beyond outcomes and treatment variables, we may need variables to define clusters used in clustered standard errors, to construct weights for poststratification of estimates to match population characteristics, and to visualize our data.

In addition to defining these variables, we need to know how they relate to each other. We define a set of nonparametric structural causal relationships. With these variables at hand, we can define a nonparametric structural causal model and visualize the model using a directed acyclic graph. 

We illustrate using a DAG to describe a model with an abstract research design in which we will collect information about $N$ units. We will measure a pretreatment covariate $X$, assign a treatment at random $Z$, and collect a posttreatment outcome $Y$. We know there are other determinants of the outcome beyond $Z$ and $X$, but we don't need to write down our beliefs about them because our main inquiry is the average treatment effect of $Z$ on $Y$. All we'll say about those other deteriminants is that they are causally related to both $X$ and $Y$, but not to $Z$, since $Z$ will be randomly assigned by us. Following the rule that we only need to make explicit the parts of our causal model that are required for the inquiry, data strategy, and answer strategy, this bare specification is sufficient. 

The nonparametric structure causal model can be written like this:

\begin{align*}
X &= f_X(U)\\
Y &= f_Y(Z, X, U)
\end{align*}

This DAG encodes this model in graphical form:

```{r, echo = FALSE}
a_blue <- "#0072B2"
a_gray <- "grey80"

dag <-
  dagify(Y ~ X + Z + U,
         X ~ U,
         latent = "U")

gg_df <-
  tidy_dagitty(dag,
               layout = "manual",
               x = c(1, 0, -1, 1),
               y = c(1, 1, 0, 0))

gg_df <-
  gg_df %>%
  mutate(
    color = case_when(
      name == "U" ~ a_gray,
      name == "X" ~ a_blue,
      name == "Y" ~ a_blue,
      name == "Z" ~ a_blue
    )
  )


g <- 
ggplot(gg_df, aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_node(aes(color = color)) +
  scale_color_identity() +
  geom_dag_text(color = "black", family = "Helvetica") +
  geom_dag_edges() +
  theme_dag()

g
```

Possibly the most important thing that a DAG can teach us is which research questions are even answerable in a given setting by applying the "back-door criterion," which asks whether a back-door path exists between a pair of causally-related variables. Here, the causal relationship between $X$ and $Y$ is confounded by the back-door path $X <- U -> Z$. (for much more on the back-door criterion, see XXX). Since we have no information about what is in $U$, we can't learn about the effects of $X$ on $Y$. However, the treatment variable $Z$ has no edges leading in to it, which represents the idea that $Z$ is randomly assigned. There are no back door paths leading from $Z$ to $Y$, so we *can* learn about average causal effects of Z on Y. We could also draw descriptive inferences about the distributions of the observed variables like their ranges and averages or their variances and covariances.

## What do we need to specify about these variables?

DAGs convey beliefs about whether *whether* two variables are causally related, but they do not encode beliefs about *how* they are related. This is no criticism of DAGs --- they just don't encode all of our causal beliefs about a system. However, in order to assess many properties of a research design we need to go further. We need to specify the scales and probability distribution of exogenous variables and the functional forms of the endogenous variables (how they relate to parent variables). This will include incorporating beliefs about effect sizes, but also correlations between variables, intra-class correlations (ICCs), and interactions. All of this to say: in order to declare and diagnose our designs, we'll need to make the leap from nonparametric models to *parametric* structural causal models. This move is not without costs -- each specific choice we make over and above the nonparametric model is an opportunity to be more wrong about the world!

Suppose that according to our model, the effect of treatment should be larger for units with $X = 1$. We can encode this belief in a design declaration. In the `declare_population` function, we write that $U$ is normally distributed with mean 0 and standard devation 1; $X$ follows a bernoulli distribution but units have a probability of $X$ equalling one that depends on $U$ in a particular way. In the `declare_potential_outcomes` function, we describes how the average effect of treatment is 0.5 when $X = 0$ but 0.5 + 0.5 = 1 when $X = 1$. 

```{r}
diff_in_cates <- 0.5
design <-
  declare_population(N = 100,
                     U = rnorm(N),
                     X = rbinom(N, 1, prob = pnorm(0.5 * U + rnorm(N)))) +
  declare_potential_outcomes(Y ~ 0.5 * X + 
                               0.5 * Z + 
                               diff_in_cates * X * Z + 
                               0.5 * U)
```

We could incorporate different beliefs about the causal model by changing the `diff_in_cates` parameter. However, notice that regardless of the value of the interaction (either zero or some other number), the DAG looks the same. So if you want to design your study for the difference-in-CATEs, then you'll need to go beyond the DAG to write down your beliefs about the extent of heterogeneity using another tool -- design declaration complements DAGs in this specific way.

<!-- - some of these variables will be exogenous and endogenous, in Pearl's terms. by exogenous variables, he means variables without parents, no antecendent causes. by endogenous variables, he means those with parents, that are determined in part by earlier variables. endogenous variables are distinct from the problem of endogeneity, which comes from a single variable being a parent of both the treatment variable of interest and the outcome we wish to measure the causal effect of the treatment on. we will use it in Pearl's sense. -->


## How do we make educated guesses about the set of nodes and edges and their parameters and functional forms?

<!-- I think this material should be the top of this section! -->


<!-- must define: -->
<!-- - probability distributions for exogenous variables and their parameters -->
<!-- - functional forms of the endogenous variables -->

The content of models typically comes from two places: reading the past literature and qualitative research. Past theoretical work can guide the set of nodes that are relevant and how they are connected by edges. Past empirical work can provide further insight on the set of edges that exist (or do not). However, when past research is thin on a topic, there is no substitute for insights gained through qualitative data collection: focus groups and interviews with key informants who know aspects of the model that are hidden to the researcher; archival investigations to understand how to draw understand a causal process when the actors in it are no longer alive, or to gain insights only contained in administrative records; and immersive participant observation to see with your eyes how social actors behave. Fenno (1982) calls this "soaking and poking." This mode of inquiry, discovery, is separate from the qualitative research designs that provide an answer to an inquiry deductively. We examine those throughout the book (particular examples are in library entry XX and YY). Instead, qualitative insights such as this, which Lieberman (2005) labels "model-building" case studies, do not aim to answer a question but rather yield a new theoretical model. Quantitative research is often seen as distinct from qualitative research, but the model building phase in both is itself qualitative.

- In specifying the parameters of the probability distributions of exogenous variables and the functional forms of exogenous variables, we will often turn to a specific set of tools for summarizing past research: meta-analysis, to obtain guesses for specific parameters (issue of finding overlap in treatments, contexts, outcomes, and participants)

- Where the literature is thin for a given parameter or functional form, we may also collect new quantitative data in pilot studies (will only want to use estimates of standard errors, not for effect sizes).

- We may also draw on past data or baseline and either rely on it as the basis of our model -- taking it as fixed -- or resampling from it if it does not represent observations of our target units.

## Robustness to multiple models

- the result of this search through past research will often not yield a single point estimate for a parameter, such as the correlation between age and gender, but rather a range.
- we face fundamental uncertainty in all our guesses about features of the model (this is why we are conducting the research in the first place!)
- this is not a bug but a feature of this process: we can retain our uncertainty and find data strategies and answer strategies that provide unbiased, efficient estimates of our inquiry under *multiple* possible models. when our procedures yield "good" estimates of our inquiry under a range of models, we label the design robust to multiple models. we will typically want our design to be robust to multiple possible large and small effect sizes, but also multiple possible intra-class correlations within clusters and levels of uncertainty from unknown forms of heterogeneity.
- robustness to alternative models: we may want to know how good a design is under a hypothesized model of the world and an alternative model posited in the literature. here, we want to know if our design can *distinguish* between these two designs. our inquiry may be which of the two models is correct.

## Fundamental uncertainty

Models are *models* -- they are abstractions and they are not the truth! The true causal structure of the world $W$ generates draws from the world $w$. The inquiry $I$ might not even defined under $W$, that is $I(w)$ might be $NA$. Applying the data strategy $D$ to $w$ might produce unexpected results. That is $D(w)$ need not be anything like $D(m)$. This disjuncture is unavoidable and is in large part, the whole point of doing research in the first place. We do not know $W$ -- that would require omniscience. We have learned parts of $W$ and put them in $M$ -- that's science. When research produces unexpected results, it's an indication that something in MIDA is out of whack and it is an opportunity for learning. The *next* research project will amend MIDA in order to bring $M$ closer to $W$.

