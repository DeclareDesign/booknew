---
title: "Defining the inquiry"
output:
  html_document:
    toc: true
    toc_depth: 2
bibliography: ../bib/book.bib
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

<!-- make sure to rename the section title below -->

```{r defining_the_inquiry, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```


```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
library(dagitty)
```

# Defining the inquiry

An inquiry is a summary of a reference model. Suppose in your reference model that $D$ possibly affects $Y$. Using the framework provided in @pearl2018book, one inquiry might be descriptive, or associational: what is the average level of $Y$ when $D=1$? A second might be about the effects of interventions: what is the average treatment effect of $D$ on $Y$? A third is about counterfactuals: for what share of units would $Y$  have been different if $D$ were different?  If a theory involves more variables, many more questions open up, for instance regarding how the effect of one variable passes through, or is modified by, another. 

Your inquiry is your research question. Simple or complex, causal or descriptive, your inquiry can be thought of as a summary of a data generating process. Like models, inquiries---the questions you ask---are themselves theoretical objects. It is easy to confuse  inquiries and the output of answer strategies. If our theory posits the existence of an Average Treatment Effect, we might use an answer strategy like difference-in-means to estimate it, but the estimate is fundamentally distinct from the inquiry. Estimates are empirical, inquiries are theoretical.

<!-- Is the estimate from simulated data empirical? -->

In general, an inquiry is a summary function $I$ that operates on an instance of a model $m \in M$.^[Recall we are thinking here of $M$ as a class of models with element $m$. If the model class has only one element then $m=M$. ] When we summarize the model with the inquiry, we obtain an "answer under the model." We formalized this as $I(m) = a^m$. You can think of the difference between $I$ and $a^m$ as the difference between a question and its answer. $I$ is the question we ask about the model and $a^m$ is the answer. Alternatively, you can think of $I$ as the "estimand" (that which is to be estimated) and $a^m$ as the value of the estimand.  

<!-- I'm getting tripped up by I being the estimand. In APSR we say a^m is what we want to estimate. I think we don;t want to estimate I -- I is a function, we want to estimate a^m-->

In this book when we talk about inquiries, we will usually be referring to single-number summaries of models. Some common estimands are descriptive, such as the means, conditional means, correlations, partial correlations, quantiles, and truth statements about variables in the model. Others are causal, such as the average difference in one variable when a second variable is set to two different values. You can think of a single-number inquiry as the atom of the research question. 

While most inquiries are "atomic" in this way, some inquiries are more complex than a single-number summary. For example, the best linear predictor of $Y$ given $X$ is a two-number summary: it is the pair of numbers (the slope and intercept) that minimizes the total squared distance between the line and each value of $Y$. Note that this is not a *causal* estimand but it is still well defined. No need to stop at two-number summaries though. We could imagine the best quadratic predictor of $Y$ given $X$ (three-number summary), and so on. See Figure \@ref(fig:ch3polynomials). We could have an inquiry that is the full conditional expectation function of $Y$ given $X$, no matter how wiggly, nonlinear, and nuanced the shape of that function -- it could in principle be a 1,000 number summary of the model, or much more. 

<!-- MH: Is this an example of an estimand that is a function of d not m?  -->

```{r ch3polynomials, fig.width = 6.5, fig.height = 2.5, echo = FALSE, fig.cap = "Inquiries based on different numbers of parameters"}
set.seed(1)
dat <- fabricate(N = 500, X = rnorm(N), Y = 0.5 *X + -0.5 * X^2 + -0.5* X^3 + 0.05 * X^4 + rnorm(N)) %>%
  mutate(Y = Y - mean(Y))

fit_1 <- lm(Y ~ 1, data = dat)
fit_2 <- lm(Y ~ X, data = dat)
fit_3 <- lm(Y ~ X + I(X^2), data = dat)
fit_4 <- lm(Y ~ X + I(X^2) + I(X^3), data = dat)

newdata = tibble(X = seq(-3, 3, length.out = 1000))
dat1 <- newdata %>% mutate(pred = predict(fit_1, newdata))
dat2 <- newdata %>% mutate(pred = predict(fit_2, newdata))
dat3 <- newdata %>% mutate(pred = predict(fit_3, newdata))
dat4 <- newdata %>% mutate(pred = predict(fit_4, newdata))

gg_df <- bind_rows( `1` = dat1, `2` = dat2, `3` = dat3, `4` = dat4,.id = "complexity") %>%
  mutate(complexity = factor(
    complexity,
    levels = 1:4,
    labels = c(
      paste0('One number summary:\n(',paste(round(coef(fit_1), 2)), ")"),
      paste0('Two number summary:\n(', paste(round(coef(fit_2), 2), collapse = ", "), ")"),
      paste0('Three number summary:\n(', paste(round(coef(fit_3), 2), collapse = ", "), ")"),
      paste0('Four number summary:\n(', paste(round(coef(fit_4), 2), collapse = ", "), ")")
    )
  ))

ggplot(gg_df, aes(X, pred)) +
  geom_line(color = "blue") +
  facet_wrap(~complexity, nrow = 1) +
  geom_point(data = dat, aes(X, Y), stroke = 0, alpha = 0.1) +
  coord_cartesian(ylim = c(-10, 10)) + 
  theme_void()
```



And of course, it need not be a number at all: the answer to your question might be "blue" or "the normal distribution." Or it might be a set. For instance, in qualitative comparative analysis (QCA) with Boolean variables ("crisp-set QCA"), a common inquiry is: what is the minimal set of conditions sufficient to produce $Y$ [@ragin1987]. For instance, if $Y$ happens any time that causal factor $A$ is present or when $A$ is absent but $B$ is present, then $a^M$ is a set: $\{A, \neg A \& B\}$. 

It could be a set of questions about an explanatory model. For instance, a researcher might articulate a handful of important questions about the model that all have to come out a certain way or the model itself should be rejected. These complex inquires are made up of a series of atomic inquiries -- we're interested in the sub-inquiries only insofar as they help us understand the real inquiry -- is this model of the world a good one or not.

## Three families of inquiries

<!-- MH: My vote: four types of queries: the three from Pearl (descriptive, interventionist, counterfactual) plus "model" queries in which you try to learn the model. --> 
<!-- AC: Could you say more about "interventionist"? not sure I understand the difference vs. counterfactual. Also, I was thinking here that the basic distinction between descriptive and causal is the most important, "model" queries are made up of a series of sub-inquiries that themselves are either descriptive or causal. Model queries can mix both. Would that cover it?-->

<!-- MH: INterventionist would be a treatment effect; attribution is counterfactual --- imagine different to how things are. These are Pearlean usages; not a great fan since of course treatment effect requires imagining things different, though only at the population level -->

<!-- MH: Suggest a table that gives a real broad set of inquiries that people can use as a reference; ATE, LATE, PATEs, SATEs, CDEs, lots and lots. Even better if we can define most of them off a simple DAG. -->

<!-- AC: tough for one DAG, but We've got the table started now at least -->

@pearl2018book usefully describes a "ladder of causation" which can be used to categorize classes of inquiries. The bottom rung of the ladder focuses on descriptive inquiries about how the world was, is, and will be. The second rung focuses on questions about the effects of interventions: what happens to $Y$ if you do something to $X$? The third rung is about counterfactuals: How would $Y$ have been different if $X$ were different. The last two rungs  both involve causal inquiries, questions about how the world would have been, would be, or would be in the future if some variables were set to different levels. 

<!-- You might think of the distinction in terms of a DAG. Descriptive inquiries are about the nodes of a dag whereas causal inquires are about the edges.  -->

Descriptive and causal inference have in common the difficulty of inferring unseen things from observed data. The fundamental problem of causal inference is well known. Because a unit cannot simultaneously be both treated and untreated, we can only observe at most one potential outcome for any particular unit and so can never *measure* causal effects -- we have to infer them. Similar problems confront descriptive inference. The concepts we want to measure are latent constructs. A perfect measurement is generally not possible, so our measurements of the latent constructs usually include some measurement error. 
<!-- Just like we can't know for sure how, counterfactually, a unit would have responded if the treatment had been set to a different level, we likewise can't know for sure whether our measurements accurately reflect the latent construct. -->

More specifically, a descriptive *inference* is a conclusion about the features of a latent variable $Y^*$ for some sets of units on the basis of observations of a measured variable $Y$, with measurements possibly taken from a different set of units. The feature we seek to describe---our inquiry---is some summaries of $Y^*$ such as its mean or perhaps its covariance with a second latent variable $X^*$. When we do descriptive research, we draw inferences about features of the nodes of the latent causal model $M$. Our measurement can be imperfect for two reasons: that we do not get to observe the quantity of interest directly for the units we study, and that the units we study are only a subset of the units of interest. It is these challenges that give rise to the focus on descriptive *inference* rather than measurement alone.  

A causal *inference* is a conclusion about the responses of variables to changes in other variables. Even if we do an exceptional job measuring $X^*$ and $Y^*$ with $X$ and $Y$, we will still have trouble learning about causal effects because causal effects are quite literally unobservable, they have to be inferred. 

### Descriptive inquiries

Descriptive inquiries are usually about latent variables since we mostly care about the true values of the variables in the models. Measured variables are often distinct from latent variables, which gives rise to a problem of descriptive inference. Normally, we define our inquiries in terms of the true latent variables rather than their measured counterparts; making the distinction explicit in a design object is especially important when the risks of measurement error loom large.

<!-- MH: I am not sure that there is a fundamental problem of descriptive  inference. Sure if you stipulate that you cannot measure correctly then we have a problem; but the fundamental problem of causal inference is that this is technically impossible. It's not just a stipulation -->

Table \@ref(tab:descriptiveestimands) enumerates some common descriptive estimands. These estimands have in common that you do not need any counterfactual quantities in order to define. Note especially that the covariance (similarly, the correlation) between $X$ and $Y$ enters as a descriptive estimand, so too does the line of best fit for $Y$ given $X$.

| Inquiry               | Description                                    | Code                 |
| --------------------- | ---------------------------------------------- | -------------------- |
| $\E_{i\in N}(Y)$      | The average value of the variable Y            | `mean(Y)`            |
| $\E[Y | X = 1]$       | A conditional expectation of Y given X = 1.    | `mean(Y[X == 1])`    |
| $\V[Y]$               | The variance of Y                              | `pop.var(Y)`         |
| $\mathrm{Cov}(X, Y)$  | The covariance of X and Y                      | `pop.cov(X, Y)`      |
| $\mathrm{BLP}(Y | X)$ | The best linear predictor of Y given X         | `cov(Y, X) / var(X)` |
| $\mathrm{CEF}(Y | X)$ | Conditional expectation function of Y given X  | `cef(Y, X)`          |
| Truth status of X     | Is X True or False?                            | `X == TRUE`          |

Table: (\#tab:descriptiveestimands) Descriptive inquiries


### Inquiries about causal effects

Inquiries about causal effects involve a comparison of at least two possible worlds. For example, an inquiry might be the causal effect of $X$ on $Y$ for a single unit. In order to infer that causal effect, we would need to know the value of $Y$ in two worlds: one world in which $X$ is set to 1 and one in which $X$ is set to 0. 

Table \@ref(tab:causalestimands) enumerates some common causal estimands. These estimands vary in the population they refer to---for instance are they statements about samples (SATEs) or populations (PATEs)? They can also depend upon possibly unobservable characteristics of populations---such as their value on a covariate (CATEs)--or the way they respond to other causes (the CACE targets the effect of treatment specifically for compliers ---those that take up treatment because they are encouraged to). Finally, they may be summaries of more than one potential outcome: for instance, the interaction effect is defined here *at the individual level* as the effect of one treatment on the effect of another treatment. 


<!-- - Estimand scope:What is the set of units which you want to learn the answer about? Know what ATE averages over -->



| Inquiry                                               | Description                                                                    | Code                                                              |
| ----------------------------------------------------- | ------------------------------------------------------------------------------ | ----------------------------------------------------------------- |
| $\E_{i\in N}[Y_i(1) - Y_i(0)]$                        | Average treatment effect (ATE)                                                 | `mean(Y_D_1 - Y_D_0)`                                             |
| $\E[Y_i(1) - Y_i(0) | X_i = 1]$                       | Conditional average treatment effect (CATE) for X = 1                          | `mean(Y_D_1[X == 1] - Y_D_0[X == 1])`                             |
| $\E[Y_i(1) - Y_i(0) | d_i(1) > d_i(0)]$            | Complier average causal effect (CACE) or local average treatment effect (LATE) | `mean(Y_D_1[D_Z_1 > D_Z_0] - Y_D_0[D_Z_1 > D_Z_0])`             |
| $\E[(Y_i(1, 1) - Y_i(0,1)) - (Y_i(1, 0) - Y_i(0,0))]$ | Causal interactions of $D_1$ and $D_2$                                         | `mean((Y_D1_1_D2_1 - Y_D1_0_D2_1) - (Y_D1_1_D2_0 - Y_D1_0_D2_0))` |

Table: (\#tab:causalestimands) Causal inquiries

Generations of students have been told to excise words that connote causality from their empirical writing. "Affects" becomes "is associated with" and "impacts" becomes "moves with." Being careful about causal language is of course very important (it's really true that correlation does not imply causation!). But this change in language is not usually accompanied by a change in inquiry. Many times we are faced with drawing causal inferences from less than ideal data -- but the deficiencies of the data strategy should not lead us too far away from our inferential targets. If the inquiry is a causal inquiry, then the move from "causes" to "is correlated with" might be a good description of the actual data analysis, but it doesn't move us closer to providing an answer to the inquiry.

### Causal attribution inquiries {#causalattribution}

Another kind of data-dependent inquiry that is distinct from the notion of a causal effect is that of causal attribution. A causal effect inquiry focuses on the change in an outcome that would be induced by a change in the causal variable (at the unit-level or across units) *irrespective of the values that the outcome takes*. By contrast, causal attribution inquiries focus on probabilities that condition on realized outcomes, such as, the "probability of the absence of the outcome in the hypothetical absence of the treatment ($Y_i(0) = 0$) given the actual presence of both ($D_i = Y_i = 1$)" [@yamamoto2012understanding, pp.240-241]. @goertz2012tale refers to causal attribution inquiries as cause-of-effects questions because they start with an outcome (an effect) and seek to validate a hypothesis about its cause. 

The dependence of these inquiries on actual outcomes makes them harder (though not impossible!) to answer with the tools of quantitative science, though they are often of central interest to scientific and policy agendas and have occupied a large number of qualitative studies. Questions like "'Was economic crisis necessary for democratization in the Southern Cone of Latin America?' or 'Were high levels of foreign investment in combination with soft authoritarianism and export-oriented policies sufficient for the economic miracles in South Korea and Taiwan?'" are examples of such inquiries [@goertz2012tale]. Though they bear a resemblance and *are* related to causal effects inquiries that focus on observed subsets (such as the average treatment effect on the treated, or ATT)^[Specifically, as @yamamoto2012understanding points out, the causal attribution estimand for binary variables can be written $\Pr(Y_i(0) = 0 \mid D_i = Y_i = 1)$, while the average treatment effect among those successfully treated can be written $E[Y_i(1) - Y_i(0) \mid D_i = Y_i = 1]$. Given binary outcomes and the additive property of expectations, the ATE among those successfully treated can be written $\Pr(Y_i(1)\mid D_i = Y_i = 1) - \Pr(Y_i(0) \mid D_i = Y_i = 1)$. The causal attribution inquiry can be written as one minus the second term of the ATE among the successfully treated.] it is important not to confuse the two kinds of inquiries, as often happens. 

While it is increasingly common to explicitly formalize causal effect inquiries, it is less common to formalize causal attribution inquiries. Doing so, however, can be important to provide the specificity required to diagnose a design on a computer. @pearl1999probabilities provides formal definitions for these inquiries using the language of causal necessity and sufficiency, depicted in the table below. To put these inquiries in the context of the democratic peace hypothesis, for example, in a given country dyad-year, $Y_i = 1$ and $D_i = 1$ could represent "Peace" and "Both democracies" and $Y_i = 0$ and $D_i = 0$ could represent "War" and "Not both democracies." Then $\Pr(Y_i(D_i = 0) = 0  \mid D_i = Y_i = 1)$ asks, among peaceful, fully democratic dyads, what is the proportion that would have had wars were they not both democracies---that is, in what proportion of dyad-years was democracy a necessary cause of peace? Similarly, $\Pr(Y_i(D_i = 1)=1  \mid D_i = Y_i = 0)$  asks, among dyads that had a war and at least one non-democracy in a given year, what is the proportion that would have experienced peace if both countries were democracies---in other words, in what proportion of cases would democracy have been sufficient to cause peace? @yamamoto2012understanding extends on this account to focus on causal attribution inquiries that focus on important subsets, such as compilers.

| Inquiry                                                | Description                                | Code                                                          |
| ------------------------------------------------------ | ------------------------------------------ | ------------------------------------------------------------- |
| $\Pr(Y_i(D_i=0)=0  \mid D_i = Y_i = 1)$                | Probability $D$ necessary for $Y$          | `mean(Y_D_0[D == 1 & Y == 1] == 0)`                           |
| $\Pr(Y_i(D_i=1)=1  \mid D_i = Y_i = 0)$                | Probability $D$ sufficient for $Y$         | `mean(Y_D_1[D == 0 & Y == 0] == 1)`                           |
| $\Pr(Y_i(D_i = 0) = 0 \mid D_i = Y_i = 1, D_i(Z_i)=z)$ | Complier probability $D$ necessary for $Y$ | `mean(Y_D_0[D == 1 & Y == 1 & D_Z_1 == 1 & D_Z_0 == 0] == 0)` |

Table: (\#tab:attributionestimands) Causal attribution inquiries

Like all designs, those with causal attribution inquiries can be declared, simulated, and diagnosed on a computer. Something to consider, however, is that the model may produce datasets in which the effect does not occur, and so questions defined over units for whom it occurred are undefined. One way to avoid this is to construct a model such that the event occurs for at least one unit with probability one.

## Estimands declared

Table \@ref(tab:MI1b) shows the "draws" of three  estimands. We declare a simple reference model and then an inquiry---or rather a set of inquiries. The estimand draws are then implemented by drawing a particular model $m$ from $M$ and then applying $I$ to the draw. 


```{r MI1a, comment = "", eval = FALSE}
model <-
  declare_population(N = 100,
                     U = rnorm(N),
                     D = rbinom(N, 1, .5)) +
  declare_potential_outcomes(Y ~ 0.5 * D + U, 
                             assignment_variable = "D") +
  reveal_outcomes(Y, D)

inquiry <-
  declare_estimand(
    treatment_group_mean = mean(Y[D == 1]),
    ATE = mean(Y_D_1 - Y_D_0),
    probability_of_causation = mean((Y_D_0 < 0)[D == 1 & Y_D_1 > 0])
  )

draw_estimands(model + inquiry)

```

```{r MI1b, comment = "", echo  = FALSE}
model <-
  declare_population(N = 100,
                     U = rnorm(N),
                     D = rbinom(N, 1, .5)) +
  declare_potential_outcomes(Y ~ 0.5 * D + U, 
                             assignment_variable = "D") +
  reveal_outcomes(Y, D)

inquiry <-
  declare_estimand(
    treatment_group_mean = mean(Y[D == 1]),
    ATE = mean(Y_D_1 - Y_D_0),
    probability_of_causation = mean((Y_D_0 < 0)[D == 1 & Y_D_1 > 0])
  )

draw_estimands(model + inquiry) %>% 
  kable(caption = "One model three estimands.", digits = 3, booktabs = TRUE)

```

The first estimand is a descriptive estimand: the average outcome for $Y$ when $D = 1$. 
Note that the declaration of the estimand does not make use of any counterfactual quantities.   
 
The second estimand is a causal effect. The inquiry is asked of the same model but this time the inquiry takes the average difference, across individuals, in two potential outcomes.  Unlike the descriptive estimand, this estimand uses information about $Y$'s potential outcomes but it does not use any information about the distribution of $D$.

The third inquiry asks an attribution question, in this case on continuous data. In this case, we ask about the share of units with positive values of $Y$ and $D=1$ that *would have had* negative values of $Y$ were $D=0$. This estimand requires information about both potential outcomes and actual outcomes (for $D$).

In this illustration, each "run" of `model + inquiry` provides a different value for the estimand (or, more precisely, this is true in this design for the first and the third estimand). How is this variation to be understood? As we noted in the last chapter, we might think of a superpopulation with a distribution of estimands and that we have an interest in understanding that superpopulation distribution, or we might think of the model, $M$, as representing a set of possible worlds and we are interested in performance in each of them `r flagit()`(WHAT DOES PERFORMANCE (IN A WORLD) MEAN?). Which approach we take will matter when we turn to diagnosis. 

## Common complexities in defining estimands

### Data-dependent inquiries

Most of the inquiries we have introduced thus far depend on variables in the model, but not on features of the data and answer strategies (the attribution estimands are an exception). However, common inquiries do depend on realizations of the research design. 

The first type depends on realizations of the data $d$: inquiries about units within a sample depend on which units enter the sample; inquiries about treated units depend on which are treated. The sample average treatment effect is a common inquiry used by experimental researchers who wish to not worry about how their effects generalize to a population but only about identifying the causal effect within the units in front of them. There is a true sample average treatment effect $a^w$ for every possible sample that we could draw. But which of those fixed values is selected as our inquiry if we define $I$ as the sample average effect depends on which sample is actually selected by our sampling procedure. The same is true when we condition inquiries on the set of treated units---in that case, our estimand is defined *conditional* on who received treatment. 

There is a curiosity here in that one might wonder how to assess whether a given sampling scheme or  assignment procedure is good, *ex ante*,  in cases in which the question is only posed conditional on sampling and assignment. Odder still one might wonder about how to conduct statistics on effect estimates when both the sample and treatment assignment is fixed, since, conditional upon these features, it is hard to see where variation in a sampling distribution for estimates might come from.  A reasonable response to such concerns is that in many cases one can pose an  ex ante question in the following form: say I am committed to a family of designs in which I allocate 50 units to treatment, with each unit equally likely to be assigned, then what will be the effect on those that receive treatment, whoever they end up being? In this case, each "run" of the study produces a different treatment group and the quality of the design is assessed with respect to this distribution of possible treatment groups; similarly, errors are calculated over this distribution. Moreover, given the constraints on the admissible assignment schemes, one can assess whether one scheme fares better than another on different criteria.



| Inquiry                          | Description                                   | Code                                  |
| -------------------------------- | --------------------------------------------- | ------------------------------------- |
| $\E[Y_i(1) - Y_i(0) | D_i = 1]$  | Average treatment effect on the treated (ATT) | `mean(Y_D_1[D == 1] - Y_D_0[D == 1])` |
| $\E[Y_i(1) - Y_i(0) | S_i = 1]$  | Sample average treatment effect (SATE)        | `mean(Y_D_1[S == 1] - Y_D_0[S == 1])` |

Table: (\#tab:datadependentestimands) Data-dependent inquiries.

A second design-dependent inquiry class depends not on $d$ but $A(d) = a^d$, the *answer* given the data. In an $a^d$-dependent inquiry, we only know the inquiry after seeing the results of our study. When we collect data on ten variables and calculate the correlation between all ten on a separate outcome variable, and then report on the magnitude of the correlation of the seventh variable - the only one that was statistically distinguishable from zero. If our inquiry is "which of these seven variables is significant" then there will be no problem, as long as we include a multiple comparisons correction to adjust for the probability of finding one significant under null effects due to random chance. If we started with the question of what is the correlation between variable seven and the outcome, we would also have no problem. However, if with our procedure we think of our inquiry as what is the correlation between variable seven and the outcome, then we have a problem: we are not accounting for the multi-step procedure in our answer strategy and we will not be able to provide good answers to that inquiry. In short, although there can be dangers if we are guided by the realization of our answer in *selecting* an inquiry, there is no problem with procedure-based answer strategies---we just must be honest about our original inquiry. This problem comes up in descriptive inference in looking at multiple correlations as in this example, but also in many other places such as searching for heterogeneity in treatment effects in experiments and nested research designs that iterate between levels of data [@lieberman2005nested].


### Non-decomposable inquiries

Most of the inquiries we have looked at are group level summaries of individual level inquiries. These are decomposable in the sense that you can think of an average effect for a large group as being the average of a set of average effects of smaller groups. However, not all inquiries are of this form. Some---such as the best linear fit---are complex summaries of possible data. Others are still more notional. Consider, for example, the estimand that the Regression Discontinuity Design (RDD) shoots at. In the RDD model (see Section \@ref(RDD)), we imagine units with $Y_i(1)$, $Y_i(0)$. Each $i$ also has a value on a "running variable", $x_i$, and units receive treatment if and only if $x_i>0$. In this case the "effect at the point of discontinuity" might be written:

$$E_{i|x_i = 0}(Y_i(Z=1) - Y_i(Z=0))$$

Curiously, however, there may be no units for whom $x_i = 0$, so we cannot easily think of the estimand as being a summary of individual potential outcomes. 

One way to resolve this is to think of $X$ as being randomized, at least locally, in which case we can define the estimand as:

$$\E_{i}(Y_i(Z=1, X=0) - Y_i(Z=0, X=0))$$

With this conceptualization the estimand is an average of individual effects, the challenge is that we need to make an inference in a condition where we have no data.  

Another approach is to imagine a more complex summary where we construct a best fit continuous potential outcomes function for the cases with $Z=1$ and $Z=0$ and evaluate the difference between these when $X=0$. Though not an average of individual effects, this difference is nevertheless a summary of the potential outcomes. Note though that the nature of the estimand (recall we are discussing the estimand, not the estimate) depends on how the potential outcomes function is constructed---is it, for instance, a linear function or a higher-order polynomial?

### Model dependent inquiries

A similar conceptualization can be used for settings where model parameters are estimands. For instance, we might have access to data on decisions by subjects in a lab and seek to estimate a "coefficient of risk aversion." The reference model might not include such a coefficient---indeed we might not be willing to believe that such a number really exists for subjects. Yet we might still ask: if we had access to all possible choices, what coefficient would best summarize the choices of an agent. The answer provides the estimand which we then seek to estimate on finite data. `r flagit()`(HOW IS IT MODEL DEPENDENT YET NOT INCLUDED IN THE REFERENCE MODEL?)

### Complex counterfactual inquiries

The counterfactual queries we have described so far involve imagining a change to one variable and assessing the effects on another, yet much more complex causal queries are imaginable including quantities about events that are not possible even under the reference model.  An example is the "controlled direct effect." We imagine for instance that $X$ causes $Y$ directly and indirectly. Say in particular that $X$ causes $M$ and conditional on $M=0$ $X$ causes $Y$ directly. Then the controlled direct effect of $X$ on $Y$ is:

$$\mathrm{CDE} = Y(X=1, M=1) - Y(X=0, M=1)$$

this is a well-defined quantity under the potential outcomes and DAG formulation. But it can require mental gymnastics in situations in which, say $M=1$ would never arise if indeed $X$ were 0. For instance: would a Democrat win in the presidential elections affect the success of Democrats in mid-term elections, conditional on the presidency remaining in Republican hands.       

<!-- ### Relationship between causal and descriptive inquiries -->

<!-- You can think of causal inference as repeated descriptive inference: we have to describe $Y$ in multiple possible worlds. -->

<!-- Causal inquiries like the average effect of $A$ on $B$ in a causal model like $A \rightarrow B \leftarrow U$ are helped enormously by good descriptive inference about the nodes $A$ and $B$, but the focus is on the edge between them. You typically can't learn about the edge by doing descriptive inference on the nodes only. If we measure $A$ and $B$ and find that they covary, we can't be sure that $A \rightarrow B$ because it could be that $A \leftarrow U \rightarrow B$. This problem goes by the familiar phrase that "correlation doesn't imply causation," which is true and is a problem that can't be wished away. But "correlation doesn't imply causation" also kind of misses the point. The point is that you can't see causality because it involves counterfactuals, which are imaginary and unseen. You have to infer causality on the basis of design. -->

### Inquiries with continuous causal variables

Inquiries that focus on a small number of potential outcomes are usually quite easy to write down: for a binary treatment in a model with no spillovers, there are only two potential outcomes, and the average treatment effect is defined as their average difference across units. But what about a treatment like income, for which there might be millions of potential outcomes, each one corresponding to a different dollar amount? For truly continuous treatments, there might even be an infinite number of potential outcomes. 

One approach is to think of the estimand as a data-dependent marginal effect. For example, $E[Y_i(X_i) - Y_i(X_i-1)]$ captures the expected average difference between the observed data, in which people have income $X_i$, and their unobservable outcome in which they have one dollar less. Another approach is to think of continuous-treatment estimands as the parameter from a regression that only an omniscient being could run. For example, we might define  $\alpha$ and $\beta$ as the solutions to:
$$\min_{(\alpha,\beta)}\sum_i\int \left(Y_i(x) - \alpha - \beta x\right)^2f(x)dx$$
Here, $Y_i(x)$ is the (unknown) potential outcome for unit $i$ in condition $x$. Estimand $\beta$ can be thought of as the coefficient one would get on $x$ if one were to able to regress all possible potential outcomes on all possible conditions for all units (given the density of interest $f(x)$). Often, the most straightforward approach is to define the inquiry over a finite number of potential outcomes drawn from the range of the treatment variable. 
<!-- Mention here that the distribution of the treatment variable might affect the probability with which these POs are revealed? -->


### Undefined and unanswerable inquiries

Declaring your design in terms of $MIDA$ may lead you to two awkward conclusions: your inquiry $I$ returns $I(m) = a^m = \mathrm{NA}$, i.e., the answer to your inquiry is undefined; or your answer may be (currently) unanswerable, that is, there is no feasible $D$ and $A$ that yield an answer to $I$. In both cases, one option is to change your inquiry. But often we selected $I$ because of its importance, so we may want to try to find an answer. In the case of undefined inquiries, we have no option but to select a new one. In the case of unanswerable inquiries, we can work to identify a novel $D$ and $A$ that change the set of feasible designs and provide an answer. In some cases, however, the fact that the inquiry is unanswerable may be due to unchangeable limitations of research such as the fundamental problems of causal inference or descriptive inference. 


### Example

@Bjorkman:2009 reports the results of a cluster-randomized trial of the effects of community-based monitoring of health clinics in Uganda to improve children's health. The main inquiry was the average treatment effect on the child mortality rate. The study showed that the program was a success: in the control group, the child mortality rate was 144 per 1000 live births, compared with 97 in the treatment group, for a 33\% reduction in child mortality. 

The study also considered a second inquiry: the average treatment effect on the weight-for-age of children under 18 months. This inquiry is harder to think about, precisely because we know that community-based monitoring saved the lives of many children. To see the problem, consider Table \@ref(tab:bstypes), which shows four types of infants distinguished on the basis of their potential outcomes. Type A (for "Adverse") is alive if in control, but dies if in treatment. Type B ("Beneficial") is just the reverse: the child dies if untreated, but survives if treated. Type C ("Chronic") would die under either condition and Type D ("Destined") would live under either condition. For the first three types, the child dies under one condition, the other, or both. Since weight-for-age only exists if the child survives, the treatment effect on weight for A, B, and C types is undefined.

The main trouble here is that the average treatment effect averages over all four types so the ATE itself is also undefined. Since this inquiry is undefined, we'll need to select a different one.

We might want to switch our inquiry to be about the average effect among D types only. However, this inquiry has a different problem -- it's unanswerable. Even though this inquiry is not undefined, it's unanswerable because we won't be able to learn who the D types are. In the treatment group, we can't tell the Bs from the Ds and in the control group, we can't tell the As from the Ds. The reason we can't tell these types apart using realized data is the fundamental problem of causal inference.

| Type | Alive($Z = 0$) | Alive($Z = 1$) | Weight($Z = 0$) | Weight($Z = 1$) | Estimand                                          |
|------|----------------|----------------|-----------------|-----------------|---------------------------------------------------|
| A    | 1              | 0              | exists          | NA              | undefined                                         |
| B    | 0              | 1              | NA              | exists          | undefined                                         |
| C    | 0              | 0              | NA              | NA              | undefined                                         |
| D    | 1              | 1              | exists          | exists          | $\E[\mathrm{Weight}(Z=1) - \mathrm{Weight}(Z=0)]$ |

Table: (\#tab:bstypes) Latent types.

What can be done in this situation? We might try to find a covariate $X$ that is correlated with being a D type and condition our analysis of the effect on weight on that covariate. Note that among this subgroup, the effect on mortality should be equal to zero. Finding such a covariate would be hard, though perhaps not impossible.

Alternatively, we might define our inquiry to be the average treatment on the average weight of living children within a cluster, but this inquiry requires careful interpretation. If the treatment saves the lives of children whose health is *marginal* in particular, then the effect on average weight could easily be negative, even though the treatment improves health. We specifically cannot interpret the answer to this inquiry to refer to the effect of treatment on health. That said, it might nevertheless be a useful number to know if we are in the position of administering healthcare resources -- we'd want to send additional help to those treatment areas where the lives of unhealthy children (who otherwise would have perished) are being saved.

## How should you select inquiries?

It's hard to know where to start when picking a research question. We want to pick one that is interesting in its own right or one that would facilitate a real-world decision. We want to pick research questions that we can learn the answer to someday, with a lot of effort. Unfeasible research questions should be abandoned as soon as possible, but of course, that's hard to do. The trouble is that it's hard to know what research questions are feasible before you start looking into it, and it's really hard to quit research projects once you learn they are unfeasible because of the sunk cost fallacy. Among feasible research questions, we want to select ones that we are likely to obtain the most informative answers, in terms of moving our priors the most. This last criterion will often help us select among related, feasible inquiries that are about the same DAG but for which we know we can learn more and less through research.

Sometimes, people advise students to follow a "theory-first" route to picking a research question. Read the literature, find an unsolved puzzle, then start choosing among the methodological approaches that might answer the problem. Others eschew the theory-first approach: "How on earth are you going to happen to land upon an unsolved -- and yet somehow solvable -- puzzle just by reading!?" These advice-givers emphasize a method-first route. Master the technical data-gathering and analysis procedures first, then set off to find opportunities to apply them. The theory-first people then say: "how would you know an interesting theoretical question if it smacked you in the face!?"

Iteration between the two is typically necessary. In order to select research questions, empiricists have to be concerned about the entire research design. We have to develop empirical strategies to provide answers to our inquiries. We have to learn a lot about how to select data and answer strategies in ways that map on to inquiries about models. So empiricists have to learn both about models and inquiries (theory) as well as about data strategies and answer strategies (empirics).

The first criterion is the subjective importance of a question. The object of the importance may be a scientist, considering the value of building a theoretical understanding of the world; to a policymaker, deciding how to collect and allocate resources in a government; a private firm, who is making decisions about how to invest their own resources to maximize profit; or another individual or organization. The scientific enterprise is designed around the idea that importance is in the eye of the scientist and is not some objective quantity. This is for two reasons. First, the scientific or practical importance of a discovery may not be understood until decades later, when other pieces of the causal model are put together or the world faces new problems. Moreover, "importance" differs for different segments of society, and scientists must be able to study questions not judged important by groups in power in order to discover new ways to solve problems faced by the left-out groups. 

Among important questions, researchers can select the $I$ they think they are likely to be able to learn the most about. We start with a prior distribution over $a^w$, the true answer about the inquiry, from past research, and a good research design will substantially update that prior distribution, either by moving the mean of the distribution or reducing our uncertainty about it. 

The final criterion is that among important, probative research designs there must be a feasible $M$, $D$, and $A$ that could answer $I$. That means picking a good question $I$ does not just involve theory. You should study $M$ to understand which $I$s are worth knowing. But you should also study $D$ and $A$ in order to learn how to demonstrate $I$. A central goal of research methodologists is to expand the feasible set of $D$ and $A$ that can provide informative answers to important questions.

Clearly, research designs will vary how important, feasible, and probative they are, and so  these criteria do not provide an immediate answer to how to select a design. Instead, the researcher must choose a weighting of the three, and norms in a research community may guide those weightings. In some disciplines, providing a minimally probative answer to a highly important question may be preferable to a highly probative answer to a less important question. 
<!-- ```{r, fig.width = 4, fig.height = 4, echo = FALSE} -->
<!-- ggplot() +  -->
<!--   geom_abline(intercept = 5, slope = -1) +  -->
<!--   geom_abline(intercept = 6, slope = -1, lty = "dashed") +  -->
<!--   geom_function(fun = function(x) (x-2)^2, geom = "curve") +  -->
<!--   coord_fixed(ylim = c(0, 6), xlim = c(0, 6)) -->
<!-- ``` -->

Here's our best advice for how to get started picking a research question: Write down the $M$ and $I$ of any causal model that you think is important to get started thinking about selecting strong $D$s and $A$s. The goal is to learn how to map $I(M)$ to $A(D)$. Then return to theory to find new important inquiries, then write down a new model, inquiry, data strategy, and answer strategy. This process is how we make progress on $M$: we bring $M$ closer to $W$, thereby making $M$ truer. In each iteration, consider how informative the answers you can provide: how much will they update what we know about the world?

People who are looking in the forest for mushrooms often don't see a mushroom for a long period of time. After a while, they acclimate. They get their "eyes on," and successful finds seem to be around every bend. In this analogy, the theory-building process is going for a walk in the forest and methods training is learning to spot mushrooms -- you need to get your eyes on answerable research questions worth answering.


## Further reading

- @goertz2012tale on differences across inquiries in qualitative and quantitative research.
- @dawid2000causal on cause-of-effects questions.
- @yamamoto2012understanding on causal attribution.
- @zhang2003estimation on "truncation-by-death"
