---
title: "Defining the inquiry"
output:
  html_document: default
  pdf_document: default
bibliography: ../bib/book.bib
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

<!-- make sure to rename the section title below -->

```{r defining_the_inquiry, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```


```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
library(dagitty)
```

# Defining the inquiry

An inquiry is a summary of a theoretical model. Suppose your theory is that $X$ affects $Y$, but that the effect is bigger for units with higher values of a third variable C. One inquiry might be the average level of $Y$. A second might be the average treatment effect of $X$ on $Y$. A third might be the difference in the effect of $X$ on $Y$ for units with high values of $C$ versus units with low values. 

Your inquiry is your research question. Simple or complex, causal or descriptive, your inquiry is a summary feature of your theoretical model. Like models, inquiries themselves are theoretical objects. A common confusion occurs between inquiries and the output of answer strategies. If our theory posits the existence of an Average Treatment Effect, we might use an answer strategy like difference-in-means to estimate it, but the estimate is fundamentally distinct from the inquiry. Estimates are empirical, inquiries are theoretical.

In general, an inquiry is a summary function $I$ that operates on the model $M$. When we summarize the model with the inquiry, we obtain an "answer under the model." We formalized this as $I(m) = a^m$. You can think of the difference between $I$ and $a^M$ as the difference between a question and its answer. $I$ is the question we ask about the model and $a^m$ is the answer. Alternatively, you can think of $I$ as the "estimand" (that which is to be estimated) and $a^m$ as the value of the estimand.  

In this book when we talk about inquiries, we will usually be referring to single-number summaries of models. Some common estimands are descripitive, such as the means, conditional means, correlations, partial correlations, quantiles, and truth statements about variable in the model. Others are causal, such as the average difference in one variable when a second varible is set to two different values. You can think of a single-number inquiry as the atom of research question. 

While most inquiries are "atomic" in this way, some inquiries are more complex than a single-number summary. For example, the best linear predictor of Y given X is a two-number summary: it is the pair of numbers (the slope and intercept) that minimizes the total squared distance between the line and each value of Y. Why stop at two-number summaries? We could imagine the best quadratic predictor of Y given X (three-number summary) or the best cubic predictor (four), and so on. We could have an inquiry that is the full conditional expectation function of Y given X, no matter how wiggly, nonlinear, and nuanced the shape of that function -- it could in principle be a 1,000 number summary of the model, or much more.

Complex inquiries can also be something along the lines of "should I reject $M$" as a causal model of the world? A researcher might articulate a handful of important questions about the model that all have to come out a certain way or the model itself should be rejected. These complex inquires are made up of a series of atomic inquiries -- we're interested in the sub-inquiries only insofar as they help us understand the real inquiry -- is this model of the world a good one or not.


## Kinds of Inquiries

<!-- MH: My vote: four types of queries: the three from Pearl (descriptive, interventionist, counterfactual) plus "model" queries in which you try to learn the model. --> 
<!-- AC: Could you say more about "interventionist"? not sure I understadn the difference vs. counterfactual. Also, I was thinking here that the basic distinction between descriptive and causal is the most important, "model" queries are made up of a series of sub-inquiries that themselves are either descriptive or causal. Model queries can mix both. Would that cover it?-->

<!-- MH: Suggest a table that gives a real broad set of inequiries that people can use as a reference; ATE, LATE, PATEs, SATEs, CDEs, lots and lots. Even better if we can define most of them off a simple DAG. -->


<!-- AC: tough for one DAG, but We've got the table started now at least -->

Atomic inquiries $I$ about a model $M$ fall into two basic categories, descripitive and causal. Descriptive inquiries are about how the world was, is, and will be whereas causal inquiries are about how the world would have been, would be, or would be in the future if some variables were set to different levels. You might think of the distinction in terms of a DAG. Descripitive inquiries are about the nodes of a dag whereas causal inquires are about the edges. 

Descriptive and causal inference have in common the difficulty of inferring unseen things from observed data. The fundamental problem of causal inference is well known. For the same reason that a unit cannot simultaneously be both treated and untreated, we can only every observe at most one potential outcome for any particular unit. The fundamental problem of descriptive inference is similar. The concepts we want to measure are latent constructs. Perfect measurement is impossible, so our measurements of the latent constructs always include some measurement error. Just like we can't know for sure how, counterfactually, a unit would have responded if the treatment had been set to a different level, we likewise can't know for sure whether our measurements accurately reflect the latent construct.

More specifically, a descriptive *inference* is a conclusion about a latent variable $Y^*$ on the basis of a measured variable $Y$. The feature we seek to describe -- our inquiry -- is some summary of $Y^*$ like its mean or perhaps its covariance with a second latent variable $X^*$. When we do descripitive research, we draw inferences about features of the nodes of the latent causal model $M$. A causal *inference* is a conclusion about the edge between two latent variables $X^*$ and $Y^*$. Even if we do an exceptional job measuring $X^*$ and $Y^*$ with $X$ and $Y$, we will still have trouble learning about edges because causal effects are quite literally unobservable. We have to *infer* causality on the basis of a strong research design because we can't just see it.

### Descriptive inquiries

Descriptive inquiries are usually about latent variables since we mostly care about the true values of the variables in the models. Because of the fundamental problem of descriptive inference, measured variables are always distinct from latent variables. For the most part, we define our inquiries in terms of the true latent variables rather than in terms of their measured counterparts.

Table ZZZ enumerates some common descriptive estimands. 

| Inquiry           | Description                                   |
| ----------------- | --------------------------------------------- |
| $E_{i\in N}(Y)$   | The average value of the variable Y           | 
| $E[Y | X = 1]$    | A conditional expectation of Y given X = 1.   |
| $V[Y]$            | The variance of Y                             |
| $Cov(X, Y)$       | The covariance of X and Y                     |
| $BLP(Y | X)$      | The best linear predictor of Y given X        |
| $CEF(Y | X)$      | Conditional expectation function of Y given X |
| Truth status of X | Is X True or False                            |

### Causal inquiries

Causal inquiries involve a comparison of at least two possible worlds. For example, an inquiry might be the causal effect of $X$ on $Y$ for a single unit. In order to infer that causal effect, we would need to know the value of $Y$ in two worlds: one world in which $X$ is set to 1 and one in which $X$ is set to 0. 

Table ZZZ enumerates some common causal estimands. 

- Estimand scope:What is the set of units which you want to learn the answer about? Know what ATE averages over



| Inquiry                                                  | Description                                                                    |
| -------------------------------------------------------- | ------------------------------------------------------------------------------ |
| $E[Y_i(1) - Y_i(0)]$                                     | Average treatment effect  (ATE)                                                |
| $E[Y_i(1) - Y_i(0) | X = 1]$                             | Conditional average treatment effect (CATE)                                    |
| $E[Y_i(1) - Y_i(0) | d_i(1) \geq d_i(0)]$                | Complier average causal effect (CACE) or local average treatment effect (LATE) |
| $E[Y_i(1) - Y_i(0)]$                                     | PATE                                                                           |
| $E[Y_i(1) - Y_i(0) | S = 1]$                             | SATE                                                                           |

Generations of students have been told to excise words that connote causality from their empirical writing. "Affects" becomes "is associated with" and "impacts" becomes "moves with." Being careful about causal language is of course very important (it's really true that correlation does not imply causation!). But this change in language is not usually accompanied by a change in inquiry. Many times we are faced with drawing causal inferences from than ideal data -- but the deficiencies of the data strategy should not lead us too far away from our inferential targets. If the inquiry is a causal inquiry, then the move from "causes" to "is correlated with" might be a good description of the actual data analysis, but it doesn't move us closer to providing an answer to the inquiry.


### Relationship between causal and descriptive inquiries

You can think of causal inference as repeated descriptive inference: we have to describe $Y$ in multiple possible worlds.

Causal inquiries like the average effect of A on B in a causal model like $A -> B <- U$ are helped enormously by good descriptive inference about the nodes $A$ and $B$, but the focus is on the edge between them. You typically can't learn about the edge by doing desscripitve inference on the nodes only. If we measure $A$ and $B$ and find that they covary, we can't be sure that $A -> B$ because it could be that $A <- U -> B$. This problem goes by the familiar phrase that "correlation doesn't imply causation," which is true and is a problem that can't be wished away. But "correlation doesn't imply causation" also kind of misses the point. The point is that you can't see causality because it involves counterfactuals, which are imaginary and unseen. You have to infer causality on the basis of design.




## How should you select Inquiries?

It's hard to know where to start when picking a research question. We want to pick one that is interesting in its own right or one that would a facilitate real-world decision. We want to pick research questions that we can learn the answer to someday, with a lot of effort. Infeasible research questions should be abandoned as soon as possible, but of course that's hard to do. The trouble is that it's hard to know what research questions are feasible before you start looking into it, and it's really hard to quit research projects once you learn they are infeasible because of the sunk cost fallacy. 

Sometimes, people give advice to students to follow a "theory-first" route to picking a research question. Read the literature, find an unsolved puzzle, then start choosing among the methodlogical approaches that might answer the problem. Others eschew the theory-first approach: "How on earth are you going to happen to land upon an unsolved -- and yet somehow solvable -- puzzle just by reading!?". These advice-givers emphasize a method-first route. Master the technical data-gathering and analysis procedures first, then set off to find opportunies to apply them. The theory-first people then say: "how would you know an interesting theoretical question if it smacked you in the face!?"

Both routes work just fine because in most any research project, scholars necessarily toggle between both modes iteratively. In order to select research questions, empiricists have to be concerned about the entire research design. We have to develop empirical strategies to provide answers to our inquiries. We have to learn a lot about how to select data and answer strategies in ways that map on to inquiries about models. So empiricists have to learn both about about models and inquiries (theory) as well as about data strategies and answer strategies (empirics).

The sine qua non of a good research question ($I$) is that there is a feasible design ($MIDA$) that could answer it. That means picking a good question $I$ does not just involve theory. You should study $M$ to understand which $I$s are worth knowing. But you should also study $D$ and $A$ in order to learn how to demonstrate $I$.

Here's our best advice for how to get started picking a research question: Write down the $M$ and $I$ of any causal model that interests you to get started thinking about selecting strong $D$s and $A$s. The goal is to learn how to map $I(M)$ to $A(D)$. Then return to theory to find new important inquiries, then write down a new model inquiry data strategy and answer strategy. This process is how we make progress on $M$, that is, we bring $M$ closer to $W$, thereby making $M$ truer.

People who are looking in the forest for mushrooms often don't see a mushroom for a long period of time. After a while, they acclimate. They get their ``eyes on,'' and successful finds seem to be around every bend. In this analogy, the theory building process is going for a walk in the forest and methods training is learning to spot mushrooms -- you need get your eyes on answerable research questions worth answering.

## Example: Bjorkman and Svennson

[ example based on BS appendix from APSR paper ]

## Grab bag of ideas we don't know where to put

- Study dependent estimands like Expected ATT vs realized ATT.  Yes, your I depends on D, but in a weird way. Since you can write down all possible ATTs in the model, you actually *can* write the estimand without realizing D, you just don't know which of the multiverse of estimands you've written down will actually eventuate. Since beliefs about the data strategy (it will create a class of subjects who will be treated) can sort of be hacked into the model, I wonder about how fundamental this wrinkle is.

- Complex counterfactuals
- QCA estimand.
- Unknown estimands: Inquiries for discovery

- Auxilliary Inquiries: these inquiries are not the main substantive focus of the design, but they are features of the model that have observable implications and can be checked. For models that include mediating roles for a variable, need to demonstrate that Z affects M at a minimum. Balance tables demonstrate a required assumption that Z is orthogonal to pre-treatment characteristics. A full DAG specification can enumerate the full set of conditional independencies that are implied by the model; these can be checked and verified.



A good inquiry is informative about the model. 
- Existence of a node (descriptive mean)
- Model suggests two variables should be correlated (descriptive correlation)
- Arrow between a node (experiment)
- CDF / PDF of a variable

A bad inquiry:
- does not exist
- does not address a "central" part of the model
- does not summarize the theory


You are responsible for your inquiry.

Choice of inquiry is not valueless.


How do you choose an inquiry? You figure out what inquiries people are fighting about. You "enter the debate."

- stuff from MODEL

Potential outcomes notation is especially useful for defining *inquiries*. The most common causal inquiry is the Average Treatment Effect (ATE), which is written like this^[The expectation operator $E[]$ is a way of describing the average of a random variable. In general, $E[X] = \sum_{x \in X} x * pr(X = x)$ for discrete outcomes. Here we are slightly abusing the notation, since in a fixed population, $Y_i(1)$ and $Y_i(0)$ are not random variables. We could write the ATE as $\frac{1}{N}\sum_1^N Y_i(1) - Y_i(0)$, or we could just imagine that we drawing one unit at random from the fixed population; the expectation operator can be defined with respect to this imaginary random variable in order to save ourselves notational headaches.]:

$$
ATE \equiv E[Y_i(1) - Y_i(0)]
$$

We want to emphasize that the ATE is an *average*. The difference between $Y_i(1)$ and $Y_i(0)$ for unit $i$ is an individual-level treatment effect (sometimes we'll refer to $Y_i(1) - Y_i(0)$ as $\tau_i$). The ATE averages over all of the individual-level treatment effects in the relevant population. Some units will have a $tau_i$ that is higher than the ATE, some will have a $\tau_i$ that is lower. We emphasize this because sometimes people mistakenly think that by focusing on an ATE, researchers "assume" that everyone experiences the same treatment effect. This is not true. The ATE is just a single-number summary of a possibly very heterogeneous set of responses to treatment.

We can also use potential outcomes notation to define other, more complicated inquiries. Throughout the book, we'll describe a series of them: local average treatment effects, average treatment effects on the treated, average direct effects, average indirect effects, and spillover effects, to name a few. For now, we'll write down three new inquiries: the conditional average treatment effect (CATE) of $Z$ on $Y$ for units with $X = 1$, the CATE among units with $X = 0$, and the difference-in-CATEs:

$$
\begin{aligned}
CATE_{(X = 1)} &\equiv E[Y_i(1) - Y_i(0) | X = 1] \\
CATE_{(X = 0)} &\equiv E[Y_i(1) - Y_i(0) | X = 0] \\
Diff-in-CATEs &\equiv E[Y_i(1) - Y_i(0) | X = 1] - E[Y_i(1) - Y_i(0) | X = 0]
\end{aligned}
$$



<!-- [Introductory Material about the Inquiry] -->


<!-- It's October in an election year. Your inquiry is: "how many voters will vote Democrat in November?" The true answer is 66,221,143. This true answer is your estimand ($a^M$), you seek to estimate this number now, even though the election has not happened yet. On the basis of a survey your best guess is 65, 112, 114. This is your estimate for this estimand -- your $a^D$ for your $a^M$. -->

<!-- In this case the estimand is a number and one that will eventually be revealed, letting you assess how well your estimate measures up against your estimand. But in social science inequiry estimands can take many different forms.  -->

