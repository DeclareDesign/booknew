---
title: "Specifying the model"
output: html_document
---

<!-- note do_bookdown is set in index.rmd, so we know if you are running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

# Specifying the model

<!-- make sure to rename the section title below -->

```{r specifying_the_model, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```

<!-- - Introduce DAGs and potential outcomes
- What is your DAG? How do you write a DAG? What must be in it? What will be missing from it (heterogeneity!)? [MH]
- What parts of background variables must be specified, and how can you specify them (existing data, substantive bounds on variables)
- Isn't defining the effect size for potential outcomes begging the question?
- Pilot studies
- Spillovers are potential outcomes
- Compliance is a potential outcome
- Attrition is a potential outcome 
- Measurements are potential outcomes
 -->


<!-- Key learning points: 
 
 - Learning depends on models because they are the only way to understand how your answer and data strategy perform with respect to your inquiry
 - The key thing a model does is posit potential outcomes---those are the building blocks of what you can ask (your $I$nquiry) and what you can observe (your $A$nswer strategy)
 - How to take control of your potential outcomes: you will learn what counterfactual states of the world you need model explicitly and which ones you do not -->

<!-- Your model encodes two very important pieces of information: first, the assumptions under which conclusions about your design's properties were reached---when it is unbiased versus unbiased, when it has low versus high power; second, your model defines what potential outcomes your inquiry and answer strategy are defined over.  -->

<!-- FIX: In practice, we never get to observe all of the potential outcomes: but knowing what they *could* be means that you can compare the true answer to some inquiry, as defined by the model, to the actual answer to the inquiry your research design would provide, if the world looked like your model.  -->

<!-- ## Models versus modelling -->


In this chapter, we will talk about how to go about the tricky task of specifying a $M$odel and why it is so important to do so. 
We are not talking about "statistical models" used to estimate unknown parameters---those are part of your answer strategy. We are talking about specifying simulation models: a set of assumptions about how your data could be generated, encoded in math or computer language, which we can use to generate imaginary datasets. <!-- Using a capital $M$ model to simulate fake datasets, you can learn about the properties of your answer strategy, which may or may not involve statistical modelling.  -->

The distinction is a subtle but important one. We should only trust the inferences we draw from a statistical model if we think they would be good inferences to draw based on a plausible $M$odel of how the data was generated. 

$M$odels often lurk where you might not expect them. When researchers do experiments, they often compare the average observed outcome in the treatment group to the average observed outcome in the control group in order to get an estimate of the average treatment effect.^[...of putting one person in treatment and everyone else in control] This comparison requires no statistical modelling of the distributions of the observed variables: it follows from the fact that the average difference in two potential outcomes is equal to the difference in the averages of those two potential outcomes. So it seems as though such strategies are completely agnostic as to how the data was generated. 

Implicit in the very definition of the average treatment effect here, however, is a $M$odel: specifically, one in which any particular draw of the random assignment is able to reveal no more than two potential outcomes for any given individual---this is sometimes referred to as a "no spillovers" assumption. But many social processes violate this assumption. If I do something differently every time you get treated and I do not, then I have at least three potential outcomes: one in which I am treated, one in which neither of us are treated, and one in which you are treated but I am not. The average observed difference-in-means across random assignments might diverge quite substantially from the average effect we are interested in (say, of putting just one person in treatment and the rest in control). So even the simplest, most agnostic research design is relying on the plausibility of an implicit $M$odel in order to generate insights that are correct on average. 

In practice, we never get to know whether our $M$odel is right. For example, we can never really know how many potential outcomes there are. So we also cannot know if we got the right answer. What we can do, however, is study our procedure for generating answers under $M$odels of the world that we find plausible. That way, we do get to know which answers we should and should not trust, given the assumptions we are willing to make about the world.




<!-- INTRODUCE IDEA OF POs -->




<!-- , we can know how many fish we *would* guess are in the ocean were our assumptions about the ocean correct. We never get to know if we guessed correctly, but we do get to know which guesses we should and should not trust, given the assumptions we are willing to make about the world. -->


<!-- To see why, let us talk about fish. How many fish *are* there in the ocean, anyway? It turns out we do not know the answer to this question: we just cannot count all the fish. 

We do have answers, though: scientists estimate there are 3.5 trillion fish in the ocean as of 2017. But if we cannot count them, how do we get this answer and why should we ever believe it? It all depends on comparisons between $M$odels and modelling. 

Let us say our $M$odel states that $N$ fish exist. We want to see how well a statistical modelling strategy would do at guessing $N$. Our $M$odel further assumes the fish do not die, reproduce, or migrate. They do not have any favorite spots in the sea, so they are equally likely to be caught no matter where you cast your net. Moreover, the fish are brave fish: having been caught once and released, the fish do not shy away from being caught again. 

One of the simplest modelling techniques to estimate the size of an unknown population is the capture-recapture technique: Net $n$ fish, tag them, and release them; catch another $K$ fish, count the $k$ that are tagged (from the previous netting), and release them. This leads to a pretty simple statistical model, $n/N = k/K \Rightarrow \hat{N} = Kn/k$, which does a fairly good job of getting the answer right, *under this $M$odel*.

In reality though, we know that the posited $M$odel of the world is very unrealistic: fish die, migrate, reproduce, favor certain spots, drop their tags, and avoid nets at different rates. So, if you were told you that the 3.5 million number came from the simple modelling exercise above, you would rightly distrust it. What fisheries scientists actually do is draw on a wealth of research to build  really complex and much more realistic $M$odels on computers, which are capable of simulating fish stocks. With those $M$odels and the imaginary but known fish populations they generate, we can test the performance of more sophisticated statistical modelling strategies. If the statistical models do a pretty good job of guessing the size of the imaginary fish populations, then we should feel more inclined to trust the numbers they give us when we go out and use them in the real world.

In other words, the distinction between $M$odels and modelling here gives us something quite profound: though we may never know how many fish are really in the ocean, we can know how many fish we *would* guess are in the ocean were our assumptions about the ocean correct. We never get to know if we guessed correctly, but we do get to know which guesses we should and should not trust, given the assumptions we are willing to make about the world. --> <!-- If our $M$odel seems plausible and the statistical modelling gives us decent answers on average, then maybe the answer we get when we apply that statistical model to real data is not all that bad. So, we have made an unanswerable question answerable, and we know the conditions under which the answer is good. --> <!-- In fact, this principle is pretty general:   -->



## Declaring exogenous and endogenous variables in the population


Remember from Chapter X that declaring a $M$odel means specifying exogenous and endogenous variables, how they are related to one another, and the probability distributions that determine which values the variables take. That might sound hard but it does not need to be. The following line of code contains a fully specified model:

```{r}
population <- declare_population(N = 8, e = runif(N), X = rnorm(N, e, 1)) 
```

An **exogenous variable** is one whose values do not depend on the values of any other variable in the $M$odel. 
Here, `e` is an exogenous variable: it is simply a random draw from the uniform distribution between 0 and 1, inclusive. So long as `N` stays fixed, no other variables influence the values that `e` takes on. 

An **endogenous variable** is one whose values *can* depend on another variable. Here, because `X` is defined as a function of the value that `e` takes, we say `X` is endogenous to its "parent," `e` (we use the term "parent" to describe the variables that appear in the function defining an endogenous variable). The code says that the value that `X` takes for a given individual is equal to a random draw from a normal distribution whose mean is equal to their value of `e` and whose standard deviation is equal to 1. <!-- Say, for example, that `e` took the value .35 for the fifth individual in the study.  In that case, the fifth individual will get a value of `X` that should be close to, but not exactly, .35.  --> <!-- Our model has two variables, one of which is uniformly distributed and the other of which is normally distributed, with the mean of `X` depending on the value of `e`. --> <!-- We refer to `e` as a parent of `X` because it appears in the expression for `X`.  -->

The population function we just declared generates random datasets with eight observations of `e` and `X`. Try running this code a few times to see:

```{r}
population()
```

As we will see below, the population function is a useful place to declare all of the exogenous variables and many of the endogenous variables in our study, along with some pretty complicated relationships between them. 

If we want to learn about our inferences, however, our model also has to define potential outcomes.

## Declaring potential outcomes

Remember from section X that potential outcomes are the building blocks of your inquiry---they describe counterfactual states of the world that could exist, depending on some parent variable. 

Say the parent variable is whether you are contacted by an election campaign canvasser. Then you might have at least two potential outcomes that depend on the value of this variable: whether you vote for their candidate when they contact you, on the one hand, and whether you vote for their candidate when they do not contact you, on the other. The difference in those two states of the world describes the treatment effect of the election campaign canvasser on your vote choice. 

Say we had a canvasser visit five out of ten households, selected at random. Then we could define potential outcomes as endogenous variables: one would encode the vote choice of the ten people if they were not contacted, the other would encode their vote choice if they were contacted. We call these variables the "untreated" and "treated" potential outcomes, respectively. We can add a third, and distinct, variable: the vote choice that we would actually observe in an experiment where we actually assigned half of the people to canvassing. To reiterate, if a researcher wants to declare a study with two treatment conditions and no spillovers, her model will have to include at least three variables:

1. The untreated potential outcome
2. The treated potential outcome
3. The observed outcome



That is why `DeclareDesign` has a whole step devoted to declaring potential outcomes. The `declare_potential_outcomes()` step is crucial because it splits up endogenous variables into the *counterfactual* sets of values they could take, given the variables they depend on. Consider this declaration:

```{r}
potential_outcomes <- declare_potential_outcomes(Y_Z_0 = .5 < e,
                                                 Y_Z_1 = .5 < e + .05)
```

Here, we have added two variables to the dataset, `Y_Z_0` and `Y_Z_1`. They are both endogenous, in the sense that they depend on the value that `e` takes and on the value that `Z` takes. In our framework, potential outcomes are labelled starting with the outcome (here, `Y`) followed by a specific parent variable whose effect we are interested in (here, `Z`), and the value that parent is set to (here `1` and `0`), all separated by underscores. 

So `Y_Z_1` is a list of the hypothetical values `Y` *could* take, if you were to set a specific variable it depends on, `Z`, to take the value of `1`. In English, the code in the potential outcomes declaration reads, "the value of $Y$ when $Z$ is zero is TRUE if $e$ is greater than .5 and FALSE otherwise, while the value of $Y$ when $Z$ is one is TRUE if $e$ plus .05 is greater than .5." So, setting $Z$ to one makes $Y$ roughly five percentage points more likely to be TRUE, on average. In math, we could write this: $Y_i(Z_i = 0) = \mathbb{I}(.5 < e_i)$ and $Y_i(Z_i = 1) = \mathbb{I}(.5 < e_i + .05)$. Notice that this provides a pretty easy expression for the observed outcome: $Y_i = \mathbb{I}(.5 < e_i + Z_i \times .05)$. So the potential outcomes for a variable can either be expressed by defining each potential outcome explicitly, as we do above, or through what we call a "potential outcomes function:"

```{r}
potential_outcomes <- declare_potential_outcomes(Y ~ .5 < e + .05 * Z)
```

By default, `declare_potential_outcomes()` assumes that the functional equation for `Y` will include a binary `Z` that it can split on to create `Y_Z_0` and `Y_Z_1`. But you can also tell the function to split on any other variables that take on any kind of value. For example, 
```{r}
potential_outcomes <- declare_potential_outcomes(
  income ~ employed + education + u, 
  assignment_variables = list(employed = c("No","Yes"), education = c(10,12)))
```
will create four new variables: `income_employed_No_education_10`, `income_employed_No_education_12`, `income_employed_Yes_education_10`, and `income_employed_Yes_education_12`. In this setup, `income` is the observed variable and the other four variables are the potential outcomes that would result from assigning individuals to the corresponding values of `employed` and `education`. The resultant function, `potential_outcomes`, knows not to create potential outcomes corresponding to values of `u` because `u` does not appear in the list of `assignment_variables`.

### Potential outcomes can include variables that are not yet defined

Careful readers may have picked up on something a bit confusing in the preceding paragraphs: we have defined potential outcomes in terms of a variable that has not yet been realized in our design.

```r
simple_design <- population + potential_outcomes + estimand + 
  sampling + assignment + reveal_outcomes + estimator
```

The potential outcomes `Y_Z_1` and `Y_Z_0` are already defined in terms of `Z` in the second step of our design, well before the variable `Z` gets created in the fifth step, `assignment`. 

How is this possible? Oddly, perhaps, the values of potential outcomes do not depend on the actual values that the parent variables happen to take^[Include reference to Pearl and truncation here? E.g. $Pr(Y~ \mid ~do(X)) ~~|| ~~Pr(X)$]---that is what makes them *potential* outcomes and not plain old outcomes. Imagine, for example, that your design involves assigning everyone to the control, so that $Z_i = 0~~\forall~~i$ in practice. In that case, we still define the treated potential outcome, $Y_i(Z_i = 1)$, exactly as before. We do not need to know what values `Z` will *actually* take in order to define the values that `Y` could *potentially* take.

What this requires at the model specification stage is some forwards-looking: you are going to need to model the imaginary states of the world that could happen before they happen. So, for example, if you have a different potential outcome depending on whether you are treated *and* whether you are sampled, then you need to define potential outcomes in terms of treatment assignment *and* sampling before either of these steps have occurred. More on this below. 

### When you do and do not need to define potential outcomes

So when should you split endogenous variables into all of the counterfactual values they can take on (potential outcomes), and when should you leave them whole? In other words, which variables belong in your `population` and which belong in your `potential_outcomes`? Why do we split on variables like `Z` and not on variables like `u` or `e`?

The short answer is that it all depends on your $I$nquiry. 

Let us take a simple example using the population declaration above. Suppose that you were interested in the average effect of $Z$ on $Y$, for any given value that $X$ can take: $E[Y_i(1) - Y_i(0)]$. Then your inquiry depends only on `Y_Z_1` and `Y_Z_0`. Those are the only potential outcomes you need.

What if you want to know the effect of $Z$ on $Y$ among groups for whom $X$ happened to equal 1 or happened to equal 0: $E[Y_i(1) - Y_i(0)\mid X_i = x]$. Here, you are not interested in the causal effect of `X`, just in whether, descriptively, the effect of `Z` on `Y` just happens to different among people for whom `X == 1`. There is no need to split on `X` in this case: you just need to look at the difference in `Y_Z_1` and `Y_Z_0` among the people for whom `X` is equal to 1 or to 0, which can be achieved through subsetting. 

Now, let us imagine that you were interested in the causal effects of both `X` and `Z` on `Y`. For example, you might want to know whether `X` *causes* the effects of `Z` on `Y` to be bigger: 
$$E[(Y_i(Z_i = 1,X_i = 1) - Y_i(Z_i = 0,X_i = 1)) - $$
$$~~~~~(Y_i(Z_i = 1,X_i = 0) - Y_i(Z_i = 0,X_i = 0))].$$
That is a claim about the counterfactual states of `Y` as a function of both variables, and would require something such as: 

```{r}
potential_outcomes <- declare_potential_outcomes(
  Y_X_0_Z_0 = .5 < e,
  Y_X_0_Z_1 = .5 < e + .05,
  Y_X_1_Z_0 = .5 < e,
  Y_X_1_Z_1 = .5 < e + .05 + .05)
```

Where `Y_X_0_Z_1`, for example, is a variable that lists every individual's potential `Y` outcome if `X` were set to 0 and `Z` were set to 1. In this example, we have stipulated that `X` increases the effect of `Z` by .05. To see this, note that we can rewrite the potential outcomes declaration above using a potential outcomes function: 

```{r,eval = FALSE}
declare_potential_outcomes(Y ~ .5 < e + Z * .05 + Z * X * .05, 
  assignment_variables = list(Z = 0:1, X = 0:1))
```

What if the value of $X$ were itself a function of $Z$, and your inquiry focused on the effect of $X$ on $Y$---$E[Y_i(X_i = 1) - Y_i(X_i = 0)]$? In that case, you might model two sets of potential outcomes: the potential outcomes of $X$ as a function of $Z$, and the potential outcomes of $Y$ as a function of $X$:

```{r}
potential_outcomes <- declare_potential_outcomes(
  X_Z_0 = .5 < e * 0.75,
  X_Z_1 = .5 < e * 1.25,
  Y_X_0 = .5 < e,
  Y_X_1 = .5 < e + .05)
```
Here, we are assuming `Z` is exogenous in the sense that it is randomly assigned. However, `X`, the causal variable of interest, is endogenous to `e` and to `Z`. In fact, if we are interested in the effect of `X` on `Y`, `e` is no longer background noise here as it was in the examples above: it has become a confounder of the causal effect in which we are interested . To see this, note that higher levels of `e` make both `X` and `Y` more likely to be TRUE. This is the sort of setup in which analysts would typically use an "instrumental variables" approach (callout to IV).^[One shortcoming of this $M$odel is that it has "baked in" the assumption of an exclusion restriction: `Y` is only affected by `Z` through `Z`'s effect on `X`---`Z` does not appear in the expression for `Y`. Returning to the fish example: showing that an instrumental variables answer strategy performs well under this $M$odel would not be convincing to someone who worried about a particular, unmodeled, violation of the exclusion restriction.]

In practice, there are always many many more potential outcomes lurking in your study than you need to model. Notice, for example, that we did not model the potential outcomes of `Y` as a function of specific levels of `e` above -- unless we care about the causal effect of `e` on some outcome, there is little reason to model the counterfactuals it gives rise to. In the following two sections, we walk through some more concrete advice on which kinds of potential outcomes you need to consider modelling. Specifically, we think you should focus on potential outcomes generated through two processes: manipulation and interference. <!-- One of the first questions to ask yourself is how many potential outcomes you want to $M$odel.   -->

### Manipulation creates potential outcomes 

Manipulation is some real or imagined intervention in the world that sets the values of a parent of one of your outcomes. Perhaps the most obvious manipulation is assignment to treatment---a coin flip, for example, is a manipulation that sets $Z$ to 1 for roughly half of the people and to 0 for the others. In quasi-experimental designs, we imagine a quasi-assignment: a non-random policy intervention might set some constituencies to have a change in their electoral rules and not others, for example. In that case, we imagine every constituency's potential outcome *had the policy intervention taken place there*, and vice versa.

But there are many other kinds of manipulations: measurement and sampling are two obvious examples. When you randomly sample someone and conduct a survey with them, you set their sampling status to "Sampled" and their measurement status to "Measured." In general, you should consider modeling any manipulation that might affect the value of your $I$nquiry.

A good rule of thumb is that there will be at least as many potential outcomes as the Cartesian product of the range of the manipulated variables. Let us suppose, for example, that you have a treatment variable with three values, $Z \in \{1,2,3\}$, and you think that there might be Hawthorne effects -- e.g., an effect of having your outcomes measured, $M \in \{0,1\}$. That implies you should have six potential outcomes, $Y_i(Z_i,M_i)$: $Y_i(1,0)$, $Y_i(2,0)$, $Y_i(3,0)$, $Y_i(1,1)$,$Y_i(2,1)$, and $Y_i(3,1)$. The first three represent states of the world revealed by assigning someone to the different arms of the treatment when they are not measured, and the latter three those same treatment outcomes when measured. The following potential outcomes declaration suggests a Hawthorne effect:

```{r,eval=FALSE}
hawthorne_POs <- declare_potential_outcomes(
  Y_Z_1_M_0 = .5 < e,
  Y_Z_2_M_0 = .5 < e + .05,
  Y_Z_3_M_0 = .5 < e + .05,
  Y_Z_1_M_1 = .5 < e + .05,
  Y_Z_2_M_1 = .5 < e + .05 + .05,
  Y_Z_3_M_1 = .5 < e + .05 + .05)
```

Note, however, that our design now requires some modifications: `simple_design` has an inquiry defined in terms of the simpler potential outcomes, `Y_Z_1` and `Y_Z_0`, which no longer exist. We need to clarify that we are interested in the effect of treatment without any measurement effects (here, we will say we are interested in the treatment 2 versus 1 comparison). Second, `simple_design` had no variable `M` to split on: we need a step in which we manipulate the measurement variable to be 1 for everyone in the sample. Finally, `simple_design` revealed `Y` purely as a function of `Z`, but we need to declare that the observed `Y` will correspond to the values of both `Z` and `M`: 

```{r,eval=FALSE}
assignment <- declare_assignment(conditions = c(1,2,3))
estimand_no_m <- declare_estimand(ate_2_no_m = mean(Y_Z_2_M_0 - Y_Z_1_M_0))
measurement <- declare_step(M = 1, handler = fabricate)
reveal_outcomes_measurement <- declare_reveal(Y, c(Z, M))
hawthorne_design <- population + hawthorne_POs + estimand_no_m + 
  sampling + assignment + measurement + reveal_outcomes_measurement + estimator
```

From here, it is easy to modify our design with measurement effects to stipulate a model in which there is an interaction between treatment and measurement---this is often referred to as an "experimenter demand" effect, and can be more problematic for inference than a simple Hawthorne effect (you can do some simple algebra with the estimand declaration to see why):

```{r,eval=FALSE}
experimenter_demand_POs <- declare_potential_outcomes(
  Y_Z_1_M_0 = .5 < e,
  Y_Z_2_M_0 = .5 < e + .05,
  Y_Z_3_M_0 = .5 < e + .05,
  Y_Z_1_M_1 = .5 < e,
  Y_Z_2_M_1 = .5 < e + .05 + .05,
  Y_Z_3_M_1 = .5 < e + .05 + .10)
demand_design <- replace_step(design = hawthorne_design, 
                              step = "hawthorne_POs",
                              new_step = experimenter_demand_POs) 
```

The very same logic can be applied to defining interactions between different treatment arms, effects from sampling, and other interactive effects. 

### Interference creates potential outcomes

We stated in the previous section that there are usually *at least* as many potential outcomes as the Cartesian product of the ranges of the manipulated parents. But that statement assumes that the value of each individual's potential outcome depends only on the value of their *own* parent variables. When one individual's potential outcomes depend on the value of a manipulated variable of any other unit in the study, we refer to this as "interference." Interference is a generic concept that includes social processes such as spillovers, social comparisons, contagion, communication, displacement, deterrence, and persistence [CITE GG p256-6]. Depending on your model, interference can generate a much, much larger space of potential outcomes. 

The formal notation for interference is that $Y_i(Z_i) \neq Y_i(\mathbf{Z})$. Here, $\mathbf{Z}$ denotes the entire vector of random assignments: the math says that an individual's potential outcome expressed in terms of their own assignment is not the same thing as their outcome expressed in terms of everyone's assignment. Accordingly, the most general potential outcomes model in the presence of interference is one in which every conceivable realization of $\mathbf{Z}$ is mapped to exactly one potential outcome.

Consider an employee-of-the-month experiment, in which one of three individuals is randomly assigned to be employee of the month (reference to GG). Suppose that employees 1 and 2 do not like each other. We will define potential outcomes in the following manner: $Y_i(j)$, where $j$ denotes the index of the treated individual. So, for example, $Y_2(3)$ is the potential outcome of the second individual when individual 3 is assigned to treatment. 


```{r}
interference_design  <- 
  declare_population(N = 3, e = runif(N)) +
  declare_potential_outcomes(
    Y_J_1 = c(.5 < e[1] + 1, .5 < e[2] - 1, .5 < e[3]),
    Y_J_2 = c(.5 < e[1] - 1, .5 < e[2] + 1, .5 < e[3]),
    Y_J_3 = c(.5 < e[1], .5 < e[2], .5 < e[3] + 1)) +
  declare_assignment(conditions = c("1","2","3"), assignment_variable = "J") +
  declare_step(Z = as.numeric(ID == J), handler = fabricate) +
  declare_reveal(Y, J) +
  declare_estimator(Y ~ Z, model = lm_robust)
```

Notice we did not declare an estimand here. That is because the inquiry in a design with interference requires particular attention (callout to inquiry section). 

As you can see, the space of potential outcomes can expand very quickly when we allow for every possible way in which the treatment can be assigned to affect outcomes differently. Under complete random assignment of $m$ of $N$ people to treatment or control, there are $N$ choose $m$ ways of assigning treatment, for example. For a simple design in which ten people are assigned to treatment and control in equal proportions, there are 252 potential outcomes to consider. The problem of specifying the potential outcomes in your $M$odel can quickly become intractable.

Often, we do not actually expect outcomes to differ quite so much: if there are 100 employees in the company and Sally does not know Jim or Tracy, she might be indifferent between the two worlds  in which either Jim or Tracy wins employee-of-the-month. Generalizing this principle, one might be able to cut down on the number of potential outcomes by considering spillovers limited to social networks within the company.

Where possible, a good way to handle spillovers is to specify a $M$odel in which they function like any other treatment. Such $M$odels rely on qualitative knowledge, which can be wrong. Let us say, for example, that you were worried about spillovers in an experiment, but: 1) you know that people's interactions are restricted by some ordering, such as a queue; 2) you strongly suspected that a person being treated only affects the outcomes of the next person in the queue, but not the person after. For example, if the treatment involved providing some randomly selected people in a queue with extra information and the outcome of interest was customer satisfaction, those who fall in the queue behind treated individuals might get frustrated at observing how long the person in front of them is taking. In this case, we can think of two treatments: $Z$, being directly treated, and $S$, having the person before you treated:

```{r,eval=FALSE}
spillover_POs <- declare_potential_outcomes(
  Y_Z_0_S_0 = .5 < e, 
  Y_Z_1_S_0 = .5 < e + .05,
  Y_Z_0_S_1 = .5 < e - .05 / 2, 
  Y_Z_1_S_1 = .5 < e + .05 / 2)
neighbors <- declare_step(next_neighbor = c(N,(1:(N-1))),
                          S = Z[next_neighbor], 
                          handler = fabricate)
reveal_spillovers <- declare_reveal(Y, c(Z, S))
spillover_design <- population + spillover_POs + 
  sampling + assignment + neighbors + reveal_spillovers + estimator 
```

Now, instead of $N$ choose $m$ potential outcomes, there are four---for any sample size. We have contained the problem of proliferating potential outcomes. Of course, showing that one's strategy is robust to the spillovers specified in this $M$odel might not be convincing to a skeptic who contends spillovers might also affect the second or third person behind the treated individual. Moreso than ever, the validity of inferences depend on the robustness of the $A$nswer strategy to plausible $M$odels. 

### What to do with potential outcomes whose parents are continuous

So far we have focused on potential outcomes whose parents take on discrete values. But another way in which potential outcomes can proliferate is if there are infinitely many places at which to consider splitting the outcome on the parent variable, as is the case with continuous parents.
[INCLUDE EXAMPLE FROM PAPER]

### Principal strata can be defined in terms of potential outcomes

One important set of $I$nquiries comprise estimands that are specific to certain  causal "types" in the population. For example, in designs in which not everyone assigned to treatment actually takes treatment, researchers are often interested in the treatment effect among those actually treated (often referred to as "compliers"). Similarly, in designs where some units do not report outcomes and where reporting is possibly a function of treatment, researchers are often interested in the effect among those who would report in either treatment or control. These causal types---referred to as "principal strata" in the literature [CITE imbens rubin]---can be usefully modeled in terms of potential outcomes.

Consider the case of one-sided non-compliance: 

```{r,eval=FALSE}
compliance_POs <- declare_potential_outcomes(
  D_Z_0 = 0,
  D_Z_1 = ifelse(order(e) > 4, 1, 0),
  Y_D_0 = .5 < e,
  Y_D_1 = .5 < e + .05)
ate_estimand <- declare_estimand(ate = mean(Y_D_1 - Y_D_0))
cace_estimand <- declare_estimand(cace = mean(Y_D_1 - Y_D_0), 
                                  subset = D_Z_0 == 0 & D_Z_1 == 1)
```

Here, treatment status, $D$, is a potential outcome of treatment assignment, $Z$. The CACE estimand is easily defined in terms of the causal type: it is the average effect among people for whom $D_i(Z_i = 0) =0, D_i(Z_i = 1) = 1$. 

Similarly, we can think of attrition as a potential outcome. Here, people with the lowest four values of `e` do not report outcomes if assigned to control, but everyone reports when they are assigned to treatment. Whenever someone does not report we only observe an `NA`. 


```{r,eval=FALSE}
attrition_POs <- declare_potential_outcomes(
  R_Z_0 = ifelse(order(e) <= 4, 1, 0),
  R_Z_1 = 1,
  Y_R_0_Z_0 = NA,
  Y_R_0_Z_1 = NA,
  Y_R_1_Z_0 = .5 < e,
  Y_R_1_Z_1 = .5 < e + .05)
```

### Develop a null model

You might be wondering whether $M$odels are simply a way of coding hypotheses. The two are similar but not quite the same: many $M$odels can correspond to the same hypothesis. One particularly important hypothesis is the so-called null hypothesis that the average effect of $Z$ on $Y$ is equal to zero. Consider the following three models: 

```{r}
population <- declare_population(N = 8, e = rnorm(N, 0, 1))
model_1 <- population + declare_potential_outcomes(Y ~ e)
model_2 <- population + declare_potential_outcomes(Y ~ e + e * 2 * Z)
model_3 <- population + declare_potential_outcomes(Y ~ ifelse(e > .5, Z * .2, -Z * .2))
```

Each of these models is consistent with the null hypothesis. In the first, treatment and control outcomes are exactly the same: $Z$ does not even appear in the functional equation for $Y$, there is no effect for any unit in the sample. This is sometimes referred to as a "sharp null hypothesis," and is a specific case of the more general null. In `model_2`, $Z$ increases the variance of $Y$, but because the mean of $e$ is 0, there is no average difference in the means of the treated and control outcomes: they are both zero. In `model_3`, there are large positive treatment effects for those with $e_i > .5$ and large negative treatment effects for those with $e_i \leq .5$. On average, the effects offset each other leading to an average effect of $Z$ on $Y$ that is equal to zero. Since there are infinitely many ways of parameterizing this average effect of zero (replace .2 with any number in `model_3`), there are infinitely many models that correspond to the single null hypothesis that the average effect of `Z` on `Y` is equal to zero. 

Despite the fact that there are many such null models to consider, and the fact that most researchers do not design a project expecting that null hypotheses are true, we see great value in declaring a so-called "null model." By "null model," we have in mind something like the potential outcomes in `model_1`: there is no relationship whatsoever between the outcome of interest and the treatment(s) of interest.

You can you learn at least three important things from a "null model" design, or "null design." 

First, the power of your null design is an important quantity: it is none other than the rate of false positives for your design, otherwise known as the type 1 error rate. It is important to know if the probability with which you (erroneously) reject the null of a zero average effect is equal to your $\alpha$: the rate at which you stipulate that you are comfortable erroneously rejecting the null (usually 5%). You might be quite happy to see that your non-null design exhibits great power with small effects, for example. But if you check your null design and see that your power is above 10%, then you know you have a problem: you are rejecting the null of no effect at twice the rate you should be for a stated error rate of 5%. 

Second, the ability to define the false positive rate for one estimator gives you  the ability to define the false positive rate over *all* of the estimators in your design. This is often referred to as the family-wise error rate: how often at least one of the tests you run erroneously rejects the null of no effect. If your tests are completely unrelated to one another, this rate will just be $\alpha^k$, where $k$ is the number of tests. But often rejecting one test implies you are more likely to reject another: if an erroneous rejection results from chance imbalance on a variable that is correlated with another variable tested against the same treatment, then you are likely to reject that test too. At the extreme, if you run $k$ equivalent tests, the familywise error rate will be 5%: rejecting one means you reject the rest, failing to reject one means failing to reject the rest. So, as we show in section X, if you use your actual realized data to generate a null design, you can figure out what your actual familywise error rate is under the global null of no effect for any unit or outcome. From there, you can figure out what testwise $\alpha$ you would need to apply in order to reject any test in the family 5% of the time. Often, this will be a lot less punitive than out-of-the-box corrections for multiple comparisons. 

Third, and maybe most importantly for practical purposes, a null design does not require any specification about effect sizes. A perennial issue in power analysis is that calculating power requires specification of some arbitrary effect size. But often the very reason we do a study is to determine what the size of an effect is. More meaningful, we think, is using diagnosis to determine the smallest effect you could detect with 80\% power. And for that, you only need a good estimate of the standard error, which does not depend on the effect size---it can be derived from a null design. When diagnosing a null design in order to calculate the MDE, it may be worth considering potential outcomes of the form declared in `model_2`: when trying to determine the standard error, it is important to consider whether the treatment may change the variance in the outcome, even if it does not change the mean. 

### Consider heterogeneity

- treatment effects may be stochastic---this can matter for variance estimation

- treatment effects may vary systematically---many otherwise unbiased designs become biased when this happens, so consider it by default

## Declaring populations

### Use data, if you have it

- can use it to estimate population parameters for RNGs
- can build off / bootstrap existing dataset
- start with a null design to calculate MDE 

### Incorporate hierarchy into your model

- Some examples of nested models 
- Time-series models 
- Stochastic group sizes

## Without a model you can get the answer pretty wrong

Of course, some research designs require much more $M$odel than others. In an experiment, we typically worry about everything that happens post-assignment when we draw up a $M$odel: attrition, compliance, and so forth. But in observational studies, in addition to those issues, the $M$odel for pretreatment variables can matter a lot. 

Take the simplest possible design, in which we want to know the effect of a non-randomly assigned treatment, $Z$, on $Y$. Say you have a pretreatment covariate, $X$, that is correlated with both $Z$ and $Y$. Should you control for $X$? 

Some authors might argue that, because the values of $X$ are realized prior to the values of $Z$ and time cannot flow backwards, $X$ is causally antecedent to $Z$ and so it follows you cannot do worse by including it. @rosenbaum2002observational, for instance, argues that "there is little to no reason to avoid adjustment for a true covariate, a variable describing subjects before treatment." However, as @greenland1999causal have shown, it turns out that if $Z$ and $Y$ are not confounded but $X$ and $Y$ are, then controlling for $X$ introduces additional spurious dependency between $Z$ and $Y$ that can create considerable bias. If the question is "should you control for $X$?" the answer is always "it depends on your $M$odel." 

So, you really need to specify a $M$odel: doing so helps determine the conditions under which your answers are credible. Without knowing the conditions under which we can believe your answers, it is hard to know whether to believe your answer. 

