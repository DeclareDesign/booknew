---
title: "Specifying the model"
output:
  html_document:
    toc: true
    toc_depth: 2
---

<!-- note do_bookdown is set in index.rmd, so we know if you are running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

# Specifying the model

<!-- make sure to rename the section title below -->

```{r specifying_the_model, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
library(dagitty)
library(ggdag)
library(ggraph)
```

In this chapter, we will talk about how to go about the tricky task of specifying a $M$odel and why it is so important to do so. 

We are not talking about "statistical models" used to estimate unknown parameters---those are part of your answer strategy. We are talking about specifying simulation models: a set of assumptions about how your data could be generated, encoded in math or computer language, which we can use to generate imaginary datasets. 



The distinction is a subtle but important one. We should only trust the inferences we draw from a statistical model if we think they would be good inferences to draw based on a plausible $M$odel of how the data was generated. 

$M$odels often lurk where you might not expect them. When researchers do experiments, they often compare the average observed outcome in the treatment group to the average observed outcome in the control group in order to get an estimate of the average treatment effect.^[...of putting one person in treatment and everyone else in control] This comparison requires no statistical modelling of the distributions of the observed variables: it follows from the fact that the average difference in two potential outcomes is equal to the difference in the averages of those two potential outcomes. So it seems as though such strategies are completely agnostic as to how the data was generated. 

Implicit in the very definition of the average treatment effect here, however, is a $M$odel: specifically, one in which any particular draw of the random assignment is able to reveal no more than two potential outcomes for any given individual---this is sometimes referred to as a "no spillovers" assumption. But many social processes violate this assumption. If I do something differently every time you get treated and I do not, then I have at least three potential outcomes: one in which I am treated, one in which neither of us are treated, and one in which you are treated but I am not. The average observed difference-in-means across random assignments might diverge quite substantially from the average effect we are interested in (say, of putting just one person in treatment and the rest in control). So even the simplest, most agnostic research design is relying on the plausibility of an implicit $M$odel in order to generate insights that are correct on average. 

In practice, we never get to know whether our $M$odel is right. For example, we can never really know how many potential outcomes there are. So we also cannot know if we got the right answer. What we can do, however, is study our procedure for generating answers under $M$odels of the world that we find plausible. That way, we do get to know which answers we should and should not trust, given the assumptions we are willing to make about the world.

## Two languages for describing causal models

[ better initial introduction to DAGs; DAG and PO intro for first timers ]

We make use of two different formal languages for describing causal models: DAGs and potential outcomes. DAGs are "directed acyclic graphs," where each node on a graph is a variable and the edges that connect them represent causal effects. DAGs emphasize a mechanical notion of causality: when the exposure variable changes, the outcome variable changes as a result. By contrast, the potential outcomes formalization emphasizes a counterfactual notion of causality. $Y_i(0)$ is the outcome for unit $i$ when the exposure variable is set to zero and $Y_i(1)$ is the outcome when it is set to one. The difference between them is the effect of the treatment on the outcome for unit $i$. Since at most only one potential outcome can ever be revealed, at least one of the two potential outcomes is necessarily counterfactual. Unrevealed potential outcomes are counter-to-facts; they do not exist. Nevertheless, the potential outcomes model is useful for thinking about what would have happened had things been different.

Despite what you may have inferred from the sometimes heated disagreements between scholars who prefer one formalization to the other, DAGs and potential outcomes are compatible systems for thinking about causality. A theorem in one language is a theorem in the other (CITE???). We use both languages because they are useful for expressing different facets of research design. We'll take the example of heterogeneous treatment effects to show how the two languages convey different aspects of the research setting.

The DAG below has just four variables. $Y$ is the outcome variable. It is affected by all of the other variables: $Z$, the treatment variable, $X$, a pre-treatment covariate, and $U$, an unobserved source of variation in both $X$ and $Y$. Possibly the most important thing that a DAG can teach us is which research questions are even answerable in a given seeting. Here, the causal relationship between $X$ and $Y$ is confounded. Since we have no information about what is in $U$, we can't learn about the effects of $X$ on $Y$. However, the treatment variable $Z$ has no edges leading in to it, which represents the idea that $Z$ is randomly assigned or otherwise exogenous. The DAG shows that even though we can't learn about the causal effects of $X$ on $Y$, we *can* learn about average causal effects of Z on Y. We could also draw descriptive inferences about the distributions of the observed variables like their ranges and averages or their variances and covariances.

```{r, echo = FALSE}
a_blue <- "#0072B2"
a_gray <- "grey80"

dag <-
  dagify(Y ~ X + Z + U,
         X ~ U,
         latent = "U")

gg_df <-
  tidy_dagitty(dag,
               layout = "manual",
               x = c(1, 0, -1, 1),
               y = c(1, 1, 0, 0))

gg_df <-
  gg_df %>%
  mutate(
    color = case_when(
      name == "U" ~ a_gray,
      name == "X" ~ a_blue,
      name == "Y" ~ a_blue,
      name == "Z" ~ a_blue
    )
  )


g <- 
ggplot(gg_df, aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_node(aes(color = color)) +
  scale_color_identity() +
  geom_dag_text(color = "black", family = "Helvetica") +
  geom_dag_edges() +
  theme_dag()

g
```

This DAG conveys beliefs about whether *whether* two variables are causally related, but it does not encode beliefs about *how* they are related. The DAG doesn't show whether the effects are positive or negative, large or small, constant or heterogeneous. For example, we can't read from the DAG whether the average effect of $Z$ should be higher or lower depending on whether $X$ is set to 0 or 1. This is no criticism of DAGs -- they just don't encode all of our causal beliefs about a system.

A potential outcomes representation of this same system can fill in some of the details. More specifically, we will make the two potential outcomes of $Y$ with respect to $Z$ explicit, since we are focused on the effects of $Z$ on $Y$. We will skip writing out the potential outcomes of $X$ and $Y$ with respect to $U$ to reduce complexity, though of course the causal process by which $U$ affects its descendant variables could also be represented in potential outcomes. 

The untreated potential outcome is written $Y_i(Z = 0)$ or $Y_i(0)$ for short. Likewise, $Y_i(Z = 1)$ (or $Y_i(1)$) is the treated potential outcome. Notice that the *potential* outcomes don't appear on the DAG -- only the revealed outcome $Y_i$ does. That's because the revealed $Y_i$ is the output of a causal process that switches which potential outcome is revealed depending on the level of the treatment variable. The so-called "switching equation" can be written like this:

$$
Y_i = \begin{cases} 
      Y_i(0) & Z = control \\
      Y_i(1) & Z = treatment \\
   \end{cases}
$$

Sometimes the switching equation is written in a more compact algebraic form: $Y_i = Z * Y_i(1) + (1 - Z) * Y_i(0)$. This expression works because in the treatment condition, Z is equal to 1, so the second half of the expression is zeroed out, and $Y_i = Y_i(1)$. In the control condition, Z is equal to 0, so the first half of the expression is zeroed out. This works fine for binary treatment variables, but the piecewise notation extends more naturally to additional potential outcomes (treatment 1, treatment 2, placebo, etc). 

```
[INSET BOX on the Fundamental Problem of Causal Inference]
The switching equation underlines the fact that at most, we can only observe the one potential outcome that happened to be revealed by the world. We either see $Y_i(1)$ or $Y_i(0)$, but we can never see both. This problem has famously been dubbed the "Fundamental Problem of Causal Inference" (Holland 1986). The problem is indeed fundamental and common to all causal inference settings. 

That said, the FUndamental Problem of Causal Inference is more *severe* in some settings than others. Consider the causal inference problem of measuring the average causal effect of a light switch on the lamp turning on. Suppose we flip the switch on at exactly 2020-07-08 12:33:38 EDT and the lamp illuminates. We literally can't know whether the lamp would be on or off if the switch were in the off position at exactly that moment -- that's the Fundamental Problem of Causal Inference at work. But we can nevertheless get a good sense of the average effect of the switch on the lamp by flicking it back and forth a few times. Conditional on everything else in the system working (the electricity to the house, the lightbulb filament, etc), the average effect of the switch on illumination is 100 percentage points. The fundamental problem just isn't a big deal in this case because we have fine control over the causal variable (the switch) and the outcome variable (is the light on?) is measured perfectly. 

Most social scientific research questions are much harder. Measuring the average effect of university education on earnings, for example, is a notoriously difficult research task. First, different kinds of people do and don't attend university; those who do attend have different experiences and develop different social networks; those who don't attend university *also* have heterogeneous experiences in their early careers. The Fundamental Problem of Causal Inference is quite severe in this case because it is very hard to know what the lives of well-educated offices worker would have been like had they not gone to college. 
```

Potential outcomes notation is especially useful for defining *estimands*. Estimands are the inferential target -- what we call the Inquiry in the MIDA framework. The most common estimand is the Average Treatment Effect (ATE), which is written like this^[The expectation operator $E[]$ is a way of describing the average of a random variable. In general, $E[X] = \sum_{x \in X} x * pr(X = x)$. Here we are slightly abusing the notation, since in a fixed population, $Y_i(1)$ and $Y_i(0)$ are not random variables. We could write the ATE as $\frac{1}{N}\sum_1^N Y_i(1) - Y_i(0)$, or we could just imagine that we drawing one unit at random from the fixed population; the expectation operator can be defined with respect to this imaginary random variable in order to save ourselves some notational headaches.]:

$$
ATE \def E[Y_i(1) - Y_i(0)]
$$

We want to emphasize that the ATE is an *average*. The difference between $Y_i(1)$ and $Y_i(0)$ for unit $i$ is an individual-level treatment effect (sometimes we'll refer to $Y_i(1) - Y_i(0)$ as $\tau_i$). The ATE averages over all of the individual-level treatment effects in the relevant population. Some units will have a $tau_i$ that is higher than the ATE, some will have a $\tau_i$ that is lower. We emphasize this because sometimes people mistakenly thing that by focusing on an ATE, researchers are "assuming" that everyone experiences the same treatment effect. This is not true. The ATE is just a single-number summary of a possibly very heterogeneous set of responses to treatment.

We can also use potential outcomes notation to define other, more complicated estimands. Throughout the book, we'll describe a series of them -- local average treatment effects, average treatment effects on the treated, average direct effects, average indirect effects, and spillover effects, to name a few -- all using potential outcomes notation. 

In the next example, we'll illustrate how using both DAGs and potential outcomes together, we can describe and learn about research designs in a more complete way. The DAG above encodes the beliefs that $Y$ is a function of $Z$, $X$, and $U$ and also that we can learn about the effects of $Z$ on $Y$ but not $X$ on $Y$. The DAG is silent, however, on the question of whether the effect of $Z$ is on average different for units with different values of $X$. In other words, the DAG doesn't reflect beliefs about treatment effect heterogeneity. 

Using potential outcomes, we can write down three new estimands: the conditional average treatment effect (CATE) of $Z$ on $Y$ for units with $X = 1$, the CATE among units with $X = 0$, and the difference-in-cates:

$$
\begin{align}
CATE_{(X = 1)} &\def E[Y_i(1) - Y_i(0) | X = 1] \\
CATE_{(X = 0)} &\def E[Y_i(1) - Y_i(0) | X = 0] \\
Diff-in-CATEs &\def E[Y_i(1) - Y_i(0) | X = 1] - E[Y_i(1) - Y_i(0) | X = 0]
\end{align}
$$

Suppose we think that the effect of treatment is larger for units with $X = 1$, which is to say we think the difference-in-cates is positive. We can supplement the DAG representation of the causal model with a design declaration that includes these beliefs.

```{r}
diff_in_cates <- 0.5
design <-
  declare_population(N = 100,
                     U = rnorm(N),
                     X = rbinom(N, 1, prob = pnorm(0.5 * U + rnorm(N)))) +
  declare_potential_outcomes(Y ~ 0.5 * X + 0.5 * Z + diff_in_cates * X * Z + 0.5 * U) +
  declare_estimands(
    ATE = mean(Y_Z_1 - Y_Z_0),
    CATE_1 = mean(Y_Z_1[X == 1] - Y_Z_0[X == 1]),
    CATE_0 = mean(Y_Z_1[X == 0] - Y_Z_0[X == 0]),
    DiC = mean(Y_Z_1[X == 1] - Y_Z_0[X == 1]) - mean(Y_Z_1[X == 0] - Y_Z_0[X == 0])
  )
```


```{r, echo = FALSE}
design %>% draw_estimands %>% kable
```

We could incorporate different beliefs about the causal model by changing the `diff_in_cates` parameter. However, notice that regardless of the value of the interaction (either zero or some other number), the DAG looks the same. So if you want to design your study for the difference-in-CATEs, then you'll need to go beyond the DAG to write down your beliefs about the extent of heterogeneity using another tool.

DAGs and potential outcomes are two languages for expressing beliefs about causality. The DAG formulation emphasizes a mechanistic understanding of causal systems: if I change this here, that will change there. The potential outcomes formulation emphasizes counterfactuals: we can either observe what happens there if I change this here or if I don't, but not both. The two languages are useful for describing different parts of a research design. DAGs excel at describing whole causal models and indicate which variables we can learn the causal effects of. Potential outcomes are useful for precisely defining causal estimands like the ATE, the CATEs, and the difference-in-CATEs. Design declaration uses the language of potential outcomes in order to encode more specific beliefs (such as beliefs about heterogeneity) than can be represented on the DAG.


## Example section

```{r cholera-declaration}
tau <- 0.15
cutoff <- 0.5
bandwidth <- 0.5

polynom_func <- function(x, coefs){ 
  as.vector(poly(x, length(coefs), raw = T) %*% coefs)
}

cholera_design <- 
  declare_population(
    houses = add_level(
      N = 1722,
      pump_border_distance = runif(N, 0, 1) - cutoff, 
      bsp = if_else(pump_border_distance > 0, 1, 0),
      noise = rnorm(N, mean = 0, sd = 0.1)
    )
  ) +
  
  declare_potential_outcomes(
    ln_prices_1864_bsp_0 = polynom_func(pump_border_distance, coefs = c(0.5, 0.5)) + noise, 
    ln_prices_1864_bsp_1 = polynom_func(pump_border_distance, coefs = c(-5, 1)) + tau + noise
  ) + 
  
  declare_estimand(
    LATE_bsp = (polynom_func(0, coefs = c(-5, 1)) + tau) - polynom_func(0, coefs = c(0.5, 0.5))) + 
  
  declare_reveal(ln_prices_1864, bsp) + 
  
  declare_estimator(
    ln_prices_1864 ~ stats::poly(pump_border_distance, degree = 4) * bsp, 
    subset = (pump_border_distance > 0 - abs(bandwidth)) & pump_border_distance < 0 + abs(bandwidth),
    model = lm_robust, 
    term = "bsp", estimand = "LATE_bsp")
  
diagnose_design(cholera_design, sims = 500)
```

```{r, fig.width = 4, fig.height = 3}
pro_con_colors <- c("#C67800", "#205C8A")
mock_data <- draw_data(cholera_design)
pump_border_distance <- seq(-.5,.5,.005)
treatment_frame <- data.frame(
  pump_border_distance = pump_border_distance,
  ln_prices_1864 = polynom_func(pump_border_distance, coefs = c(-5, 1)),
  observed = if_else(pump_border_distance > 0, "a", "b"),
  bsp = 1
  )
control_frame <- data.frame(
  pump_border_distance = pump_border_distance,
  ln_prices_1864 = polynom_func(pump_border_distance, coefs = c(0.5, 0.5)),
  observed = if_else(pump_border_distance <= 0, "a", "b"),
  bsp = 0
  )
plot_frame <- bind_rows(treatment_frame, control_frame)

ggplot(plot_frame, aes(x = pump_border_distance, y = ln_prices_1864, color = as.factor(bsp))) +
  geom_line(aes(linetype = observed)) +
  geom_point(data = mock_data, alpha = .2, size = .5) +
  scale_linetype_discrete(name = "", labels = c("Observable", "Unobservable")) +
  scale_color_manual(
    name = "",
    labels = c("Untreated", "Treated"),
    values = pro_con_colors
  ) +
  geom_vline(xintercept = 0, size = .05) +
  ylab("Ln House Prices (1864)") + 
  xlab("Distance from Broad Street Pump Coverage Boundary") +
  geom_segment(aes(
    x = 0,
    xend = 0,
    y = polynom_func(0, coefs = c(0.5, 0.5)),
    yend = polynom_func(0, coefs = c(-5, 1))
  ), color = "black") +
  dd_theme()
```


## Connections to MIDA


## Specifying a model in DeclareDesign

### Declaring exogenous and endogenous variables in the population

Declaring a $M$odel means specifying exogenous and endogenous variables, how they are related to one another, and the probability distributions that determine which values the variables take. That might sound hard but it does not need to be. The following line of code contains a fully specified model:

```{r}
population <- declare_population(N = 8, e = runif(N), X = rnorm(N, mean = e, sd = 1)) 
```

An **exogenous variable** is one whose values do not depend on the values of any other variable in the $M$odel. 
Here, `e` is an exogenous variable: it is simply a random draw from the uniform distribution between 0 and 1, inclusive. So long as `N` stays fixed, no other variables influence the values that `e` takes on. 

An **endogenous variable** is one whose values *can* depend on another variable. Here, because `X` is defined as a function of the value that `e` takes, we say `X` is endogenous to its "parent," `e` (we use the term "parent" to describe the variables that appear in the function defining an endogenous variable). The code says that the value that `X` takes for a given individual is equal to a random draw from a normal distribution whose mean is equal to their value of `e` and whose standard deviation is equal to 1.

The population function we just declared generates random datasets with eight observations of `e` and `X`. Try running this code a few times to see:

```{r}
population()
```

As we will see below, the population function is a useful place to declare all of the exogenous variables and many of the endogenous variables in our study, along with some pretty complicated relationships between them. 

If we want to learn about our inferences, however, our model also has to define potential outcomes.

### Declaring potential outcomes

Remember from section X that potential outcomes are the building blocks of your inquiry---they describe counterfactual states of the world that could exist, depending on some parent variable. 

Say the parent variable is whether you are contacted by an election campaign canvasser, who tries to convince you to vote for Jane Doe, a candidate running in your district. Then you might have at least two potential outcomes that depend on the value of this variable: whether you vote for Jane Doe when a canvasser from her campaign contacts you, on the one hand, and whether you vote for Jane Doe when that canvasser does not contact you, on the other. The difference in those two states of the world describes the treatment effect of the election campaign canvasser on whether you vote for Jane Doe.

Say we did an experiment in which that canvasser visits five out of ten people who answer doors, selected at random. Then we could define the potential outcomes of the people they visit as endogenous variables: the "untreated" potential outcome of the experiment would encode whether each door-answerer would vote for Jane Doe if they were not contacted by the canvasser, and the "treated" potential ouctcome would encode whether they vote for Jane Doe if they _were_ contacted by the canvasser. 

In addiiton to the untreated and treated potential outcomes of this experiment, we can add a third, distinct, variable: the vote choice that we would actually observe in an experiment where we actually assigned half of the people to canvassing. To reiterate, if a researcher wants to declare a study with two treatment conditions and no spillovers, her model will have to include at least three variables:

1. The untreated potential outcome
2. The treated potential outcome
3. The observed outcome

That is why `DeclareDesign` has a whole step devoted to declaring potential outcomes. The `declare_potential_outcomes()` step is crucial because it splits up endogenous variables into the *counterfactual* sets of values they could take, given the variables they depend on. Consider this declaration:

```{r}
potential_outcomes <- declare_potential_outcomes(Y_Z_0 = .5 < e,
                                                 Y_Z_1 = .5 < e + .05)
```

Here, we have added two variables to the dataset, `Y_Z_0` and `Y_Z_1`. They are both endogenous, in the sense that they depend on the value that `e` takes and on the value that `Z` takes.^[In `DeclareDesign`, potential outcomes are labelled starting with the outcome (here, `Y`) followed by a specific parent variable whose effect we are interested in (here, `Z`), and the value that parent is set to (here `1` and `0`), all separated by underscores.] 

So `Y_Z_1` is a list of the hypothetical values `Y` *could* take, if you were to set a specific variable it depends on, `Z`, to take the value of `1`. Suppose, for example, that `e` represents a person's utility from voting for Jane Doe. Then, the code says that each person will vote for Jane Doe if `e` is greater than .5 when they're untreated, and if they are treated, they vote for Jane Doe when `e + .05` is greater than .5. So, the $M$odel stipulates that canvassing makes people roughly five percentage points more likely to vote for Jane Doe.

A variable's potential outcomes can either be expressed by defining each potential outcome explicitly, as we do above, or through what we call a "potential outcomes function:"

```{r}
potential_outcomes <- declare_potential_outcomes(Y ~ .5 < e + .05 * Z)
```

By default, `declare_potential_outcomes()` assumes that the functional equation for `Y` will include a binary `Z` that it can split on to create `Y_Z_0` and `Y_Z_1`. But you can also tell the function to split on any other variables that take on any kind of value. For example, 
```{r}
potential_outcomes <- declare_potential_outcomes(
  income ~ employed + education + u, 
  assignment_variables = list(employed = c("No","Yes"), education = c(10,12)))
```
will create four new variables: `income_employed_No_education_10`, `income_employed_No_education_12`, `income_employed_Yes_education_10`, and `income_employed_Yes_education_12`. In this setup, `income` is the observed variable and the other four variables are the potential outcomes that would result from assigning individuals to the corresponding values of `employed` and `education`. The resultant function, `potential_outcomes`, knows not to create potential outcomes corresponding to values of `u` because `u` does not appear in the list of `assignment_variables`.

INCLUDE HETEROGENEITY DISCUSSION HERE

### Potential outcomes often include variables that are not yet defined

Careful readers may have picked up on something a bit confusing in the preceding paragraphs: we have defined potential outcomes in terms of a variable that has not yet been realized in our design.

```r
simple_design <- population + potential_outcomes + estimand + 
  sampling + assignment + reveal_outcomes + estimator
```

The potential outcomes `Y_Z_1` and `Y_Z_0` are already defined in terms of `Z` in the second step of our design, well before the variable `Z` gets created in the fifth step, `assignment`. 

How is this possible? Oddly, perhaps, the values of potential outcomes do not depend on the actual values that the parent variables happen to take^[Include reference to Pearl and truncation here? E.g. $Pr(Y~ \mid ~do(X)) ~~|| ~~Pr(X)$]---that is what makes them *potential* outcomes and not plain old outcomes. Imagine, for example, that your design involves assigning everyone to the control, so that $Z_i = 0~~\forall~~i$ in practice. In that case, we still define the treated potential outcome, $Y_i(Z_i = 1)$, exactly as before. We do not need to know what values `Z` will *actually* take in order to define the values that `Y` could *potentially* take.

What this requires at the model specification stage is some forwards-looking: you are going to need to model the imaginary states of the world that could happen before they happen. So, for example, if you have a different potential outcome depending on whether you are treated *and* whether you are sampled, then you need to define potential outcomes in terms of treatment assignment *and* sampling before either of these steps have occurred. More on this below. 

### When you do and do not need to define potential outcomes

So when should you split endogenous variables into all of the counterfactual values they can take on (potential outcomes), and when should you leave them whole? In other words, which variables belong in your `population` and which belong in your `potential_outcomes`? Why do we split on variables like `Z` and not on variables like `u` or `e`?

The short answer is that it all depends on your $I$nquiry. 

Let us take a simple example using the population declaration above. Suppose that you were interested in the average effect of $Z$ on $Y$, for any given value that $X$ can take: $E[Y_i(1) - Y_i(0)]$. Then your inquiry depends only on `Y_Z_1` and `Y_Z_0`. Those are the only potential outcomes you need.

What if you want to know the effect of $Z$ on $Y$ among groups for whom $X$ happened to equal 1 or happened to equal 0: $E[Y_i(1) - Y_i(0)\mid X_i = x]$. Here, you are not interested in the causal effect of `X`, just in whether, descriptively, the effect of `Z` on `Y` just happens to different among people for whom `X == 1`. There is no need to split on `X` in this case: you just need to look at the difference in `Y_Z_1` and `Y_Z_0` among the people for whom `X` is equal to 1 or to 0, which can be achieved through subsetting. 

Now, let us imagine that you were interested in the causal effects of both `X` and `Z` on `Y`. For example, you might want to know whether `X` *causes* the effects of `Z` on `Y` to be bigger: 
$$E[(Y_i(Z_i = 1,X_i = 1) - Y_i(Z_i = 0,X_i = 1)) - $$
$$~~~~~(Y_i(Z_i = 1,X_i = 0) - Y_i(Z_i = 0,X_i = 0))].$$
That is a claim about the counterfactual states of `Y` as a function of both variables, and would require something such as: 

```{r}
potential_outcomes <- declare_potential_outcomes(
  Y_X_0_Z_0 = .5 < e,
  Y_X_0_Z_1 = .5 < e + .05,
  Y_X_1_Z_0 = .5 < e,
  Y_X_1_Z_1 = .5 < e + .05 + .05)
```

Where `Y_X_0_Z_1`, for example, is a variable that lists every individual's potential `Y` outcome if `X` were set to 0 and `Z` were set to 1. In this example, we have stipulated that `X` increases the effect of `Z` by .05. To see this, note that we can rewrite the potential outcomes declaration above using a potential outcomes function: 

```{r,eval = FALSE}
declare_potential_outcomes(Y ~ .5 < e + Z * .05 + Z * X * .05, 
  assignment_variables = list(Z = 0:1, X = 0:1))
```

What if the value of $X$ were itself a function of $Z$, and your inquiry focused on the effect of $X$ on $Y$---$E[Y_i(X_i = 1) - Y_i(X_i = 0)]$? In that case, you might model two sets of potential outcomes: the potential outcomes of $X$ as a function of $Z$, and the potential outcomes of $Y$ as a function of $X$:

```{r}
potential_outcomes <- declare_potential_outcomes(
  X_Z_0 = .5 < e * 0.75,
  X_Z_1 = .5 < e * 1.25,
  Y_X_0 = .5 < e,
  Y_X_1 = .5 < e + .05)
```
Here, we are assuming `Z` is exogenous in the sense that it is randomly assigned. However, `X`, the causal variable of interest, is endogenous to `e` and to `Z`. In fact, if we are interested in the effect of `X` on `Y`, `e` is no longer background noise here as it was in the examples above: it has become a confounder of the causal effect in which we are interested . To see this, note that higher levels of `e` make both `X` and `Y` more likely to be TRUE. This is the sort of setup in which analysts would typically use an "instrumental variables" approach (callout to IV).^[One shortcoming of this $M$odel is that it has "baked in" the assumption of an exclusion restriction: `Y` is only affected by `Z` through `Z`'s effect on `X`---`Z` does not appear in the expression for `Y`. Returning to the fish example: showing that an instrumental variables answer strategy performs well under this $M$odel would not be convincing to someone who worried about a particular, unmodeled, violation of the exclusion restriction.]

In practice, there are always many many more potential outcomes lurking in your study than you need to model. Notice, for example, that we did not model the potential outcomes of `Y` as a function of specific levels of `e` above -- unless we care about the causal effect of `e` on some outcome, there is little reason to model the counterfactuals it gives rise to. In the following two sections, we walk through some more concrete advice on which kinds of potential outcomes you need to consider modelling. Specifically, we think you should focus on potential outcomes generated through two processes: manipulation and interference. 

### Using existing information (pilot data, past studies)
### What to do when you are uncertain

We are always uncertain about model parameters. You can directly incorporate this into the process in two ways: (1) incorporate uncertainty into the model, by instead of selecting a scalar parameter value integrating over all the possible ones; (2) redesign to alternative models and diagnose your design under those several possibilities. 


## How you already specify models in everyday research

-- directional hypothesis
-- assert a DGP to justify a parametric model
-- claims justifying functional form and inclusion of controls
-- agnostic and nonparametric statistics tries to assume less -- but what do they still assume?
-- selection on observables mostly is in M (I assert there is no additional confounding)

goal here is not to point out that we should never make assumptions about the causal model, but rather we should be clear what they are and how those assumptions shape the choices we make as researchers in D and A


