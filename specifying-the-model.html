<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 6 Specifying the model | Research Design: Declare, Diagnose, Redesign</title>
<meta name="author" content="Graeme Blair, Jasper Cooper, Alexander Coppock, and Macartan Humphreys">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.2.9000/tabs.js"></script><script src="libs/bs3compat-0.2.2.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<link href="libs/bs4_book-1.0.0/dd_imgpopup.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/bs4_book-1.0.0/dd_imgpopup.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://hypothes.is/embed.js" async></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Research Design: Declare, Diagnose, Redesign</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li class="book-part">Introduction</li>
<li><a class="" href="preamble.html"><span class="header-section-number">1</span> Preamble</a></li>
<li><a class="" href="improving-research-designs.html"><span class="header-section-number">2</span> Improving research designs</a></li>
<li><a class="" href="primer.html"><span class="header-section-number">3</span> Software primer</a></li>
<li><a class="" href="part-i-exercises.html"><span class="header-section-number">4</span> Part I Exercises</a></li>
<li class="book-part">Declaration, Diagnosis, Redesign</li>
<li><a class="" href="declaration.html"><span class="header-section-number">5</span> Declaration</a></li>
<li><a class="active" href="specifying-the-model.html"><span class="header-section-number">6</span> Specifying the model</a></li>
<li><a class="" href="defining-the-inquiry.html"><span class="header-section-number">7</span> Defining the inquiry</a></li>
<li><a class="" href="crafting-a-data-strategy.html"><span class="header-section-number">8</span> Crafting a data strategy</a></li>
<li><a class="" href="choosing-an-answer-strategy.html"><span class="header-section-number">9</span> Choosing an answer strategy</a></li>
<li><a class="" href="p2diagnosis.html"><span class="header-section-number">10</span> Diagnosis</a></li>
<li><a class="" href="redesign-2.html"><span class="header-section-number">11</span> Redesign</a></li>
<li><a class="" href="part-ii-exercises.html"><span class="header-section-number">12</span> Part II Exercises</a></li>
<li class="book-part">Research Design Library</li>
<li><a class="" href="research-design-library.html"><span class="header-section-number">13</span> Research Design Library</a></li>
<li><a class="" href="observational-designs-for-descriptive-inference.html"><span class="header-section-number">14</span> Observational designs for descriptive inference</a></li>
<li><a class="" href="experimental-designs-for-descriptive-inference.html"><span class="header-section-number">15</span> Experimental designs for descriptive inference</a></li>
<li><a class="" href="observational-designs-for-causal-inference.html"><span class="header-section-number">16</span> Observational designs for causal inference</a></li>
<li><a class="" href="experimental-designs-for-causal-inference.html"><span class="header-section-number">17</span> Experimental designs for causal inference</a></li>
<li><a class="" href="multi-study-designs.html"><span class="header-section-number">18</span> Multi-study designs</a></li>
<li><a class="" href="part-iii-exercises.html"><span class="header-section-number">19</span> Part III Exercises</a></li>
<li class="book-part">Research Design Lifecycle</li>
<li><a class="" href="research-design-lifecycle.html"><span class="header-section-number">20</span> Research Design Lifecycle</a></li>
<li><a class="" href="part-iv-exercises.html"><span class="header-section-number">21</span> Part IV Exercises</a></li>
<li><a class="" href="references-4.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="specifying-the-model" class="section level1">
<h1>
<span class="header-section-number">6</span> Specifying the model<a class="anchor" aria-label="anchor" href="#specifying-the-model"><i class="fas fa-link"></i></a>
</h1>
<!-- make sure to rename the section title below -->
<p>Any research design – whether the research question is fundamentally causal or descriptive – implicitly relies on models. Indeed models can enter at multiple stages, for example in guiding the research question or in the analysis stage. Here we focus on the role of models in providing a background understanding of how the world works, against which the performance of a design can be assessed. We call these “<strong>reference models</strong>” (to be distinguished from analytic models later). Their role is to provide a stipulation of how the world works—for instance — what variables are important and how do they interrelate—allowing us to ask questions such as: if the reference model were true, what would the answer to my question be and would I be able to figure out the answer?</p>
<p>The <span class="math inline">\(M\)</span> in MIDA refers to these reference models. As we describe below we often think of <span class="math inline">\(M\)</span> as a set of models, with typical element <span class="math inline">\(m\)</span> though in some cases the <span class="math inline">\(M\)</span> may just be a single model.</p>
<!-- Even if the model is hazy, researchers carry with them a model of the world that could in principle be expressed as a probablistic causal model. As described in the previous chapter, probabalistic causal models are described by a set of exogeneous and endogenous variables, a set of functional relationships between the variables, and a probability distribution over the exogenous variables. -->
<p>Critically, whether a design is good or bad depends on the reference model. A data and analysis strategy might fare very well under one model of the world but poorly under another. Thus to get to the point where we can assess a design we need to make the reference model—or in many cases, the family of reference models—explicit. This chapter is about how to go about this difficult task.</p>
<p>We’ll make use of two different formal languages for describing causal models: DAGs and potential outcomes.</p>
<p>The <strong>potential outcomes</strong> formalization emphasizes a counterfactual notion of causality. <span class="math inline">\(Y_i(Z = 0)\)</span> is the outcome for unit <span class="math inline">\(i\)</span> that <em>would</em> occur <em>were</em> the causal variable equal to zero and <span class="math inline">\(Y_i(Z = 1)\)</span> is the outcome that would occur if <span class="math inline">\(Z\)</span> were set to one. The difference between them defines the effect of the treatment on the outcome for unit <span class="math inline">\(i\)</span>. Since at most only one potential outcome can ever be revealed, at least one of the two potential outcomes is necessarily counterfactual. Usually, the potential outcomes notation <span class="math inline">\(Y_i(Z)\)</span> reports how outcomes depend on one feature – <span class="math inline">\(Z\)</span>, ignoring all other determinants of outcomes. This is not to say that these don’t matter, they do, they are just not the focus. In a sense they are contained in the subscript <span class="math inline">\(i\)</span> since the units carry with them all relevant features other than <span class="math inline">\(Z\)</span>. We can, and will generalize to settings where we want to focus on more than one cause, in which case we use expressions of the form <span class="math inline">\(Y(0,0)\)</span> or <span class="math inline">\(Y(0,1)\)</span>.</p>
<p>The <strong>graphical model</strong> formulation approach makes use of DAGs or “directed acyclic graphs” to characterize causal relations. Each node on a graph is a variable and the edges that connect them represent possible causal effects. An arrow from a “parent” node to a “child” node indicates that the value of the parent sometimes determines the outcome of the child; more formally: the parent’s value is an argument in a functional equation determining the child’s outcome. Though consistent with a counterfactual notion of causality, DAGs emphasize mechanistic accounts: when the exposure variable changes, the outcome variable changes as a result—though possibly in different ways for different units. DAGs are <em>nonparametric</em>. This means that they do not encode all the beliefs about the full causal model. They don’t show <em>how</em> variables are related, just <em>that</em> they are related.</p>
<p>Defining a reference model requires both defining a set of variables (their meaning and their ranges) and stipulating how they relate to each other. In the potential outcomes framework these are captured by differences in potential outcomes under different conditions. In the graphical modeling literature we define a set of nonparametric structural causal relationships, indicating which variables depend on which other variables. With these variables in hand, we can visualize the model using a directed acyclic graph (DAG).</p>
<p>Despite what you may have inferred from the sometimes heated disagreements between scholars who prefer one formalization to the other, DAGs and potential outcomes are compatible systems for thinking about causality. We <em>could</em> use only the language of causal graphs or we <em>could</em> use only the language of potential outcomes. We choose to use both languages because they are useful for expressing different facets of research design. We use DAGs to describe the web of causal interrelations in a concise way (writing out the potential outcomes for every relationship in the model is tedious). We use potential outcomes when we want to zoom in on <em>particular</em> causal relationships and to make fine distinctions between inquiries that apply to different sets of units (it’s difficult to describe effect heterogeneity with graphical models).</p>
<p>We illustrate these ideas using a simple DAG to describe a model with an abstract research design in which we will collect information about <span class="math inline">\(N\)</span> units. We will assign a treatment at random <span class="math inline">\(Z\)</span>, and collect a posttreatment outcome <span class="math inline">\(Y\)</span>. We know there are other determinants of the outcome beyond <span class="math inline">\(Z\)</span>, but we don’t need to write down our beliefs about them because our main inquiry is the average treatment effect of <span class="math inline">\(Z\)</span> on <span class="math inline">\(Y\)</span>. All we’ll say about those other determinants is that they are causally related to <span class="math inline">\(Y\)</span>, but not to <span class="math inline">\(Z\)</span>, since <span class="math inline">\(Z\)</span> will be randomly assigned by us.
<!-- Following the rule that we only need to make explicit the parts of our causal model that are required for the inquiry, data strategy, and answer strategy, this bare specification is sufficient. --></p>
<p>The nonparametric structural equation determining <span class="math inline">\(Y\)</span> can be written like this:</p>
<p><span class="math display">\[\begin{align*}
Y &amp;= f_Y(Z, U)
\end{align*}\]</span></p>
<p>A parametric structural equation can be written like this:</p>
<p><span class="math display">\[\begin{align*}
Y &amp;= Z + U
\end{align*}\]</span></p>
<p>Equivalently, the potential outcomes (for <span class="math inline">\(Y\)</span>) might be written, for <span class="math inline">\(i \in \{1,2,\dots, n\}\)</span> as:</p>
<p><span class="math display">\[\begin{align*}
Y_i(0) &amp;=&amp; u_i  \\
Y_i(1) &amp;=&amp; 1 + u_i 
\end{align*}\]</span></p>
<p>This DAG encodes this model in graphical form:</p>
<div class="figure">
<span id="fig:p2simpledag"></span>
<img src="book_files/figure-html/p2simpledag-1.svg" alt="Simple DAG. U is unobserved." width="100%"><p class="caption">
Figure 6.1: Simple DAG. U is unobserved.
</p>
</div>
<!-- This is good text but for answer stratgy: -->
<!-- Possibly the most important thing that a DAG can teach us is which research questions are even answerable in a given setting by applying the "back-door criterion," which asks whether a back-door path exists between a pair of causally-related variables. Here, the causal relationship between $X$ and $Y$ is confounded by the back-door path $X \leftarrow U \rightarrow Z$. (for much more on the back-door criterion, see XXX). Since we have no information about what is in $U$, we can't learn about the effects of $X$ on $Y$. However, the treatment variable $Z$ has no edges leading in to it, which represents the idea that $Z$ is randomly assigned. There are no back door paths leading from $Z$ to $Y$, so we *can* learn more easily about average causal effects of $Z$ on $Y$. We could also draw descriptive inferences about the distributions of the observed variables like their ranges and averages or their variances and covariances. -->
<div id="what-is-the-population" class="section level2">
<h2>
<span class="header-section-number">6.1</span> What is the population?<a class="anchor" aria-label="anchor" href="#what-is-the-population"><i class="fas fa-link"></i></a>
</h2>
<p>The first choice to make in declaring <span class="math inline">\(M\)</span> is the set of units about which you wish to make inferences. This is largely determined by your inquiry (<span class="math inline">\(I\)</span>). We might usefully distinguish between three types of sets of units—all of which we will refer to as your “population.”</p>
<ul>
<li><p>Finite population. If your inquiry is about the population of Americans or Brazilians, your reference model should describe the characteristics of all Americans or Brazilians. You might only analyze data from a sample of these, but you seek nevertheless to make inferences about this (finite) population.</p></li>
<li><p>Finite sample. Moving down, your inquiry might only be about a sample from a finite population. If you are interested in the sample average treatment effect, then you need only describe only the units in your sample. For practical purposes your sample then <em>is</em> your population. Subtly however, if you are interested in a sample but do not know what your sample from the population will be then your inquiry might concern a typical sample from a population in some way and you will need to your estimand.</p></li>
<li><p>Superpopulation. Moving <em>up</em> you might imagine units as being draws from an infinite population. You are interested in “what happens when you shake a fizzy drink?”: the set of instances is infinite and when you characterize the superpopulation you want to describe a distribution over possible cases not a finite set of cases.</p></li>
</ul>
<p>Which population you have in mind affects how reference populations should be modeled but also how draws from a population should be interpreted.</p>
<p>To illustrate consider a very simple model in which we believe that <span class="math inline">\(Y\)</span> depends upon <span class="math inline">\(Z\)</span> and <span class="math inline">\(Z\)</span> is randomly assigned, with probability .5. Say we believe that potential outcomes, and treatment effects, are different for each person. This model, like many in this book, might be declared like this:</p>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">M</span> <span class="op">&lt;-</span>
  <span class="fu">declare_population</span><span class="op">(</span>N <span class="op">=</span> <span class="fl">100</span>, 
                     U <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>, 
                     tau <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, mean <span class="op">=</span> <span class="fl">1</span>, sd <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>, 
                     Z <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">declare_potential_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">tau</span> <span class="op">*</span> <span class="va">Z</span> <span class="op">+</span> <span class="va">U</span><span class="op">)</span></code></pre></div>
<p>The model can be used to generate data, like this:</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:realizedmodel">Table 6.1: </span>Data from a simple model
</caption>
<thead><tr>
<th style="text-align:left;">
ID
</th>
<th style="text-align:right;">
U
</th>
<th style="text-align:right;">
tau
</th>
<th style="text-align:right;">
Z
</th>
<th style="text-align:right;">
Y_Z_0
</th>
<th style="text-align:right;">
Y_Z_1
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
001
</td>
<td style="text-align:right;">
2.321
</td>
<td style="text-align:right;">
1.003
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2.321
</td>
<td style="text-align:right;">
3.324
</td>
</tr>
<tr>
<td style="text-align:left;">
002
</td>
<td style="text-align:right;">
-0.843
</td>
<td style="text-align:right;">
0.874
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-0.843
</td>
<td style="text-align:right;">
0.032
</td>
</tr>
<tr>
<td style="text-align:left;">
003
</td>
<td style="text-align:right;">
-0.104
</td>
<td style="text-align:right;">
1.030
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.104
</td>
<td style="text-align:right;">
0.926
</td>
</tr>
<tr>
<td style="text-align:left;">
004
</td>
<td style="text-align:right;">
-0.058
</td>
<td style="text-align:right;">
0.997
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.058
</td>
<td style="text-align:right;">
0.940
</td>
</tr>
<tr>
<td style="text-align:left;">
005
</td>
<td style="text-align:right;">
-0.583
</td>
<td style="text-align:right;">
0.784
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-0.583
</td>
<td style="text-align:right;">
0.201
</td>
</tr>
<tr>
<td style="text-align:left;">
006
</td>
<td style="text-align:right;">
1.748
</td>
<td style="text-align:right;">
1.045
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.748
</td>
<td style="text-align:right;">
2.793
</td>
</tr>
</tbody>
</table></div>
<p>Note first that now that this declaration has a stochastic component. Not only is <code>X</code> randomized but so are individual level features <code>U</code> and treatment effects <code>tau</code>. Note also that the “data” contains potential outcomes—that is, <em>each draw</em> includes a description of how the world would work under different conditions and not simply a description of possibly observable data. In other words it reports a data generating process, not just data.</p>
<p>How should we these populations and draws given this stochastic component? What type of population have we just modeled? Have we modeled one or many populations?</p>
<p>In fact there are three distinct ways to interpret this model specification.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Large Population Interpretation of M</strong>: We have a large population—perhaps a superpopulation. On each run of the model we get to see a new sample and we use the sample to learn about the large population. In this interpretation <span class="math inline">\(M\)</span> is a singleton—we have specified only one model.</p></li>
<li><p><strong>Priors Interpretation of M</strong>: A third interpretation is that the stochastic component represents our uncertainty over a set of possible worlds. It might be, for instance, the a design performs well for some possible worlds and poorly for others, in which case the nature of this distribution is important for assessing our <em>expectation</em> that a design will perform well. In this interpretation <span class="math inline">\(M\)</span> is again a singleton.</p></li>
<li><p><strong>Multiple Worlds Interpretation of M</strong>: A second interpretation is that each data draw is itself a (non stochastic) model and the distribution functions provide a handy way of generating multiple plausible models. We we will want to learn about design performance for each of these possible worlds. Under this interpretation <em>M</em> is a collection of models and we may be interested in performance over each <span class="math inline">\(m\)</span> in <span class="math inline">\(M\)</span>.</p></li>
</ol>
<p>Which interpretation we have matters for how we do diagnosis (see Section <a href="p2diagnosis.html#p2diagnosis">10</a>).</p>
</div>
<div id="what-variables-to-include" class="section level2">
<h2>
<span class="header-section-number">6.2</span> What variables to include?<a class="anchor" aria-label="anchor" href="#what-variables-to-include"><i class="fas fa-link"></i></a>
</h2>
<!-- perhaps give technical definition of a variable -->
<div id="types-of-variables" class="section level3">
<h3>
<span class="header-section-number">6.2.1</span> Types of variables<a class="anchor" aria-label="anchor" href="#types-of-variables"><i class="fas fa-link"></i></a>
</h3>
<p>The key components in the model above and all the reference models we examine are the “variables” (or “nodes”) and the ways these stand in relation to each other. Informally a variable is a quantity that can take on different values: the day of the week, the winner of an election, the height of a mountain. All variables are formally similar but they can play distinguished roles in a model.</p>
<p>Often variables are labeled according to the role they play in a causal model and in later discussions we will often refer to variables in this way using the following terms:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Outcome variables</strong>: the variable whose level or responses we want to understand, generally referred to as <span class="math inline">\(Y\)</span>, as in Figure <a href="specifying-the-model.html#fig:vartypes">6.2</a>. Variously described as “dependent variables,” “endogenous variables,” “left hand side variables,” “response variables.”</li>
<li>
<strong>Explanatory variables</strong>: variables that affect outcome variables, often referred to as <span class="math inline">\(X\)</span>s though often as <span class="math inline">\(Z\)</span>, <span class="math inline">\(D\)</span>, or <span class="math inline">\(W\)</span>. We will most often use <span class="math inline">\(D\)</span> to refer to the main causal variable of interest in a particular study.</li>
<li>
<strong>Conditioning</strong> or <strong>moderating</strong> variables. Variables that might alter the effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span>. See for example <span class="math inline">\(X2\)</span> in Figure <a href="specifying-the-model.html#fig:vartypes">6.2</a>. Note that the figure simply indicates that <span class="math inline">\(X2\)</span> is a cause of <span class="math inline">\(Y\)</span> and the graph does not indicate that there is an interaction between <span class="math inline">\(X1\)</span> and <span class="math inline">\(X2\)</span>. One account for this is that as a general matter if two variables cause an outcome it would be surprising if they did <em>not</em> interact in some way.<br>
</li>
<li>
<strong>Mediators.</strong> Variables “along the path” between explanatory variables and outcomes. <span class="math inline">\(M\)</span> is an example of a mediator in this figure. Mediators are often studied to assess “how” <span class="math inline">\(D\)</span> causes <span class="math inline">\(Y\)</span>.</li>
<li>
<strong>Confounders</strong>. Variables that introduce a noncausal correlation between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>. In the figure <span class="math inline">\(X1\)</span> is an unobserved confounder because it causes both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> and could introduce a correlation between them even if <span class="math inline">\(D\)</span> did not cause <span class="math inline">\(Y\)</span>.</li>
<li>
<strong>Instruments.</strong> An instrumental variable is a variable that can induce an exogenous change in an explanatory variable and help us to figure out the relationship between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>, it is used instrumentally—not for its own sake. We give a much more detailed treatment of these variables in Section <a href="observational-designs-for-causal-inference.html#p3iv">16.3</a>. <span class="math inline">\(Z\)</span> is often reserved for instruments; see Figure <a href="specifying-the-model.html#fig:vartypes">6.2</a>.</li>
<li>
<strong>Colliders.</strong> Colliders are variables that are caused by two other variables. Colliders can be important because conditioning on a collider introduces a statistical but noncausal relationship between the causes of the collider. IN figure <a href="specifying-the-model.html#fig:vartypes">6.2</a> <span class="math inline">\(K\)</span> is a collider that can create a correlation between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span> (via <span class="math inline">\(U\)</span>) when conditioned upon.</li>
</ol>
<p>Note that these labels reflect the researcher’s interest as much as their position in a model. Another researcher examining the same graph might, for instance, label <span class="math inline">\(M\)</span> as their explanatory variable or <span class="math inline">\(K\)</span> as their outcome of interest.</p>
<div class="figure">
<span id="fig:vartypes"></span>
<img src="book_files/figure-html/vartypes-1.svg" alt="A DAG with an explantory variable of interest (D), an outcome of interest (Y), a mediator (M), a confounder (X1), a moderator (X2), an instrument (Z), and a collider (K)." width="100%"><p class="caption">
Figure 6.2: A DAG with an explantory variable of interest (D), an outcome of interest (Y), a mediator (M), a confounder (X1), a moderator (X2), an instrument (Z), and a collider (K).
</p>
</div>
</div>
<div id="what-variables-are-needed-for-declaration-and-diagnosis" class="section level3">
<h3>
<span class="header-section-number">6.2.2</span> What variables are <em>needed</em> for declaration and diagnosis?<a class="anchor" aria-label="anchor" href="#what-variables-are-needed-for-declaration-and-diagnosis"><i class="fas fa-link"></i></a>
</h3>
<p>When considering what variables to include in a model researchers are often torn between two conflicting goals. First, we want to learn more and more about how the world works or in other words, to fill in more and more of a large causal model. There are an infinite number of nodes and edges in this model — from how people vote to how they save and spend money to how they find romantic partners, all of which are interrelated. Second, we generally seek simple explanations where possible. Indeed in some accounts the point of research is to generate simplified representations of the world. The analogy of a map is often used: a useful map usually should have less detail than the object it is mapping.</p>
<p>We are used to these considerations vying with each other when considering which variables “of interest” to include in a model. For instance, which are the causes to examine when explaining an outcome. We highlight only here that in the MIDA framework the first consideration – realism–likely carries more weight than in other settings. The reason is that the model, as understood here, is not the analysis but <em>the benchmark against which your analysis will be assessed</em>. An excellent “analytic model” might ignore unimportant details about a problem, but your reference model might have to specify these details in order to establish that indeed they can be ignored without harming your inferences.</p>
<p>In the design declaration framework the variables that we need to specify in <span class="math inline">\(M\)</span> are in general comprised of (a) those we will need in the latter three elements in our research design: our inquiry <span class="math inline">\(I\)</span>, data strategy <span class="math inline">\(D\)</span>, and answer strategy <span class="math inline">\(A\)</span> and (b) those that we need for diagnosis.</p>
<p>Consider the first set first:</p>
<p><span class="math inline">\(I\)</span>: In order to reason about whether the data we collect will be able to provide an answer to our inquiry, we need to define all of the variables used to construct our inquiry. In descriptive research, this will mean the variables we will summarize. In causal research, this will mean the potential outcomes under different states of the world, such as treatment and control. For example, if we are studying the effects of a voter mobilization campaign on vote choice between the three candidates running in a primary election, we should define a vote choice variable and the values it takes on in two circumstances: in the presence of the voter mobilization campaign (treatment) and without it (control).</p>
<p><span class="math inline">\(D\)</span>: The data strategy — sampling, treatment assignment, and measurement — defines many of the variables we need to specify in the model. Sampling procedures often involve stratification (e.g., sampling equal proportions of men and women), clustering (e.g., sampling all of the individuals in a household to participate in the research), or both. In the model, we need to define the variables that will be used to stratify and cluster. Similarly, treatment assignment can involve assigning treatments within blocks and cluster assignment where all units are assigned to the same status. The variables that are used to construct blocks and that will form clusters will be defined in the model. Finally, all of the variables that will be measured should also be defined in the model. When we measure latent variables imperfectly, for example sensitive questions where a true characteristic exists but respondent do not always admit it, we should define both the latent trait and measured responses.</p>
<p><span class="math inline">\(A\)</span>: Finally, answer strategies rely on collected data to provide an answer to the inquiry, and so any variable in the collected data should be defined in the model. (Any of these variables should also be defined in the measurement strategy.) Beyond outcomes and treatment variables, we may need variables to define clusters used in clustered standard errors, to construct weights for poststratification of estimates to match population characteristics, and to visualize our data.</p>
<p>If we have all this, do we have enough for diagnosis? We might not. When we engage in diagnosis we may want to ask about how our design fares if the world worked in a particular way. For instance, the gender of subjects might not be a primary interest for us or enter into our inquiry, our data strategy, or our analysis, but we might worry that gender confounds our inferences—for example if it affects both treatment uptake and outcomes. In this case we may include gender in the reference model in order to assess the extent to which our analysis is sensitive to it.</p>
</div>
</div>
<div id="specifying-structural-relations" class="section level2">
<h2>
<span class="header-section-number">6.3</span> Specifying structural relations<a class="anchor" aria-label="anchor" href="#specifying-structural-relations"><i class="fas fa-link"></i></a>
</h2>
<p>DAGs convey beliefs about <em>whether</em> two variables are causally related, but they do not encode beliefs about <em>how</em> they are related. This is no criticism of DAGs — they just don’t encode all of our causal beliefs about a system. To assess many properties of a research design we need to go further. We need to specify the probability distribution of exogenous variables and the functional forms of the endogenous variables (how they relate to parent variables). This will include incorporating beliefs about effect sizes, but also correlations between variables, intra-class correlations (ICCs), and interactions. All of this to say: in order to declare and diagnose our designs, we’ll need to make the leap from nonparametric models to <em>parametric</em> structural causal models. This move is not without costs – each specific choice we make over and above the nonparametric model is an opportunity to be more wrong about the world!</p>
<p>A slightly more complex example helps demonstrate how we can use a model declaration to facilitate representation of a class of possibly stochastic models. Suppose that according to our model, the effect of <span class="math inline">\(Z\)</span> should be larger for units with <span class="math inline">\(X = 1\)</span>. We can encode this belief in the design declaration below. In the <code>declare_population</code> function, we write that <span class="math inline">\(U\)</span> is normally distributed with mean 0 and standard deviation 1; <span class="math inline">\(X\)</span> follows a Bernoulli distribution. In the <code>declare_potential_outcomes</code> function, we describe how the average effect of treatment depends on <span class="math inline">\(X\)</span>.</p>
<!-- I removed the confounding to keep focused on one point -->
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tau_X0</span> <span class="op">&lt;-</span> <span class="fl">0.5</span>
<span class="va">tau_X1</span> <span class="op">&lt;-</span> <span class="fl">1</span>

<span class="va">M</span> <span class="op">&lt;-</span>
  <span class="fu">declare_population</span><span class="op">(</span>
    N <span class="op">=</span> <span class="fl">100</span>, 
    U <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>, 
    X <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">1</span>, <span class="fl">.5</span><span class="op">)</span>
  <span class="op">)</span> <span class="op">+</span>
  <span class="fu">declare_potential_outcomes</span><span class="op">(</span>
    <span class="va">Y</span> <span class="op">~</span> <span class="op">(</span><span class="va">X</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span> <span class="op">*</span> <span class="va">Z</span> <span class="op">*</span> <span class="va">tau_X0</span> <span class="op">+</span> <span class="op">(</span><span class="va">X</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="va">Z</span> <span class="op">*</span> <span class="va">tau_X1</span> <span class="op">+</span> <span class="va">U</span>
  <span class="op">)</span></code></pre></div>
<p>The design describes a more complex world in which treatment effects of <span class="math inline">\(Z\)</span> depend in a particular way on a background variable <span class="math inline">\(X\)</span>. We could incorporate different beliefs about the causal model by changing the <code>tau_X0</code> and <code>tau_X1</code> parameters. However, regardless of the value of the interaction (either zero or some other number), the DAG looks the same but the ability of the design to answer questions of interest will vary. This highlights the point that DAGs themselves are not enough to characterize a model—design declaration requires functional equations also: either specific equations or families of equations. Thus although we might feel uncomfortable specifying particular values for <code>tau_X0</code> and <code>tau_X1</code> we are not beholden to these particular values. We can easily vary them to see how a design performs over a range of models, or we could even expand the declaration to specify a distribution of values for <code>tau_X0</code> and <code>tau_X1</code>.</p>
<!-- maybe a footnote? -->
<!-- - some of these variables will be exogenous and endogenous, in Pearl's terms. by exogenous variables, he means variables without parents, no antecendent causes. by endogenous variables, he means those with parents, that are determined in part by earlier variables. endogenous variables are distinct from the problem of endogeneity, which comes from a single variable being a parent of both the treatment variable of interest and the outcome we wish to measure the causal effect of the treatment on. we will use it in Pearl's sense. -->
<!-- maybe should clarify somewhere that the choice of a distribution function is as much a parametric decision as the choice of its arguments -->
</div>
<div id="substantive-justifications-for-choices-of-nodes-and-equations" class="section level2">
<h2>
<span class="header-section-number">6.4</span> Substantive justifications for choices of nodes and equations<a class="anchor" aria-label="anchor" href="#substantive-justifications-for-choices-of-nodes-and-equations"><i class="fas fa-link"></i></a>
</h2>
<p>So far we have described formal considerations but we have not described substantive considerations for including particular variables or stipulating particular relations between them.</p>
<p>The justification of your choice of reference model will depend on the purpose of your design. Broadly we distinguish between reality tracking models, discursive models, and sufficient models.</p>
<div id="reality-tracking-models" class="section level3">
<h3>
<span class="header-section-number">6.4.1</span> Reality tracking models<a class="anchor" aria-label="anchor" href="#reality-tracking-models"><i class="fas fa-link"></i></a>
</h3>
<p>Reality tracking reference models seek to approximate the truth as well as possible.</p>
<p>The content of these models typically comes from two places: reading the past literature and qualitative research. Past theoretical work can guide the set of nodes that are relevant and how they are connected by edges. Past empirical work can provide further insight on the set of edges that exist (or do not). However, when past research is thin on a topic, there is no substitute for insights gained through qualitative data collection: focus groups and interviews with key informants who know aspects of the model that are hidden to the researcher; archival investigations to understand how to draw understand a causal process when the actors in it are no longer alive, or to gain insights only contained in administrative records; and immersive participant observation to see with your eyes how social actors behave. <span class="citation">Fenno (<a href="references-4.html#ref-fenno1978home" role="doc-biblioref">1978</a>)</span> calls this “soaking and poking.” This mode of inquiry, discovery, is separate from the qualitative research designs that provide an answer to an inquiry deductively. We examine those throughout the book. Instead, qualitative insights such as this, which <span class="citation">Lieberman (<a href="references-4.html#ref-lieberman2005nested" role="doc-biblioref">2005</a>)</span> labels “model-building” case studies, do not aim to answer a question but rather yield a new theoretical model. Quantitative research is often seen as distinct from qualitative research, but the model building phase in both is itself qualitative.</p>
<p>The next step — selecting statistical distributions and their parameters to describe exogenous variables and the functional forms of endogenous variables — is often more uncomfortable. We do not know the magnitude of the effect of an intervention before we do the research or the correlation between two outcomes when those are the goal of the research. That’s why we are conducting the study! However, we are not fully in the dark in most cases and can make educated guesses about parameters like effect sizes, intraclass correlations, and correlations between variables.</p>
<p>We can conduct meta-analyses of past, relevant studies on the same topic to identify the range of plausible effect sizes, intraclass correlations, correlations between variables, and other model parameters. Conduct such a meta-analysis might be as simple as collecting the three papers that measured similar outcomes in the past and calculating the average intraclass correlation and its range across the three. A more sophisticated but still straightforward analysis would be to calculate the precision-weighted average of effect sizes and use that as the baseline effect size in the model, but also calculate the predictive interval from a random effects meta-analysis to characterize the expected range of effect sizes across differing contexts.</p>
<p>The key question in conduct such a meta-analysis is how to select studies that are “relevant.” There are four dimensions on which we might want to compare past studies to the current setting: similarity in the type of units, treatments, outcomes, and contexts <span class="citation">(Cronbach and Shapiro <a href="references-4.html#ref-cronbach1982" role="doc-biblioref">1982</a>)</span>. Except in the case of pure replication studies, we are typically studying a (possibly new) treatment in a new setting, with new participants, or with new outcomes, so there will not be perfect overlap. However, the variation in effects across contexts and these other dimensions will help structure the range of our guesses specified in the model.</p>
<p>When there are past studies that are especially close to our own, we may want to not define probability distributions that approximate the causal model of the world, but use the data from that past study directly as a stand in. To do so, instead of declaring variables and their distributions and potential outcomes, we can resample from the past data to obtain simulated alternative possible worlds.</p>
<p>Where there are no past studies that are sufficiently similar in some dimension, we can collect new data through pilot studies. We discuss risks to relying on data from small pilot studies in planning new research in Chapter <a href="research-design-lifecycle.html#p4piloting">20.5</a>. In short, we should not rely on effect size estimates from small pilot studies, and only use parameters such as the range of outcome data and the standard errors of estimates which are less noisy in declaring our new design.</p>
<p>In some cases, we can define many of the variables from early data collection in a study, e.g., from a baseline survey. Once we conduct a baseline survey, we can use the set of individuals selected for the study and their baseline characteristics to define many of the variables in our model. We can define our expectations about effect sizes and other features of endogenous variables, but rely on the correlations between exogenous variables from the baseline data. The danger here is that if we fix the characteristics of our model using baseline data, we will not consider what data <em>could have</em> been revealed if our sampling procedure had yielded a different set of study participants or we had conducted data collection a month later.</p>
</div>
<div id="discursive-models" class="section level3">
<h3>
<span class="header-section-number">6.4.2</span> Discursive models<a class="anchor" aria-label="anchor" href="#discursive-models"><i class="fas fa-link"></i></a>
</h3>
<p>For some purposes the reference model might be developed not to track reality but to reflect assumptions in scholarly debate. For instance the purpose might be to question whether a given conclusion is valid <strong>under the assumptions maintained by some scholarly community</strong>. Indeed it is possible that a reference model is used specifically because the researcher thinks it inaccurate, allowing them to show what even if they are wrong in some background assumptions about the world, their analysis will produce good answers.</p>
<p>A particularly important class of discursive models are what might be called “agnostic models”: models that make weaker assumptions about the world than the researcher in good faith holds. In a directed acyclic graph, every arrow indicates a possible relation between a cause and an outcome. The big assumptions in these models however are not seen in the arrows but in the absence of arrows: every missing arrow represents a claim that an outcome is not affected by a possible cause. Analysis strategies often depend upon such assumptions. Even when arrows are included, functional relations might presuppose particular features important for inference. For instance a researcher using “instrumental variables” analysis will generally assume that <span class="math inline">\(Z\)</span> causes <span class="math inline">\(Y\)</span> though <span class="math inline">\(D\)</span> but not through other paths. This is an assumption about absent arrows. The same analysis might also assume that <span class="math inline">\(Z\)</span> never affects <span class="math inline">\(D\)</span> negatively. That is an assumption about functional forms. An agnostic reference model might loosen these assumptions, allow for the possibility of violations of exclusion restrictions and violations of monotonicity assumptions and use this to see how analysis fares under conditions that the researcher believes not to be true, but that a skeptic might be willing to entertain.</p>
</div>
<div id="sufficient-models" class="section level3">
<h3>
<span class="header-section-number">6.4.3</span> Sufficient models<a class="anchor" aria-label="anchor" href="#sufficient-models"><i class="fas fa-link"></i></a>
</h3>
<p>For some purposes the validity of inferences, or the lessons learned from a diagnosis do not depend on <span class="math inline">\(w\)</span> lying in <span class="math inline">\(M\)</span>, the relevant question is only whether the kinds of inferences one might draw given stipulated reference models would also hold reasonable well for the true data generating process. For instance if your aim is to assess whether an analysis strategy generates an unbiased estimate of a treatment effect you may go to pains to make sure that that you model treatment assignment carefully but modeling the size of a treatment effect correctly may not be important. The idea is that what you learn from the model that you do study is sufficient for inferences about a broader class of model within which the true data generating process might lie.</p>
</div>
</div>
<div id="getting-it-right" class="section level2">
<h2>
<span class="header-section-number">6.5</span> Getting it right?<a class="anchor" aria-label="anchor" href="#getting-it-right"><i class="fas fa-link"></i></a>
</h2>
<div id="robustness-to-multiple-models" class="section level3">
<h3>
<span class="header-section-number">6.5.1</span> Robustness to multiple models<a class="anchor" aria-label="anchor" href="#robustness-to-multiple-models"><i class="fas fa-link"></i></a>
</h3>
<p>We noted that the most uncomfortable part of declaring <span class="math inline">\(M\)</span> is choosing point estimates of its parameters such as the effect size, the mean and variance of the normal distribution that describes unknown heterogeneity. But we also emphasized that there is in general no need to specify a single point! Indeed, our uncertainty about the model should usually lead us to a range or even empirical distribution from past studies of each parameter.</p>
<p>We suggest three strategies for choosing these ranges: the <em>logical bounds</em> of a parameter, such as choosing the range of possible effect sizes based on the largest change from the bottom of a scale to the top of a scale; the <em>empirical distribution</em> from past studies, either the full range of the parameter or the predictive interval from a random effects meta-analysis; or a <em>best case</em>-<em>worst case</em> bounds, based on the substantive interpretation of results in light of past results, for example ranging from an effect size of zero to the largest plausible effect size. A design that performs well in terms of power and bias under one or all of these three ranges for each parameter might be labeled “robust to multiple models.”</p>
<p>A separate goal is assessing the performance of a research design under different models implied by alternative theories. A good design will provide probative evidence about which model is correct regardless of which model it is that aligns with the true causal model of the world.</p>
<p>An important example is assessing the performance of a research design under a “null model” where the true effect size is zero. A good research design should report with high probability that there is insufficient evidence to reject a null effect. That same research design, under an alternative model with a large effect size, should with high probability return evidence rejecting the null hypothesis of zero effect. The example makes clear that in order to understand whether the research design is strong, we need to understand how it performs under not just multiple models, but the models implied by alternative theoretical understandings of the world.</p>
<p>Two alternative theories of why <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span>, through mediator <span class="math inline">\(M_1\)</span> or mediator <span class="math inline">\(M_2\)</span> (and not both), imply two different structural causal models. When the inquiry is which variable mediates the relationship, we need to understand how the research design performs in providing evidence for which is correct under both possibilities.</p>
</div>
<div id="fundamental-uncertainty" class="section level3">
<h3>
<span class="header-section-number">6.5.2</span> Fundamental uncertainty<a class="anchor" aria-label="anchor" href="#fundamental-uncertainty"><i class="fas fa-link"></i></a>
</h3>
<p>Even the best reference models are sure to be simplifications of the true data generating process. The true causal structure of the world <span class="math inline">\(W\)</span> generates draws from the world <span class="math inline">\(w\)</span>. The inquiry <span class="math inline">\(I\)</span> might not even defined under <span class="math inline">\(W\)</span>, that is <span class="math inline">\(I(w)\)</span> might be <span class="math inline">\(NA\)</span>. Applying the data strategy <span class="math inline">\(D\)</span> to <span class="math inline">\(w\)</span> might produce unexpected results. That is <span class="math inline">\(D(w)\)</span> need not be anything like <span class="math inline">\(D(m)\)</span>. This disjuncture is in large part the point of doing research in the first place. We do not know <span class="math inline">\(W\)</span> – that would require omniscience. We have learned parts of <span class="math inline">\(W\)</span> and put them in <span class="math inline">\(M\)</span> – that’s science. When research produces unexpected results, it’s an indication that something in MIDA is out of whack and it is an opportunity for learning. The <em>next</em> research project will amend MIDA in order to bring <span class="math inline">\(M\)</span> closer to <span class="math inline">\(W\)</span>.</p>

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
<!-- start post here, do not edit above -->
<!-- make sure to rename the section title below -->
</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="declaration.html"><span class="header-section-number">5</span> Declaration</a></div>
<div class="next"><a href="defining-the-inquiry.html"><span class="header-section-number">7</span> Defining the inquiry</a></div>
</div></main><div id="on-this-page-nav" class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#specifying-the-model"><span class="header-section-number">6</span> Specifying the model</a></li>
<li><a class="nav-link" href="#what-is-the-population"><span class="header-section-number">6.1</span> What is the population?</a></li>
<li>
<a class="nav-link" href="#what-variables-to-include"><span class="header-section-number">6.2</span> What variables to include?</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#types-of-variables"><span class="header-section-number">6.2.1</span> Types of variables</a></li>
<li><a class="nav-link" href="#what-variables-are-needed-for-declaration-and-diagnosis"><span class="header-section-number">6.2.2</span> What variables are needed for declaration and diagnosis?</a></li>
</ul>
</li>
<li><a class="nav-link" href="#specifying-structural-relations"><span class="header-section-number">6.3</span> Specifying structural relations</a></li>
<li>
<a class="nav-link" href="#substantive-justifications-for-choices-of-nodes-and-equations"><span class="header-section-number">6.4</span> Substantive justifications for choices of nodes and equations</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#reality-tracking-models"><span class="header-section-number">6.4.1</span> Reality tracking models</a></li>
<li><a class="nav-link" href="#discursive-models"><span class="header-section-number">6.4.2</span> Discursive models</a></li>
<li><a class="nav-link" href="#sufficient-models"><span class="header-section-number">6.4.3</span> Sufficient models</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#getting-it-right"><span class="header-section-number">6.5</span> Getting it right?</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#robustness-to-multiple-models"><span class="header-section-number">6.5.1</span> Robustness to multiple models</a></li>
<li><a class="nav-link" href="#fundamental-uncertainty"><span class="header-section-number">6.5.2</span> Fundamental uncertainty</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Research Design: Declare, Diagnose, Redesign</strong>" was written by Graeme Blair, Jasper Cooper, Alexander Coppock, and Macartan Humphreys. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Supported by the Laura and John Arnold Foundation and Evidence in Governance and Politics.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
