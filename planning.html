<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 23 Planning | Research Design: Declare, Diagnose, Redesign</title>
<meta name="author" content="Graeme Blair, Alexander Coppock, and Macartan Humphreys">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.4.9002/tabs.js"></script><script src="libs/bs3compat-0.2.4.9002/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<link href="libs/bs4_book-1.0.0/dd_imgpopup.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/bs4_book-1.0.0/dd_imgpopup.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://hypothes.is/embed.js" async></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS --><link rel="stylesheet" href="headers/style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Research Design: Declare, Diagnose, Redesign</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li class="book-part">Introduction</li>
<li><a class="" href="preamble.html"><span class="header-section-number">1</span> Preamble</a></li>
<li><a class="" href="defining-research-designs.html"><span class="header-section-number">2</span> Defining research designs</a></li>
<li><a class="" href="research-design-principles.html"><span class="header-section-number">3</span> Research design principles</a></li>
<li><a class="" href="primer.html"><span class="header-section-number">4</span> Software primer</a></li>
<li><a class="" href="part-i-exercises.html"><span class="header-section-number">5</span> Part I Exercises</a></li>
<li class="book-part">Declaration, Diagnosis, Redesign</li>
<li><a class="" href="declaration-1.html"><span class="header-section-number">6</span> Declaration</a></li>
<li><a class="" href="specifying-the-model.html"><span class="header-section-number">7</span> Specifying the model</a></li>
<li><a class="" href="defining-the-inquiry.html"><span class="header-section-number">8</span> Defining the inquiry</a></li>
<li><a class="" href="crafting-a-data-strategy.html"><span class="header-section-number">9</span> Crafting a data strategy</a></li>
<li><a class="" href="choosing-an-answer-strategy.html"><span class="header-section-number">10</span> Choosing an answer strategy</a></li>
<li><a class="" href="p2diagnosis.html"><span class="header-section-number">11</span> Diagnosis</a></li>
<li><a class="" href="redesign-2.html"><span class="header-section-number">12</span> Redesign</a></li>
<li><a class="" href="part-ii-exercises.html"><span class="header-section-number">13</span> Part II Exercises</a></li>
<li class="book-part">Research Design Library</li>
<li><a class="" href="research-design-library.html"><span class="header-section-number">14</span> Research Design Library</a></li>
<li><a class="" href="observational-descriptive.html"><span class="header-section-number">15</span> Observational | descriptive</a></li>
<li><a class="" href="observational-causal.html"><span class="header-section-number">16</span> Observational | causal</a></li>
<li><a class="" href="experimental-causal.html"><span class="header-section-number">17</span> Experimental | causal</a></li>
<li><a class="" href="experimental-descriptive.html"><span class="header-section-number">18</span> Experimental | descriptive</a></li>
<li><a class="" href="complex-designs-1.html"><span class="header-section-number">19</span> Complex designs</a></li>
<li><a class="" href="part-iii-exercises.html"><span class="header-section-number">20</span> Part III Exercises</a></li>
<li class="book-part">Research Design Lifecycle</li>
<li><a class="" href="research-design-lifecycle.html"><span class="header-section-number">21</span> Research Design Lifecycle</a></li>
<li><a class="" href="brainstorming.html"><span class="header-section-number">22</span> Brainstorming</a></li>
<li><a class="active" href="planning.html"><span class="header-section-number">23</span> Planning</a></li>
<li><a class="" href="realization.html"><span class="header-section-number">24</span> Realization</a></li>
<li><a class="" href="integration.html"><span class="header-section-number">25</span> Integration</a></li>
<li><a class="" href="part-iv-exercises.html"><span class="header-section-number">26</span> Part IV Exercises</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="planning" class="section level1">
<h1>
<span class="header-section-number">23</span> Planning<a class="anchor" aria-label="anchor" href="#planning"><i class="fas fa-link"></i></a>
</h1>
<div id="ethics" class="section level2">
<h2>
<span class="header-section-number">23.1</span> Ethics<a class="anchor" aria-label="anchor" href="#ethics"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>As researchers, we have ethical obligations beyond the requirements of national laws and the regulations of institutional review boards. The considerations at play in any particular study vary from context to context. For example, <span class="citation">Slough (<a href="references.html#ref-slough2020ethics" role="doc-biblioref">2020</a>)</span> considers the ethics of field experimentation in the context of elections, and <span class="citation">Wood (<a href="references.html#ref-wood2006ethical" role="doc-biblioref">2006</a>)</span> addresses the ethical encumbrances specific to interview-based field research in conflict zones. Despite the ethical heterogeneity across research projects, the common ethical principles laid out in the Belmont report – respect for persons, beneficence, and justice – apply across designs and research modes.</p>
<p>As conceptions of how to follow these principles evolve, however, the standards to which research communities hold their members also shift. For example, journal editors and peer reviewers have begun to request ethical appendices, and the ethical status of studies is regularly discussed in public academic forums.</p>
<p>Most design declarations and diagnoses elide ethical considerations. For instance, a declaration that is diagnosand-complete for statistical power may tell you little about the level of care and respect accorded to subjects. Many declarations are diagnosand-complete for bias, but obtaining an unbiased treatment effect estimate is not always the highest goal. When obtaining a credible answer would come at too high an ethical cost, the study may need to be scrapped altogether.</p>
<p>However, ethical diagnosands can be (and we think should be!) directly incorporated into the declare-diagnose-redesign framework. Diagnosands could include the total cost to participants, how many participants were harmed, the average level of informed consent measured by a survey about comprehension of study goals, or the risks of adverse events. More complex ethical diagnosands are possible as well: <span class="citation">Slough (<a href="references.html#ref-slough2020ethics" role="doc-biblioref">2020</a>)</span> provides a formal analysis of the “aggregate electoral impact” diagnosand for experiments that take place in the context of elections. We consider two specific ethical diagnosands here, costs and potential harms, though many others may apply in particular research scenarios.</p>
<p><strong>Costs.</strong> A common concern is that measurement imposes a cost on subjects, if only by wasting their time. Subjects’ time is a valuable resource they often donate willingly to the scientific enterprise by participating in a survey or other measurement. Although subjects’ generosity is sometimes repaid with financial compensation, in many scenarios direct payments are not feasible. Regardless of whether subjects are paid, the costs to subjects should be top of mind when designing the study.</p>
<p><strong>Potential harms.</strong> Different realizations of the data from the same data strategy may differ in their ethical status. Ex-post, a study may not have ended up harming subjects, but ex-ante, there may have been a risk of harm <span class="citation">(Baron and Young <a href="references.html#ref-young2020" role="doc-biblioref">2020</a>)</span>. The project’s ethical status depends on judgments about <em>potential</em> harms and <em>potential</em> participants: not only what did happen, but what could have happened. The potential harm diagnosand might be formalized as the maximum harm that could eventuate under any realization of the data strategy. Researchers could then follow a minimax redesign procedure to find the design that minimizes this maximum potential harm.</p>
<p>When the design is diagnosed, we can characterize the ethical status of possible realizations of the design. The first way these ethical diagnosands can be used is to determine whether the study design meets a set of ethical thresholds. Is the probability of harm minimal enough? Is the average level of informed consent sufficient? Given that these characteristics vary across designs and across realizations of the same design, writing down concretely both the measure of the ethical status and the ethical threshold can help structure thinking. These diagnoses and the considerations that inspire them can be shared in funding proposals, preanalysis plans, or other report.</p>
<p>Often, once an ethical threshold is met, we select among feasible designs based on research design criteria such as statistical power and bias. This approach has appeal since we should only implement designs that meet the relevant research community’s ethical standards. However, dichotomizing designs into “ethical” and “unethical” is a difficult task in general. Instead, we should continue to assess ethical considerations alongside the quality of the research design. Even among ethical designs, we still face tradeoffs between how much time is asked of subjects and the risk of harm. We should select designs that weigh these considerations (perhaps highly!) against other desiderata. A difficult challenge in this process is that we have to measure the two on a common scale to weigh ethical criteria against other diagnosands such as power and cost.</p>
<p><strong>Further readings</strong>.</p>
<ul>
<li><span class="citation">Humphreys (<a href="references.html#ref-humphreys2015reflections" role="doc-biblioref">2015</a>)</span></li>
<li><span class="citation">Teele (<a href="references.html#ref-teele2020" role="doc-biblioref">2021</a>)</span></li>
<li><span class="citation">Meyer (<a href="references.html#ref-meyer2015two" role="doc-biblioref">2015</a>)</span></li>
<li><span class="citation">Luft (<a href="references.html#ref-luft2020you" role="doc-biblioref">2020</a>)</span></li>
<li><span class="citation">Baron and Young (<a href="references.html#ref-young2020" role="doc-biblioref">2020</a>)</span></li>
<li><span class="citation">Lyall (<a href="references.html#ref-lyall2020" role="doc-biblioref">2020</a>)</span></li>
<li><span class="citation">Slough (<a href="references.html#ref-slough2020ethics" role="doc-biblioref">2020</a>)</span></li>
<li><span class="citation">Wood (<a href="references.html#ref-wood2006ethical" role="doc-biblioref">2006</a>)</span></li>
<li><a href="https://www.apsanet.org/Portals/54/diversity%20and%20inclusion%20prgms/Ethics/Final_Principles%20with%20Guidance%20with%20intro.pdf?ver=2020-04-20-211740-153">American Political Science Association ethics guidelines</a></li>
<li><a href="https://www.asanet.org/sites/default/files/asa_code_of_ethics-june2018.pdf">American Sociological Association Code of Ethics</a></li>
<li><a href="https://www.apa.org/ethics/code">American Psychological Association Ethical Principles of Psychologists and Code of Conduct</a></li>
</ul>
<!-- By declaring your expectations about the ethical outcomes of an experiment in terms of diagnosands such as the time participants devote to the study and the probability of harm to individuals, a declared research design can be an input to ethical reporting. Readers can review how you considered ethical outcomes in your design and judge the mitigation efforts you undertook in relation to those expectations. Other scholars have proposed including ethical assessments in preanalysis plans. Declarations of ethical diagnosands are a natural complement to these preregistered assessments. --><!-- ### Illustration: Estimating expected costs and expected learning  --><!-- <!-- I would prefer to have an example where there is consent but people are willing to tkae part because they value the outcome --><!-- We illustrate how researchers can weigh the tradeoffs between the value of research and its ethical costs with an audit study of discrimination in government hiring. The characteristics of applicants to a municipal government job are randomized. The rate of callbacks for a job interview are compared across applicant characteristics. We consider three different inquiries that could be studied with the design: the hiring rate for job applications from a Black applicant and a White applicant; the hiring rate between someone from the local area vs. someone equally qualified who lives far away; and the rates between someone who went to East High School and someone who went to West High School in town. We judge the questions to rank in importance between high (the question of racial discrimination), medium (local favoratism), and low (personal interest). The value of the research is a function of the importance of the inquiry, but also how much we learn about it. We proxy for the learning from the experiment by sample size: the higher the $N$, the more we learn, but with decreasing marginal returns (it's a lot better to have a sample of 100 compared to 10; it matters less if it 1010 or 1100). Figure \@ref(fig:ethicsplot) shows the three research value curves labeled by the importance of the inquiry. --><!-- Because the job applicants are fictitious but appear real, a primary ethical concern in audit experiments is how much time hiring managers (the participants in the research) spend reviewing the fictitious applications. In the case of government hiring, it is public money spent on their review. The time cost to participants is linear in the number of applications: each application takes about ten minutes to review, regardless of how many are sent. We represent the cost to participants as the purple line in Figure \@ref(ethicsplot).  --><!-- We have placed the costs to participants on the same scale as the value of the research, by placing a value to society of the research and the value to society of the time of the hiring managers. When benefit exceeds cost (upper blue region), we decide to move forward with the research; if costs exceed benefits (lower gray region), we do not conduct the study. --><!-- The conclusion of the graph is that for high-importance inquiries, it is almost always worth doing the study. We get a lot of value from the research, despite the costs to participants. However, there is a region at low sample sizes where the cost to participants exceed the benefits from the research, because of the very imprecise answers we get from the research. We don't learn enough about the inquiry, despite its importance, to make it worth wasting the hiring managers time. By contrast, for low importance inquiries, it is never worth conducting the study. The costs to participants always exceed the (low) value of the research. Medium importance questions are in the middle: there is a region of the benefits curve (highlighted in blue) where it is worth doing the study, but two regions (highlighted in gray) where it is not worth it. The left region is where the sample is too small so the value of the research is low both because of its medium importance and we do not learn enough about it. The second gray region at right in the medium importance curve is where though we learn a lot about the inquiry, the cost is too high from the many hours of hiring manager time to justify what we learn because the inquiry is not important enough.  --><!-- In short, ethical determinations require diagnosis both of how much we learn and how much it costs to participants (along with other ethical costs), and we must place a value on both ethical costs and research benefits in order to compare them on the same scale.  --><!-- ```{r ethicsplot, echo=FALSE, fig.cap = "Tradeoffs between ethical costs and scientific benefits. A design might have too *many* subjects but also too *few* subjects.", fig.height=5, fig.width=5} --><!-- dat <-  --><!--   tibble( --><!--     X = seq(1, 10, 0.001), --><!--     cost =  4* X + 6 , --><!--     high = log(X, base = 1.05), --><!--     med = log(X, base = 1.06), --><!--     low = log(X, base = 1.10) --><!--   )  --><!-- dat_long <- --><!--   dat %>%  --><!--   pivot_longer(c(high, med, low)) %>% --><!--   mutate(cost_benefit = if_else(value > cost, "A", "B")) --><!-- label_df <- --><!--   tibble( --><!--     X = c(9.9, 9.9, 9.9), --><!--     value = c(22, 36, 48), --><!--     label = c("Low", --><!--               "Medium", --><!--               "Inquiry importance: High"), --><!--     cost_benefit = c("B", "B", "A") --><!--   ) --><!-- ggplot(dat_long, aes(X)) + --><!--   geom_ribbon(data = dat, aes(ymax = cost, x = X, ymin = 0), fill = gray(0.8, alpha = 0.3)) +  --><!--   geom_ribbon(data = dat, aes(ymin = cost, x = X, ymax = 50), fill = "#72B4F344") +  --><!--   geom_line(aes(y = value, color = cost_benefit, group = name)) + --><!--   geom_line(data = dat, aes(y = cost), color = dd_pink) + --><!--   geom_text(data = label_df, aes(y = value, label = label, color = cost_benefit), hjust = 1) + --><!--   scale_color_manual("", values = c(dd_dark_blue, gray(0.5))) +  --><!--   annotate("text", x = 1.5, y = 42, label = "Scientific benefits exceed ethical costs", hjust = 0, color = dd_dark_blue) +  --><!--   annotate("text", x = 4, y = 7, label = "Ethical costs exceed scientific benefits", hjust = 0, color = dd_gray) +  --><!--   labs(x = "Sample size", y = "Costs and benefits") +  --><!--   dd_theme() + --><!--     theme(legend.position = "none", --><!--           axis.text = element_blank(), --><!--           panel.grid.major = element_blank()) --><!-- ``` --><!-- ### Illustration: Assessing risks of adverse events  --><!-- <!-- Tara like exampe of swinging an election --><!-- * * * --><!-- - Is it the measurement they object to? Is it the random assignment?  --><!-- papers to cite here: the A/B illusion (Michelle Mayer); Cite APSA guidelines; preregistering ethics guidelines (Lyall paper); report on ethics in paper (Lauren Young's paper); Mac's paper; Belmont report --><!-- We must be able to think about the value to society of the research to weigh against the risks to participants and others. Similarly, we must be able to weigh more precise estimates of the same question against ethical considerations that also change based on the number of units and the proportion treated among other design features. By moving forward with research we must implicitly weigh these considerations. In IRB applications, we are often more directly asked to weigh the costs to subjects against the benefits of the research *to subjects* as well as to society as a whole. --><!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book--><!-- start post here, do not edit above -->
</div>
<div id="approvals" class="section level2">
<h2>
<span class="header-section-number">23.2</span> Approvals<a class="anchor" aria-label="anchor" href="#approvals"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>When researchers sit at universities in the United States, research must be approved by the university’s institutional review board (IRB) under the federal regulation known as the “Common Rule.” Similar research review bodies exist at universities worldwide and at many independent research organizations and think tanks. Though these boards are commonly thought to judge research ethics, in fact, they mainly exist to protect their institution from liability for research gone awry <span class="citation">(King and Sands <a href="references.html#ref-King2015" role="doc-biblioref">2015</a>)</span>. Accordingly, a researcher’s obligation to consider their study’s ethics is neither constrained nor checked by IRBs. Instead, a set of idiosyncratic rules and practices specific to each institution are checked. The researcher, as a result, remains responsible for their own ethical decision about whether or not to move forward with the research. That said, the IRB process is not necessarily without benefit. In some cases, useful discussions can be had with IRB board members about study decisions, and the approval itself may protect the researcher from some kinds of liability.</p>
<p>Laws and regulations at the country, state or province, or municipality level may also govern research on human subjects besides the IRB. Many countries require human subjects approval, especially for health research, in addition to the approvals researchers must seek from their home institutions. These approvals serve a similar purpose to the home institution IRB, but by virtue of their authority coming from the context in which the research is conducted rather than from far away bureaucrats, they may serve to more directly protect human subjects.</p>
<p>Though these bodies’ goals differ from the broader ethical aims social scientists hold, design diagnosis may also be useful here. Many IRBs ask researchers to describe tradeoffs between the costs and benefits to research subjects. In some cases, researchers are asked to defend research design choices that provide benefits to science, but where the only direct effects on participants are costs with no immediate benefits. Defining the costs and benefits to participants in terms of their time and money and the compensation provided by researchers, if any, can both simplify communication with IRBs and provide tools for researchers to more easily clarify these tradeoffs for themselves. The expected benefit and expected cost can be diagnosands across possible realizations of the design. The design diagnosis can highlight tradeoffs between the value to participants and the scientific value in the form of standard diagnosands. Rather than argue in the abstract about these quantities, they can be simulated and described formally through declaration and diagnosis.</p>
<p><strong>Further readings.</strong></p>
<ul>
<li><a href="https://www.hhs.gov/ohrp/regulations-and-policy/regulations/finalized-revisions-common-rule/index.html">U.S. “Revised Common Rule”</a></li>
</ul>
<!-- Local research approval --><!-- Partner approval  --><!-- - IRB approval (purpose is to protect the university from liability) - Gary and Melissa's paper --><!-- - IRB approval at your institution and with others --><!-- - IRB in context where you are working - country IRBs, what to do if there is not a country IRB --><!-- - research clearances --><!-- - history: belmont report. tuskegee experiment. stanford prison experiment.  --><!-- - laws and IRBs: revised common rule, paper on IRBs --><!-- - guidelines from econ, poli sci, soc, psych. --><!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book--><!-- start post here, do not edit above -->
</div>
<div id="partners" class="section level2">
<h2>
<span class="header-section-number">23.3</span> Partners<a class="anchor" aria-label="anchor" href="#partners"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>Partnering with third-party organizations in research entails cooperating to intervene in the world or to measure outcomes. Researchers seek to produce (and publish) scientific knowledge; they work with political parties, government agencies, nonprofit organizations, and businesses to learn more than they could if they worked independently. These groups work with researchers to learn about how to achieve their own organizational goals. Governments may want to expand access to healthcare, corporations to improve their ad targeting, and nonprofits to demonstrate program impact to funding organizations.</p>
<p>In the best-case scenario, the goals of the researchers and partner organizations are aligned. When the scientific question to be answered is the same as the practical question the organization cares about, the gains from cooperation are clear. The research team gains access to the organization’s financial and logistical capacity to act in the world, and the partner organization gains access to the researchers’ scientific expertise. Finding the right research partner almost always amounts to finding an organization with a common – or at least not conflicting – goal. Selecting a research design amenable to both parties requires understanding each partners’ private goals. Research design declaration and diagnosis can help with this problem by formalizing tradeoffs between the two sets of goals.</p>
<p>One frequent divergence between partner and researcher goals is that partner organizations often want to learn, but they care most about their primary mission. This dynamic is sometimes referred to as the “learning versus doing” tradeoff. (In business settings, this tradeoff goes by names like “learning versus earning” or “exploration versus exploitation”). An aid organization cares about delivering their program to as many people as possible. Learning whether the program has the intended effects on the outcomes of interest is obviously also important, but resources spent on evaluation are resources <em>not</em> spent on program delivery.</p>
<p>Research design diagnosis can help navigate the learning versus doing tradeoff. One instance of the tradeoff is that the proportion of units that receive a treatment represents the rate of “doing,” but this rate also affects the amount of learning. In the extreme, if all units are treated, we can’t measure the effect of the treatment. The tradeoff here is represented in a graph of the study’s power versus the proportion treated (top facet) and the partner’s utility (bottom facet). The researchers have a power cutoff at the standard 80% threshold. The partner also has a strict cutoff: they need to treat at least 2/3 of the sample to fulfill a donor requirement.</p>
<p>Researchers might simply ignore the proportion treated and select the design with the highest power in the absence of partners. With a partner organization, the researcher might use this graph in conversation with the partner to jointly select the design that has the highest power that has a sufficiently high proportion treated to meet the partner’s needs. This is represented in the “zone of agreement” in gray: in this region, the design has at least 80% power and at least two-thirds of the sample are treated. Deciding within this region involves a tradeoff between power (which is decreasing in the proportion treated here) and the partner’s utility (which is increasing in proportion treated). The diagnosis surfaces the zone of the agreement and clarifies the choice between designs in that region.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Unfortunately, some partnerships simply will not work out if the zone of agreement is empty.&lt;/p&gt;"><sup>29</sup></a></p>
<div class="figure">
<span id="fig:partnersplot"></span>
<img src="book_files/figure-html/partnersplot-1.svg" alt="Navigating research partnerships." width="100%"><p class="caption">
Figure 23.1: Navigating research partnerships.
</p>
</div>
<p>Choosing the proportion treated is one example of integrating partner constraints into research designs. A second common problem is that there are a set of units that must be treated or that must not be treated for ethical or political reasons (e.g., the home district of a government partner must receive the treatment). If these constraints are discovered after treatment assignment, they lead to noncompliance, which may substantially complicate the analysis of the experiment and even prevent providing an answer to the original inquiry. <span class="citation">Gerber and Green (<a href="references.html#ref-Gerber2012" role="doc-biblioref">2012</a>)</span> recommend, before randomizing treatment, exploring possible treatment assignments with the partner organization and using this exercise to elicit the set of units that must or cannot be treated. <span class="citation">King et al. (<a href="references.html#ref-king2007politically" role="doc-biblioref">2007</a>)</span> describe a “politically-robust” design, which uses pair-matched block randomization. In this design, when any unit is dropped due to political constraints, the whole pair is dropped from the study.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;This procedure is prone to bias for the average treatment effect among the “political feasible” units if within some pairs, one unit is treatable but the other is not.&lt;/p&gt;"><sup>30</sup></a></p>
<p>A major benefit of working with partners is their deep knowledge of the substantive area. For this reason, we recommend involving them in the design declaration and diagnosis process. How can we develop intuitions about the means, variances, and covariances of the variables to be measured? Ask your partner for their best guesses, which may be far more educated than your own. For experimental studies, solicit your partner’s beliefs about the magnitude of the treatment effect on each outcome variable, subgroup by subgroup if possible. Engaging partners in the declaration process improves design – and it very quickly sharpens the discussion of key design details. Sharing your design diagnoses and mock analyses <em>before</em> the study is launched can help to build a consensus around the study’s goals.</p>
<p><strong>Further Reading</strong></p>
<ul>
<li><span class="citation">King and Persily (<a href="references.html#ref-king_persily_2020" role="doc-biblioref">2020</a>)</span></li>
<li><span class="citation">Levi and Rajala (<a href="references.html#ref-levi_rajala_2020" role="doc-biblioref">2020</a>)</span></li>
<li><span class="citation">Levine (<a href="references.html#ref-levine_2020" role="doc-biblioref">2020</a><a href="references.html#ref-levine_2020" role="doc-biblioref">a</a>)</span></li>
<li><span class="citation">Levine (<a href="references.html#ref-levine_2020b" role="doc-biblioref">2020</a><a href="references.html#ref-levine_2020b" role="doc-biblioref">b</a>)</span></li>
<li><a href="https://www.povertyactionlab.org/resource/formalize-research-partnership-and-establish-roles-and-expectations">JPAL research resources: “Formalize research partnership and establish roles and expectations”</a></li>
<li><a href="https://www.povertyactionlab.org/resource/assessing-viability-and-building-relationships">JPAL research resources: “Assessing viability and building relationships”</a></li>
</ul>
<!-- ### Scattered thoughts --><!-- - Partnerships and ethics should be in here --><!-- - Research for Impact (@levine_2020) --><!-- - When to walk away --><!-- - Advice: there's usually a boss that gives you the green light, then staff people who actually help you. Our advice is to ensure that at least some meetings are with both the boss and the staff people so that the staff people know that the boss cares about the project and are therefore motivated to help you. A crucial person at the partner organization is the person who knows where the data are and how you can access them. Many people at partner organizations do not have this power, but you must be frequent touch.  --><!-- - In some cases, some member of the research staff can actually embed wiht the partner organization to ensure all the good things. --><!-- - Involve partners in PAP writing. --><!-- - when should partners be coauthors on the paper? --><!-- (Increasingly, funders are separating evaluation funds from implementation funds to remove this tradeoff.) --><!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book--><!-- start post here, do not edit above -->
</div>
<div id="funding" class="section level2">
<h2>
<span class="header-section-number">23.4</span> Funding<a class="anchor" aria-label="anchor" href="#funding"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<!-- point 1 -->
<p>Higher quality designs usually come with higher costs. Collecting original data is more expensive than analyzing existing data, but collecting new data may be more or less costly depending on the ease of contacting subjects or conducting measurements. As a result, including cost diagnosands in research design diagnosis can be helpful, and those diagnosands may usefully include both average cost and maximum cost. Researchers may make different decisions about cost: in some cases, the researcher will select the “best” design in terms of research design quality subject to a budget constraint. Others will choose the cheapest among similar quality designs to save money for future research. Diagnosis can help identify each set and decide among them.</p>
<p>To relax the budget constraint, researchers apply for funding. Funding applications have to communicate important features of the proposed research design. Funders want to know why the study would be useful, important, or interesting to scholars, the public, or policymakers. They also want to ensure that the research design provides credible answers to the question and that the research team is capable of executing the design. Since it’s their money on the line, funders also care that the design provides good value-for-money.</p>
<p>Researchers and funders have an information problem. Applicants wish to obtain as large a grant as possible for their design but have difficulty credibly communicating the quality of their design given the subjectivity of the exercise. On the flip side, funders wish to get the most value-for-money in the set of proposals they decide to fund and have difficulty assessing the quality of proposed research. Design declaration and diagnosis provide a partial solution to the information problem. A common language for communicating the proposed design and its properties can communicate the value of the research under design assumptions that – crucially – can be understood and interrogated by funders.</p>
<p>Funding applications should include a declaration and diagnosis of the proposed design. In addition to common diagnosands such as bias and efficiency, two special diagnosands may be valuable: cost and value-for-money. The cost can be included for each design variant as a function of design features such as sample size, the number of treated units, and the duration of survey interviews. Simulating the design across possible realizations of each variant explains how costs vary with choices the researcher makes. Value-for-money is a diagnosand that is a function of cost and the amount learned from the design.</p>
<p>In some cases, funders request applicants to provide multiple options and multiple price points or make clear how a design could be altered so that it could be funded at a lower level. Redesigning over differing sample sizes communicates how the researcher conceptualizes these options and provides the funder with an understanding of tradeoffs between the amount of learning and cost in these design variants. Applicants could use the redesign process to justify the high cost of their request directly in terms of the amount learned.</p>
<p>Ex-ante power analyses are required by an increasing number of funders. Current practice, however, illustrates the crux of the misaligned incentives between applicants and funders. Power calculators online have difficult-to-interrogate assumptions built in and cannot accommodate the specifics of many common designs <span class="citation">(Blair et al. <a href="references.html#ref-bccmapsr" role="doc-biblioref">2020</a>)</span>. As a result, existing power analyses can demonstrate that almost any design is “sufficiently powered” by changing expected effect sizes and variances. Design declaration is a partial solution to this problem. By clarifying the assumptions of the design in code, applicants can more clearly link the assumptions of the power analysis to the specifics of the design setting.</p>
<p>Finally, design declarations can also help funders compare applications on standard scales: root mean-squared-error, bias, and power. They also want to weigh considerations like importance and fit. Moving design considerations onto a common scale takes some of the guesswork out of the process and reduces reliance on researcher claims about properties.</p>
<!-- **Further readings.** -->
<!-- -  -->
<!-- -- funders often request power analysis, but these are typically described in words and thus the assumptions behind them cannot be interrogated fully. (a) not in code, so not specific; (b) user power calculators that are wrong (cite paper); (c) do not provide the details funders need to verify whether they agree with the assumptions.  -->
<!-- -- for funders, providing MIDA declared in code allows them to change the parameters of the design and test how the properties of the design change with beliefs about the world in M or data strategy parameters in D such as sample size, rather than having to rely on claims by applicants -->
<!-- -- often funders require regular reporting on changes in plan -- MIDA and design declaration provides a way to communicate (a) what those changes are and (b) how they change the values of diagnosands.  -->
<!-- -- value for money as a diagnosand (cost of each design as a function of design parameters) -->
<!-- -- allows funders to compare on a common scale (the same set of diagnosands) funding proposals -- often trying to evaluate "quality" but hard to do that with narrative proposals -->
<!-- ### References -->

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
<!-- start post here, do not edit above -->
</div>
<div id="p4piloting" class="section level2">
<h2>
<span class="header-section-number">23.5</span> Piloting<a class="anchor" aria-label="anchor" href="#p4piloting"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<!-- -- can't learn causal effect -->
<!-- -- what can you learn? about Y0, about M, about se -->
<!-- -- bring in blog post -->
<!-- mini MIDA in each piloting exercise -->
<p>Designing a research study always entails relying on a set of mostly informal beliefs. Choices like how many subjects to sample, which covariates to measure, which treatments to allocate, and depend on beliefs about treatment effects, the correlations of the covariates with the outcome, and the variance of the outcome.</p>
<p>We may have reasonably educated guesses about these parameters from past studies or theory. Our understanding of the nodes and edges in the causal graph of <em>M</em>, expected effect sizes, the distribution of outcomes, feasible randomization schemes, and many other features are directly selected from past research or chosen based on a literature review of past studies.</p>
<p>Even so, we remain uncertain about these values. One reason for the uncertainty is that our research context and inquiries often differ subtly from previous work. Even when replicating an existing study as closely as possible, difficult-to-intuit features of the research setting may have serious consequences for the design. Moreover, our uncertainty about a design parameter is often the very reason for conducting a study. We run experiments <em>because</em> we are uncertain about the average treatment effect. If we knew the ATE for sure, there would be no need to run the study. Frustratingly, we always have to design using parameters whose values we are unsure of.</p>
<p>The main goal of pilot studies is to reduce this uncertainty so that the main study can be designed, taking into account design parameters closer to the true values. Pilots take many forms: focus groups to learn how to ask survey questions, small-scale tests of measurement tools, even miniature versions of the main study on a smaller scale. We want to learn things like the distribution of outcomes, how covariates and outcomes might be correlated, or how feasible the assignment, sampling, and measurement strategies are.</p>
<p>Almost by definition, pilot studies are inferentially weaker than main studies. We turn to them in response to fundamental constraints on our time, money, and capacity. If we were not constrained, we would run a first full-size study, learn what is wrong with our design, then run a corrected full-size study. Since running multiple full studies is too expensive or otherwise infeasible, we run either smaller mini-studies or test out only a subset of the elements of our planned design. Accordingly, the diagnosands of a pilot design will not measure up to those of the main design. Pilots have much lower statistical power and may suffer from higher measurement error and less generalizability. Accordingly, the goal of pilot studies should not be to obtain a preliminary answer to the main inquiry, but instead to learn the information that will make the main study a success.</p>
<p>Like main studies, pilot studies can be declared and diagnosed – but importantly, the diagnosands for main and pilot studies need not be the same. Statistical power for an average treatment effect may be an essential diagnosand for the main study, but owing to their small size, power for pilot studies will typically be abysmal. Pilot studies should be diagnosed with respect to the decisions they imply for the main study.</p>
<p>Figure <a href="planning.html#fig:nrequired">23.2</a> shows the relationship between effect size and the sample size required to achieve 80% statistical power for a two-arm trial using simple random assignment. Uncertainty about the true effect size has enormous design consequences. If the effect size is 0.2, we need about 800 subjects to achieve 80% power. If it’s 0.1, we need 3200.</p>
<div class="figure">
<span id="fig:nrequired"></span>
<img src="book_files/figure-html/nrequired-1.svg" alt="Minimum required sample sizes and uncertainty over effect size" width="100%"><p class="caption">
Figure 23.2: Minimum required sample sizes and uncertainty over effect size
</p>
</div>
<p>Suppose we have prior beliefs about the effect size that can be summarized as a normal distribution centered at 0.3 with a standard deviation of 0.1, as in the bottom panel of Figure <a href="planning.html#fig:nrequired">23.2</a>. We could choose a design that corresponds to this best guess, the average of our prior belief distribution. If the true effect size is 0.3, then a study with 350 subjects will have 80% power.</p>
<p>However, redesigning the study to optimize for the “best guess” is risky because the true effect could be much smaller than 0.3. Suppose we adopt the redesign heuristic of powering the study for an effect size at the 10th percentile of our prior belief distribution, which works out here to be an effect size of 0.17. Following this rule, we would select a design with 1100 subjects. Now suppose the true effect size is, in actuality, only 0.1, so we would need to sample 3200 subjects for 80% power. The power of our chosen 1100-subject design is a mere 38%. Here we see the consequences of having incorrect prior beliefs: our ex-ante guess of the effect size was too optimistic. Even taking what we thought of as a conservative choice – the 10th percentile redesign heuristic – we ended up with too small a study.</p>
<p>A pilot study can help researchers update their priors about important design parameters. Suppose we do a small scale pilot with 100 subjects; we’ll get a noisy but unbiased estimate of the true effect size. We can update prior beliefs by taking a precision weighted average of our priors and the estimate from the pilot, where the weights are the inverse of the variance of each guess. Our posterior beliefs will be closer to the truth, and our posterior uncertainty will be smaller. If we then follow the heuristic of powering the 10th percentile of our (now posterior) beliefs about effect size, we will have come closer to correctly powering our study. Figure <a href="planning.html#fig:pilotupdate">23.3</a> shows how large the studies would be, depending on how the pilot study came out if we were to follow the 10th percentile decision rule. On average, the pilot leads us to design the main study with 1800 subjects, sometimes more and sometimes less.</p>
<p>This exercise reveals that a pilot study can be quite valuable. Without a pilot study, we would chose to sample 1100 subjects, but since the true effect size is only 0.1 (not our best guess of 0.3), the experiment would be underpowered. The pilot study helps us correct our diffuse and incorrect prior beliefs. However, since the pilot is small, we don’t update our priors all the way to the truth. We still end up with a main study that is on average too small (1800), with a corresponding power of 56%. That said, a 56% chance of finding a statistically significant result is better than a 38% chance.</p>
<div class="figure">
<span id="fig:pilotupdate"></span>
<img src="book_files/figure-html/pilotupdate-1.svg" alt="Distribution of post-pilot sample size choices" width="100%"><p class="caption">
Figure 23.3: Distribution of post-pilot sample size choices
</p>
</div>
<p>In summary, pilots are most useful when we are uncertain – or outright wrong – about important design parameters. This uncertainty can often be shrunk by quite a bit without running pilot studies by meta-analyzing past empirical studies. Some things are hard to learn by reading others’ work; pilot studies are especially useful tools for learning about those things.</p>
<p><strong>Further reading</strong>.</p>
<ul>
<li><span class="citation">Van Teijlingen and Hundley (<a href="references.html#ref-van2001importance" role="doc-biblioref">2001</a>)</span></li>
<li><span class="citation">Lancaster, Dodd, and Williamson (<a href="references.html#ref-lancaster2004design" role="doc-biblioref">2004</a>)</span></li>
<li><span class="citation">Turner (<a href="references.html#ref-turner2005role" role="doc-biblioref">2005</a>)</span></li>
<li><span class="citation">Hertzog (<a href="references.html#ref-hertzog2008considerations" role="doc-biblioref">2008</a>)</span></li>
<li>
<span class="citation">Viechtbauer et al. (<a href="references.html#ref-viechtbauer2015simple" role="doc-biblioref">2015</a>)</span> (how many subjects do you need to discover if a rare problem exisits)</li>
<li><span class="citation">Avery et al. (<a href="references.html#ref-avery2017informing" role="doc-biblioref">2017</a>)</span></li>
<li>
<span class="citation">Eldridge et al. (<a href="references.html#ref-eldridge2016defining" role="doc-biblioref">2016</a>)</span> - distinguishes between “feasibility” studies and “pilot” studies. these differ in what is unknown about the main study. “Is it even possible”</li>
<li><span class="citation">Bell, Whitehead, and Julious (<a href="references.html#ref-bell2018guidance" role="doc-biblioref">2018</a>)</span></li>
</ul>
<!-- Pilot studies share a lot in common with baseline measurement. A baseline measurement phase can sometimes be used instead of a pilot to learn about some empirical features. If our sample size is fixed and we are interested in learning whether some outcome measures vary across units or how they covary, we can measure them in the baseline and then make adjustments before a posttreatment survey. We will still control for our imperfect measures at baseline to improve efficiency. --><!-- Diagnosing the pilot study on its own provides stark insights, which amount to: we cannot provide answers to the inquiry in the main study, and should not try to do so. There are also aspects of the logistics of research that within time and financial constraints we simply cannot learn until we run the main study. Science is imperfect, and also iterative, but these mistakes or suboptimal design choices also often lead to discoveries. --><!-- -- how does it help to diagnose the design together? the properties of the main study *change* when we do a pilot. This is because if we run the pilot study, we are doing so to make decisions about how to run the main study, and so our *design* of the main study and thus its results may depend on the *results* (and design) of the pilot study.  --><!-- In this section, we illustrate several general principles that flow from diagnosing pilot studies.  --><!-- Purposes of pilot studies: --><!-- Existence proofs: --><!-- -- is there variation in Y --><!-- -- is there variation in X --><!-- -- what are nodes in M --><!-- -- what are feasible D's, what are feasible treatments / can you implement the treatment (existence proof) --><!-- Harder questions requiring bigger sample sizes: --><!-- -- what is the distribution of X (helps select stratification proportions etc.) --><!-- -- what is the standard deviation of Y0 --><!-- #### Assessing a pilot design --><!-- declare pilot itself and diagnose just as if it were the main study --><!-- if you can't learn the answer, don't make any decisions based on it --><!-- #### Assessing a sequenced design --><!-- if you are making decisions about MIDA for main study based on pilot, diagnose the procedure of two studies, think about POs of pilot --><!-- #### Pilots and baselines --><!-- Designs can be reassessed after baselines and before treatment assignment -- so some of the questions you might do a pilot for can just be answered in a baseline --><!-- #### BLOG material --><!-- Data collection is expensive, and we often only get one bite at the apple. In response, we often conduct an inexpensive (and small) pilot test to help better design the study. Pilot studies have many virtues, including practicing the logistics of data collection and improving measurement tools. But using pilots to get noisy estimates in order to determine sample sizes for scale up comes with risks. --><!-- Pilot studies are often used to get a guess of the average effect size, which is then plugged into power calculators when designing the full study. --><!-- The procedure is: --><!-- 1. Conduct a small pilot study (say, N = 50) --><!-- 2. Obtain an estimate of the effect size (this is noisy, but better than nothing!) --><!-- 3. Conduct a power analysis for a larger study (say, N = 500) on the basis of the estimated effect size in the pilot --><!-- We show in this post that this procedure turns out to be dangerous: at common true effect sizes found in the social sciences, you are at risk of selecting an underpowered design based on the noisy effect estimate in your pilot study. --><!-- A different procedure has better properties: --><!-- 1. Conduct a small pilot study (say, N = 50) --><!-- 2. Obtain an estimate of the **standard deviation of the outcome variable** (again, this is a noisy estimate but better than nothing!) --><!-- 3. Estimate the minimum detectable effect (MDE) for a larger study (say, N = 500), using the estimated standard deviation --><!-- We show what happens in each procedure, using DeclareDesign. In each case, we'll think about a decision the researcher wants to make based on the pilot: should I move forward with my planned study, or should I go back to the drawing board? We'll rely on power to make that decision in the first procedure and the MDE in the second procedure. --><!-- [omitting code] --><!-- For each true effect size, the simulations will give us a distribution of estimated effects that a researcher might use as a basis for power analysis. For example, for a true effect size of 0 the researcher might still estimate an effect of 0.10, and so conduct their power analysis assuming that the true effect is 0.10. For each true effect, we can thus construct a distribution of *power estimates* a researcher might obtain from *estimated* effects. Since we know the true power for the true underlying effect, we can compare the distribution of post-hoc power estimates to the true power one would estimate if one knew the true effect size. --><!-- What did we find? In the plot, we show our guesses for the power of the main study based on our pilot effect size estimates.  --><!-- At high true effect sizes (top row), we do pretty well. Most of our guesses are above 80\% power, leading us to the correct decision that the study is powered. Indeed we often *underestimate* our power in these cases meaning that we run larger studies than we need to. --><!-- However, at low true effect sizes (bottom row) we show we are equally likely to find that the design is in fact powered as underpowered. We are equally likely to guess the power of the design is 90% as 10%. There is a good chance that we will falsely infer that our design is well powered just because we happened to get a high estimate from a noisy pilot. --><!-- ### How about estimating the standard deviation of the outcome? --><!-- Now, let's look at the second approach. Here, instead of using our pilot study to estimate the effect size for a power calculation, we estimate the **standard deviation of the outcome** and use this to calculate the main study's minimum detectable effect. The decision we want to make is: is this MDE small enough to be able to rule out substantively important effects? --><!-- We calculate the minimum detectable effect size using the approximation from [@gelman2006data, pg. 441], 2.8 times the estimated standard error. We estimate the standard error using Equation 3.6 from @gerber2012field.  --><!-- In summary, pilot studies can be valuable in planning research for many reasons, but power calculations based on noisy effect size estimates can be misleading. A better approach is to use the pilot to learn about the distribution of outcome variables. The variability of the outcome variable can then be plugged into MDE formulas or even power calculations with, say, the smallest effect size of political, economic, or social importance. --><!-- In the same spirit, pilot studies could also be used to learn the strength of the correlation between pre-treatment covariates and the outcome variable. With this knowledge in hand, researchers can develop their expectations about how much precision there is to be gained from covariate control or blocking. --><!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book--><!-- start post here, do not edit above -->
</div>
<div id="criticism" class="section level2">
<h2>
<span class="header-section-number">23.6</span> Criticism<a class="anchor" aria-label="anchor" href="#criticism"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>A vital part of the research design process is gathering criticism and feedback from others. Timing is delicate here. Asking for comments on an underdeveloped project can sometimes lead to brainstorming sessions about what research questions one might look into. Such unstructured sessions can be quite useful but essentially restarts the research design lifecycle from the beginning. Sharing work only after a full draft has been produced is worse since the data strategy will have already yielded the realized data. The investigators may have become attached to favored answer strategies and interpretations. While critics can always suggest changes to <em>I</em> and <em>A</em> post-data collection, an almost-finished project is fundamentally constrained by the data strategy as it was implemented.</p>
<p>The best moments to seek advice come before registering preanalysis plans or, if not writing a PAP, before implementing major data strategy elements. The point is not to seek advice exclusively on sampling, assignment, or measurement procedures; the important thing is that there’s still time to modify those design elements. Feedback about the design as a whole can inform changes to the data strategy before it is set in stone.</p>
<p>Feedback will come in many forms. Sometimes the comments are directly about diagnosands. The critic may think the design has too many arms and won’t be well-powered for many inquiries. The critic may be concerned about bias due to excludability violations or selection issues. These comments are especially useful because they can easily be incorporated in design diagnosis and redesign exercises.</p>
<p>Other comments are harder to pin down. A fruitful exercise in such cases is to understand how the criticism fits in to <em>M</em>, <em>I</em>, <em>D</em>, and <em>A</em>. Comments like, “I’m concerned about external validity here” might seem to be about the data strategy. If the units were not randomly sampled from some well-specified population, we can’t generalize from the sample to the population. But if the inquiry is not actually a population quantity, then this inability to use sample data to estimate a population quantity is irrelevant. The question then becomes whether knowing the answer to your sample inquiry helps make theoretical progress or whether we need to switch the inquiry to the population quantity to make headway. Critics will not usually be specific about how their criticism relates to each element of design, so it is up to the seeker to understand the implications of the criticism for the design.</p>
<p>Sometimes we seek feedback from smart people, but they do not immediately understand the design setting. If the critic hasn’t absorbed or taken into account important features of the design, their recommendations and amendments may be off-base. For this reason, it’s important to communicate the design features – the model, inquiry, data strategy, and answer strategy – at a high enough level of detail that the critic is up to speed before passing judgment.</p>
<p><strong>Further reading</strong>.</p>
<ul>
<li>
<span class="citation">Weyland (<a href="references.html#ref-weyland_2020" role="doc-biblioref">2020</a>)</span>: feedback at a book conference</li>
</ul>
<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book--><!-- start post here, do not edit above -->
</div>
<div id="p4pap" class="section level2">
<h2>
<span class="header-section-number">23.7</span> Preanalysis Plan<a class="anchor" aria-label="anchor" href="#p4pap"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>In many research communities, it is becoming standard practice to publicly register a pre-analysis plan (PAP) before implementing some or all of the data strategy. PAPs serve many functions, but most importantly, they clarify which design choices were made before data collection and which were made after. Sometimes – perhaps every time! – we conduct a research study, aspects of <em>M</em>, <em>I</em>, <em>D</em>, and <em>A</em> shift along the way. A concern is that they shift in ways that invalidate the apparent conclusions of the study. For example, “<em>p</em>-hacking” is the shady practice of trying out many regression specifications until the <em>p</em>-value associated with an important test attains statistical significance. PAPs protect researchers by communicating to skeptics <em>when</em> design decisions were made. If the regression specification was detailed in a PAP posted before any data were collected, the test could not be the result of a <em>p</em>-hack.</p>
<p>PAPs are sometimes misinterpreted as a binding commitment to report all pre-registered analyses and nothing but. This view is unrealistic and unnecessarily rigid. While we think that researchers should report all pre-registered analyses <em>somewhere</em> (see Section <a href="realization.html#p4populatedpap">24.3</a> on “populated PAPs”), study writeups inevitably deviate in some way from the PAP – and that’s a good thing. Researchers learn more by conducting research. This learning can and should be reflected in the finalized answer strategy.</p>
<p>Our hunch is that the main consequence of actually writing a PAP is improving the research design itself. Just like research design declaration forces us to think through the details of our model, inquiry, data strategy, and answer strategy, describing those choices in a publicly-posted document surely causes deeper reflection about the design. In this way, the main audience for a PAP is the study authors themselves.</p>
<p>What belongs in a PAP? Recommendations for the set of decisions that should be specified in a PAP remain remarkably unclear and inconsistent across research communities. PAP templates and checklists are proliferating, and the number of items they suggest ranges from nine to sixty. PAPs themselves are becoming longer and more detailed. Some in the American Economic Association and Evidence in Governance and Politics (EGAP) study registries reach hundreds of pages as researchers seek to be ever more comprehensive. Some registries emphasize the registration of the hypotheses to be tested, while others emphasize the registration of the tests that will used. In a review of many PAPs, <span class="citation">Ofosu and Posner (<a href="references.html#ref-ofosu2021pre" role="doc-biblioref">2021</a>)</span> find considerable variation in how often analytically-relevant pieces of information appear in posted plans.</p>
<p>In our view a PAP should center on a design declaration. Currently, most PAPs focus on the answer strategy <em>A</em>: what estimator to use, what covariates to condition on, and what subsets of the data to include. But of course, we also need to know the details of the data strategy <em>D</em>: how units will be sampled, how treatments will be assigned, and how the outcomes will be measured. We need these details to assess the properties of the design and gauge whether the principles of analysis respecting sampling, treatment assignment, and measurement procedures are being followed. We need to know about the inquiry <em>I</em> because we need to know the target of inference. A significant concern is “outcome switching,” wherein the eventual report focuses on different outcomes than initially intended. When we switch outcomes, we switch inquiries! We need enough of the model <em>M</em> in the plan to describe <em>I</em> in sufficient detail. In short, a design declaration is what belongs in a PAP because a design declaration specifies all of the analytically-relevant design decisions.</p>
<p>In addition to a design declaration, a PAP should include mock analyses conducted on simulated data. If the design declaration is made formally in code, creating simulated data that resemble the eventually realized data is straightforward. We think researchers should run their answer strategy on the mock data, creating mock figures and tables that will ultimately be made with real data. In our experience, <em>this</em> is the step that really causes researchers to think hard about all aspects of their design.</p>
<p>PAPs can, optionally, include design diagnoses in addition to declarations, since it can be informative to describe why a particular design was chosen. For this reason, a PAP might include estimates of diagnosands like power, root-mean-squared-error, or bias. If a researcher writes in a PAP that the power to detect a very small effect is large, then if the study comes back null, the eventual writeup can much more credibly rule out “low power” as an explanation for the null.</p>
<div id="example-12" class="section level3">
<h3>
<span class="header-section-number">23.7.1</span> Example<a class="anchor" aria-label="anchor" href="#example-12"><i class="fas fa-link"></i></a>
</h3>
<p>In this section, we provide an example of how to supplement a PAP with a design declaration. We follow the actual PAP for <span class="citation">Bonilla and Tillery (<a href="references.html#ref-bonilla_tillery_2020" role="doc-biblioref">2020</a>)</span>, which was posted to the <a href="https://aspredicted.org/q56qq.pdf">As Predicted registry</a>. The study’s goal is to estimate the causal effects of alternative framings of Black Lives Matter (BLM) on support for the movement among Black Americans overall and among subsets of the Black community. These study authors are models of research transparency: they prominently link to the PAP in the published article, they conduct no non-preregistered analyses except those requested during the review process, and their replication archive includes all materials required to confirm their analyses, all of which we were able to reproduce exactly with minimal effort. Our goal with this section is to show how design declaration can supplement and complement existing planning practices.</p>
<div id="model-1" class="section level4">
<h4>
<span class="header-section-number">23.7.1.1</span> Model<a class="anchor" aria-label="anchor" href="#model-1"><i class="fas fa-link"></i></a>
</h4>
<p>The authors write in their PAP:</p>
<blockquote>
<p>We hypothesize that: H1: Black Nationalist frames of the BLM movement will increase perceived effectiveness of BLM among African American test subjects. H2: Feminist frames of the BLM movement will increase perceived effectiveness of BLM among African American women, but decrease perceived effectiveness in male subjects. H3: LGBTQ and Intersectional frames of the BLM movement will have no effect (or a demobilizing effect) on the perceived effectiveness of BLM African American subjects.</p>
</blockquote>
<p>These hypotheses reflect a model of coalition politics that emphasizes the tensions induced by overlapping identities. Framing the BLM movement as feminist or pro-LGBTQ may increase support among Black women or Black LGBTQ identifiers, but that increase may come at the expense of support among Black men or Black Americans who do not identify as LGBTQ. Similarly, this model predicts that subjects with stronger attachment to their Black identity will have a larger response to a Black nationalist framing of BLM than those with weaker attachments.</p>
<p>The model also includes beliefs about the distributions of gender, LGBTQ status, and Black identity strength. In the data strategy, Black identity was measured with the standard linked fate measure. Other background characteristics that may be correlated with BLM support include age, religiosity, income, education, and familiarity with the movement, so these are included in <em>M</em> as well.</p>
<p>The study’s focus will be on the causal effects of nationalism, feminism, and intersectional frames relative to a general description of the Black Lives Matter movement. Model beliefs about treatment effect heterogeneity are embedded in the model declaration. The effect of the nationalism treatment is hypothesized to be stronger, the greater subjects’ sense of linked fate; the effect of the feminism treatment should be negative for men but positive for women; the effect of the intersectionality treatment should be positive for LGBTQ identifiers, but negative for non-identifiers.</p>
<div class="sourceCode" id="cb139"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">rescale</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span>
  <span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span>

<span class="va">likert_cut</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span>
  <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cut.html">cut</a></span><span class="op">(</span><span class="va">x</span>, breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">100</span>, <span class="fl">0.1</span>, <span class="fl">0.3</span>, <span class="fl">0.6</span>, <span class="fl">0.8</span>, <span class="fl">100</span><span class="op">)</span>, labels <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span>

<span class="va">model</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_model.html">declare_model</a></span><span class="op">(</span>
    N <span class="op">=</span> <span class="fl">800</span>,
    female <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.51</span><span class="op">)</span>,
    lgbtq <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span>,
    linked_fate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, <span class="va">N</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, 
                         prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.15</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span>,
    age <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">18</span><span class="op">:</span><span class="fl">80</span>, <span class="va">N</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,
    religiosity <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span>, <span class="va">N</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,
    income <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">12</span>, <span class="va">N</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,
    college <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>,
    blm_familiarity <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span>, <span class="va">N</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,
    U <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>,
    blm_support_latent <span class="op">=</span> <span class="fu">rescale</span><span class="op">(</span>
      <span class="va">U</span> <span class="op">+</span> <span class="fl">0.1</span> <span class="op">*</span> <span class="va">blm_familiarity</span> <span class="op">+</span> 
        <span class="fl">0.45</span> <span class="op">*</span> <span class="va">linked_fate</span> <span class="op">+</span> 
        <span class="fl">0.001</span> <span class="op">*</span> <span class="va">age</span> <span class="op">+</span> 
        <span class="fl">0.25</span> <span class="op">*</span> <span class="va">lgbtq</span> <span class="op">+</span> 
        <span class="fl">0.01</span> <span class="op">*</span> <span class="va">income</span> <span class="op">+</span> 
        <span class="fl">0.1</span> <span class="op">*</span> <span class="va">college</span> <span class="op">+</span> 
        <span class="op">-</span><span class="fl">0.1</span> <span class="op">*</span> <span class="va">religiosity</span><span class="op">)</span>,
    <span class="co"># potential_outcomes</span>
    blm_support_Z_general <span class="op">=</span> 
      <span class="fu">likert_cut</span><span class="op">(</span><span class="va">blm_support_latent</span><span class="op">)</span>,
    blm_support_Z_nationalism <span class="op">=</span> 
      <span class="fu">likert_cut</span><span class="op">(</span><span class="va">blm_support_latent</span> <span class="op">+</span> <span class="fl">0.01</span> <span class="op">+</span> 
                   <span class="fl">0.01</span> <span class="op">*</span> <span class="va">linked_fate</span> <span class="op">+</span> 
                   <span class="fl">0.01</span> <span class="op">*</span> <span class="va">blm_familiarity</span><span class="op">)</span>,
    blm_support_Z_feminism <span class="op">=</span> 
      <span class="fu">likert_cut</span><span class="op">(</span><span class="va">blm_support_latent</span> <span class="op">-</span> <span class="fl">0.02</span> <span class="op">+</span> 
                   <span class="fl">0.07</span> <span class="op">*</span> <span class="va">female</span> <span class="op">+</span> 
                   <span class="fl">0.01</span> <span class="op">*</span> <span class="va">blm_familiarity</span><span class="op">)</span>,
    blm_support_Z_intersectional <span class="op">=</span> 
      <span class="fu">likert_cut</span><span class="op">(</span><span class="va">blm_support_latent</span>  <span class="op">-</span> <span class="fl">0.05</span> <span class="op">+</span> 
                   <span class="fl">0.15</span> <span class="op">*</span> <span class="va">lgbtq</span> <span class="op">+</span> 
                   <span class="fl">0.01</span> <span class="op">*</span> <span class="va">blm_familiarity</span><span class="op">)</span>
  <span class="op">)</span></code></pre></div>
</div>
<div id="inquiry-1" class="section level4">
<h4>
<span class="header-section-number">23.7.1.2</span> Inquiry<a class="anchor" aria-label="anchor" href="#inquiry-1"><i class="fas fa-link"></i></a>
</h4>
<p>The inquiries for this study naturally include the average effects of all three treatments relative to the “general” framing, as well as the differences in average effects for subgroups. When describing their planned analyses, the authors write:</p>
<blockquote>
<p>We will also look at differences in responses between those indicating a pre-treatment familiarity BLM (4-Extensive knowledge to 1-Never heard of BLM), gender (particularly on the Feminist treatment), linked fate (particularly on the Nationalist treatment), and LGBT+ affiliation (particularly on the LGBT+ treatment), though we are not necessarily expecting these moderations to have a strong effect because samples may lack adequate representation.</p>
</blockquote>
<p>In the code below, we specify how each treatment effect changes with its corresponding covariate <span class="math inline">\(X\)</span> with <span class="math inline">\(\frac{\mathrm{cov}(\tau_i, X)}{\mathbb{V}(X)}\)</span>, which is identical to the difference-in-difference for the binary covariates (<code>female</code> and <code>lgbtq</code>) and is the slope of the best linear predictor of how the effect changes over the range of <code>linked_fate</code>, and <code>blm_familiarity</code> which we are treating as quasi-continuous here.</p>
<div class="sourceCode" id="cb140"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">slope</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">y</span>, <span class="va">x</span><span class="op">)</span> <span class="op">{</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">x</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">}</span>

<span class="va">inquiry</span> <span class="op">&lt;-</span>  
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_inquiry.html">declare_inquiries</a></span><span class="op">(</span>
    <span class="co"># Average effects</span>
    ATE_nationalism <span class="op">=</span> 
      <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">blm_support_Z_nationalism</span> <span class="op">-</span> <span class="va">blm_support_Z_general</span><span class="op">)</span>,
    ATE_feminism <span class="op">=</span> 
      <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">blm_support_Z_feminism</span> <span class="op">-</span> <span class="va">blm_support_Z_general</span><span class="op">)</span>,
    ATE_intersectional <span class="op">=</span> 
      <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">blm_support_Z_intersectional</span> <span class="op">-</span> <span class="va">blm_support_Z_general</span><span class="op">)</span>,
    
    <span class="co"># Overall heterogeneity w.r.t. blm_familiarity</span>
    DID_nationalism_familiarity <span class="op">=</span> 
      <span class="fu">slope</span><span class="op">(</span><span class="va">blm_support_Z_nationalism</span> <span class="op">-</span> <span class="va">blm_support_Z_general</span>, 
            <span class="va">blm_familiarity</span><span class="op">)</span>,
    DID_feminism_familiarity <span class="op">=</span> 
      <span class="fu">slope</span><span class="op">(</span><span class="va">blm_support_Z_feminism</span> <span class="op">-</span> <span class="va">blm_support_Z_general</span>, 
            <span class="va">blm_familiarity</span><span class="op">)</span>,
    DID_intersectional_familiarity <span class="op">=</span> 
      <span class="fu">slope</span><span class="op">(</span><span class="va">blm_support_Z_intersectional</span> <span class="op">-</span> <span class="va">blm_support_Z_general</span>, 
            <span class="va">blm_familiarity</span><span class="op">)</span>,
    
    <span class="co"># Treatment-specific heterogeneity</span>
    DID_nationalism_linked_fate <span class="op">=</span> 
      <span class="fu">slope</span><span class="op">(</span><span class="va">blm_support_Z_nationalism</span> <span class="op">-</span> <span class="va">blm_support_Z_general</span>, 
            <span class="va">linked_fate</span><span class="op">)</span>,
    DID_feminism_gender <span class="op">=</span> 
      <span class="fu">slope</span><span class="op">(</span><span class="va">blm_support_Z_feminism</span> <span class="op">-</span> <span class="va">blm_support_Z_general</span>,
            <span class="va">female</span><span class="op">)</span>,
    DID_intersectional_lgbtq <span class="op">=</span> 
      <span class="fu">slope</span><span class="op">(</span><span class="va">blm_support_Z_intersectional</span> <span class="op">-</span> <span class="va">blm_support_Z_general</span>, 
            <span class="va">lgbtq</span><span class="op">)</span>
  <span class="op">)</span></code></pre></div>
</div>
<div id="data-strategy-1" class="section level4">
<h4>
<span class="header-section-number">23.7.1.3</span> Data strategy<a class="anchor" aria-label="anchor" href="#data-strategy-1"><i class="fas fa-link"></i></a>
</h4>
<p>This study’s subjects are 800 Black Americans recruited by the survey firm Qualtrics using a quota sampling procedure. We omit this sampling step in our declaration: 800 subjects are described in the model declaration above. The reason is that, as is common practice in the analysis of survey experiments on convenience samples, the authors do not formally extrapolate from their data to make generalizations about the population of Black Americans. The inquiries they study are sample average effects. If the authors had used a different sampling strategy, such as using random sampling through random digit dialing, we would have defined the population from which they were sampling and the random sampling procedure.</p>
<p>After subjects’ background characteristics were measured, they were assigned to one of four treatment conditions. Since the survey was conducted on Qualtrics, we assume that the authors used the built-in randomization tools, which use simple (Bernoulli) random assignment.</p>
<div class="sourceCode" id="cb141"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">data_strategy</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_assignment.html">declare_assignment</a></span><span class="op">(</span>
    conditions <span class="op">=</span> 
      <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"general"</span>, <span class="st">"nationalism"</span>, <span class="st">"feminism"</span>, <span class="st">"intersectional"</span><span class="op">)</span>, 
    simple <span class="op">=</span> <span class="cn">TRUE</span>
  <span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_measurement.html">declare_measurement</a></span><span class="op">(</span>blm_support <span class="op">=</span> <span class="fu">reveal_outcomes</span><span class="op">(</span><span class="va">blm_support</span> <span class="op">~</span> <span class="va">Z</span><span class="op">)</span><span class="op">)</span> </code></pre></div>
</div>
<div id="answer-strategy-1" class="section level4">
<h4>
<span class="header-section-number">23.7.1.4</span> Answer strategy<a class="anchor" aria-label="anchor" href="#answer-strategy-1"><i class="fas fa-link"></i></a>
</h4>
<p>The authors write:</p>
<blockquote>
<p>We will run an OLS regression predicting the support for, effectiveness of, and trust in BLM on each treatment condition. […] We will also look at differences in responses between those indicating a pre-treatment familiarity BLM (4-Extensive knowledge to 1-Never heard of BLM), gender (particularly on the Feminist treatment), linked fate (particularly on the Nationalist treatment), and LGBT+ affiliation (particularly on the LGBT+ treatment), though we are not necessarily expecting these moderations to have a strong effect because samples may lack adequate representation. We plan to conduct analyses without controls. As we will check for between group balance, we may also run OLS analyses with demographic controls (age, linked fate, gender, sexual orientation, religiosity, income, education, and ethnic or multi-racial backgrounds), and will report differences in OLS results.</p>
</blockquote>
<p>In DeclareDesign, this corresponds to five estimators, with two shooting at the ATEs and three shooting at the differences-in-differences. We use OLS for all five. The majority of the code is bookkeeping to ensure we match the right regression coefficient with the appropriate inquiry.</p>
<div class="sourceCode" id="cb142"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">answer_strategy</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span>
    <span class="va">blm_support</span> <span class="op">~</span> <span class="va">Z</span>,
    term <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Znationalism"</span>, <span class="st">"Zfeminism"</span>, <span class="st">"Zintersectional"</span><span class="op">)</span>,
    model <span class="op">=</span> <span class="va">lm_robust</span>,
    inquiry <span class="op">=</span> 
      <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"ATE_nationalism"</span>, <span class="st">"ATE_feminism"</span>, <span class="st">"ATE_intersectional"</span><span class="op">)</span>,
    label <span class="op">=</span> <span class="st">"OLS"</span>
  <span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span>
    <span class="va">blm_support</span> <span class="op">~</span> <span class="va">Z</span> <span class="op">+</span> <span class="va">age</span> <span class="op">+</span> <span class="va">female</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">linked_fate</span><span class="op">)</span> <span class="op">+</span> <span class="va">lgbtq</span>,
    term <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Znationalism"</span>, <span class="st">"Zfeminism"</span>, <span class="st">"Zintersectional"</span><span class="op">)</span>,
    inquiry <span class="op">=</span> 
      <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"ATE_nationalism"</span>, <span class="st">"ATE_feminism"</span>, <span class="st">"ATE_intersectional"</span><span class="op">)</span>,
    model <span class="op">=</span> <span class="va">lm_robust</span>,
    label <span class="op">=</span> <span class="st">"OLS with controls"</span>
  <span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span>
    <span class="va">blm_support</span> <span class="op">~</span> <span class="va">Z</span><span class="op">*</span><span class="va">blm_familiarity</span>,
    term <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Znationalism:blm_familiarity"</span>, 
             <span class="st">"Zfeminism:blm_familiarity"</span>, 
             <span class="st">"Zintersectional:blm_familiarity"</span><span class="op">)</span>,
    model <span class="op">=</span> <span class="va">lm_robust</span>,
    inquiry <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"DID_nationalism_familiarity"</span>, 
                 <span class="st">"DID_feminism_familiarity"</span>, 
                 <span class="st">"DID_intersectional_familiarity"</span><span class="op">)</span>,
    label <span class="op">=</span> <span class="st">"DID_familiarity"</span>
  <span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span>
    <span class="va">blm_support</span> <span class="op">~</span> <span class="va">Z</span> <span class="op">*</span> <span class="va">linked_fate</span>,
    term <span class="op">=</span> <span class="st">"Zfeminism:linked_fate"</span>,
    model <span class="op">=</span> <span class="va">lm_robust</span>,
    inquiry <span class="op">=</span> <span class="st">"DID_nationalism_linked_fate"</span>,
    label <span class="op">=</span> <span class="st">"DID_nationalism_linked_fate"</span>
  <span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span>
    <span class="va">blm_support</span> <span class="op">~</span> <span class="va">Z</span> <span class="op">*</span> <span class="va">female</span>,
    term <span class="op">=</span> <span class="st">"Zfeminism:female"</span>,
    model <span class="op">=</span> <span class="va">lm_robust</span>,
    inquiry <span class="op">=</span> <span class="st">"DID_feminism_gender"</span>,
    label <span class="op">=</span> <span class="st">"DID_feminism_gender"</span>
  <span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span>
    <span class="va">blm_support</span> <span class="op">~</span> <span class="va">Z</span> <span class="op">*</span> <span class="va">lgbtq</span>,
    term <span class="op">=</span> <span class="st">"Zintersectional:lgbtq"</span>,
    model <span class="op">=</span> <span class="va">lm_robust</span>,
    inquiry <span class="op">=</span> <span class="st">"DID_intersectional_lgbtq"</span>,
    label <span class="op">=</span> <span class="st">"DID_intersectional_lgbtq"</span>
  <span class="op">)</span></code></pre></div>
</div>
<div id="mock-analysis" class="section level4">
<h4>
<span class="header-section-number">23.7.1.5</span> Mock analysis<a class="anchor" aria-label="anchor" href="#mock-analysis"><i class="fas fa-link"></i></a>
</h4>
<p>Putting it all together, we can declare the complete design and draw mock data from it.</p>
<div class="sourceCode" id="cb143"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">design</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op">+</span> <span class="va">inquiry</span> <span class="op">+</span> <span class="va">data_strategy</span> <span class="op">+</span> <span class="va">answer_strategy</span>
<span class="va">mock_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/draw_functions.html">draw_data</a></span><span class="op">(</span><span class="va">design</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:unnamed-chunk-457">Table 23.1: </span>Mock analysis from Bonilla and Tillery design.
</caption>
<thead><tr>
<th style="text-align:left;">
ID
</th>
<th style="text-align:right;">
female
</th>
<th style="text-align:right;">
lgbtq
</th>
<th style="text-align:right;">
linked_fate
</th>
<th style="text-align:right;">
age
</th>
<th style="text-align:right;">
religiosity
</th>
<th style="text-align:right;">
income
</th>
<th style="text-align:right;">
college
</th>
<th style="text-align:right;">
blm_familiarity
</th>
<th style="text-align:right;">
U
</th>
<th style="text-align:right;">
blm_support_latent
</th>
<th style="text-align:right;">
blm_support_Z_general
</th>
<th style="text-align:right;">
blm_support_Z_nationalism
</th>
<th style="text-align:right;">
blm_support_Z_feminism
</th>
<th style="text-align:right;">
blm_support_Z_intersectional
</th>
<th style="text-align:left;">
Z
</th>
<th style="text-align:right;">
Z_cond_prob
</th>
<th style="text-align:right;">
blm_support
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
001
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
27
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0.976
</td>
<td style="text-align:right;">
0.758
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
intersectional
</td>
<td style="text-align:right;">
0.25
</td>
<td style="text-align:right;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
002
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
44
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.274
</td>
<td style="text-align:right;">
0.429
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
feminism
</td>
<td style="text-align:right;">
0.25
</td>
<td style="text-align:right;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
003
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
78
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
0.349
</td>
<td style="text-align:right;">
0.491
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
nationalism
</td>
<td style="text-align:right;">
0.25
</td>
<td style="text-align:right;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
004
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0.929
</td>
<td style="text-align:right;">
0.841
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
feminism
</td>
<td style="text-align:right;">
0.25
</td>
<td style="text-align:right;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
005
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
69
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0.351
</td>
<td style="text-align:right;">
0.540
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
feminism
</td>
<td style="text-align:right;">
0.25
</td>
<td style="text-align:right;">
3
</td>
</tr>
</tbody>
</table></div>
<p>Table <a href="#tab:bonillatilleryregtable"><strong>??</strong></a> shows a mock analysis ofaverage effects (estimated with and without covariate adjustment) as well as the heterogeneous effects analyses with respect to the quasi-continuous moderators.</p>
<div class="inline-table"><table class="texreg" style="margin: 10px auto;border-collapse: collapse;border-spacing: 0px;caption-side: bottom;color: #000000;border-top: 2px solid #000000;">
<caption>
Mock regression table from Bonilla and Tillery design.
</caption>
<thead><tr>
<th style="padding-left: 5px;padding-right: 5px;">
 
</th>
<th style="padding-left: 5px;padding-right: 5px;">
Model 1
</th>
<th style="padding-left: 5px;padding-right: 5px;">
Model 2
</th>
<th style="padding-left: 5px;padding-right: 5px;">
Model 3
</th>
<th style="padding-left: 5px;padding-right: 5px;">
Model 4
</th>
</tr></thead>
<tbody>
<tr style="border-top: 1px solid #000000;">
<td style="padding-left: 5px;padding-right: 5px;">
(Intercept)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
3.629<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
1.283<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
1.383<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
3.284<sup>***</sup>
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.059)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.104)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.146)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.140)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Znationalism
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.339<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.305<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.101
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.056
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.089)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.048)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.199)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.217)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Zfeminism
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.284<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.208<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.543<sup>**</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.361
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.084)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.049)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.207)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.198)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Zintersectional
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.073
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.041
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.169
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.031
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.087)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.050)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.230)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.208)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
female
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.071<sup>*</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.035)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
lgbtq
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.279<sup>*</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.110)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
age
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.000
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.001)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
religiosity
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.147<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.010)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
income
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.013<sup>**</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.005)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
college
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.165<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.035)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
linked_fate
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.549<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.561<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.015)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.035)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
blm_familiarity
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.173<sup>***</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.141<sup>**</sup>
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.017)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.052)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Znationalism:linked_fate
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.067
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.048)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Zfeminism:linked_fate
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.075
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.050)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Zintersectional:linked_fate
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.061
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.055)
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Znationalism:blm_familiarity
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.147
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.081)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Zfeminism:blm_familiarity
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.034
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.074)
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Zintersectional:blm_familiarity
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
-0.040
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
 
</td>
<td style="padding-left: 5px;padding-right: 5px;">
(0.079)
</td>
</tr>
<tr style="border-top: 1px solid #000000;">
<td style="padding-left: 5px;padding-right: 5px;">
R<sup>2</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.038
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.701
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.567
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.081
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Adj. R<sup>2</sup>
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.034
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.697
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.563
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.073
</td>
</tr>
<tr>
<td style="padding-left: 5px;padding-right: 5px;">
Num. obs.
</td>
<td style="padding-left: 5px;padding-right: 5px;">
800
</td>
<td style="padding-left: 5px;padding-right: 5px;">
800
</td>
<td style="padding-left: 5px;padding-right: 5px;">
800
</td>
<td style="padding-left: 5px;padding-right: 5px;">
800
</td>
</tr>
<tr style="border-bottom: 2px solid #000000;">
<td style="padding-left: 5px;padding-right: 5px;">
RMSE
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.882
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.494
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.593
</td>
<td style="padding-left: 5px;padding-right: 5px;">
0.864
</td>
</tr>
</tbody>
<tfoot><tr>
<td style="font-size: 0.8em;" colspan="5">
<sup><em><strong></strong></em></sup>p &lt; 0.001; <sup></sup>p &lt; 0.01; <sup></sup>p &lt; 0.05
</td>
</tr></tfoot>
</table></div>
<div class="figure">
<span id="fig:bonillatilleryresultsfig"></span>
<img src="book_files/figure-html/bonillatilleryresultsfig-1.svg" alt="Mock coefficient plot from Bonilla and Tillery design." width="100%"><p class="caption">
Figure 23.4: Mock coefficient plot from Bonilla and Tillery design.
</p>
</div>
</div>
<div id="design-diagnosis" class="section level4">
<h4>
<span class="header-section-number">23.7.1.6</span> Design diagnosis<a class="anchor" aria-label="anchor" href="#design-diagnosis"><i class="fas fa-link"></i></a>
</h4>
<p>Finally, while a design diagnosis is not a necessary component of a preanalysis plan, it can be useful to show readers why a particular design was chosen over others. This diagnosis indicates that the design produces unbiased estimates but is better powered from some inquires than others (under the above assumptions about effect size, which were our own and not the original authors’). We are well-powered for the average effects, and the power increases when we include covariate controls. The design is probably too small for most of the heterogeneous effect analyses, which is a point directly conceded in the authors’ original PAP.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:bonillatillerydiagnosis">Table 23.2: </span>Design diagnosis for Bonilla and Tillery design.
</caption>
<thead><tr>
<th style="text-align:left;">
Estimand
</th>
<th style="text-align:left;">
Estimator
</th>
<th style="text-align:right;">
Bias
</th>
<th style="text-align:right;">
Power
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
ATE feminism
</td>
<td style="text-align:left;">
OLS
</td>
<td style="text-align:right;">
-0.015
</td>
<td style="text-align:right;">
0.45
</td>
</tr>
<tr>
<td style="text-align:left;">
ATE feminism
</td>
<td style="text-align:left;">
OLS with controls
</td>
<td style="text-align:right;">
-0.001
</td>
<td style="text-align:right;">
0.81
</td>
</tr>
<tr>
<td style="text-align:left;">
ATE intersectional
</td>
<td style="text-align:left;">
OLS
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.13
</td>
</tr>
<tr>
<td style="text-align:left;">
ATE intersectional
</td>
<td style="text-align:left;">
OLS with controls
</td>
<td style="text-align:right;">
-0.002
</td>
<td style="text-align:right;">
0.33
</td>
</tr>
<tr>
<td style="text-align:left;">
ATE nationalism
</td>
<td style="text-align:left;">
OLS
</td>
<td style="text-align:right;">
-0.006
</td>
<td style="text-align:right;">
0.97
</td>
</tr>
<tr>
<td style="text-align:left;">
ATE nationalism
</td>
<td style="text-align:left;">
OLS with controls
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
1.00
</td>
</tr>
<tr>
<td style="text-align:left;">
DID feminism familiarity
</td>
<td style="text-align:left;">
DID familiarity
</td>
<td style="text-align:right;">
-0.002
</td>
<td style="text-align:right;">
0.05
</td>
</tr>
<tr>
<td style="text-align:left;">
DID feminism gender
</td>
<td style="text-align:left;">
DID feminism gender
</td>
<td style="text-align:right;">
0.006
</td>
<td style="text-align:right;">
0.43
</td>
</tr>
<tr>
<td style="text-align:left;">
DID intersectional familiarity
</td>
<td style="text-align:left;">
DID familiarity
</td>
<td style="text-align:right;">
-0.008
</td>
<td style="text-align:right;">
0.04
</td>
</tr>
<tr>
<td style="text-align:left;">
DID intersectional lgbtq
</td>
<td style="text-align:left;">
DID intersectional lgbtq
</td>
<td style="text-align:right;">
0.027
</td>
<td style="text-align:right;">
0.34
</td>
</tr>
<tr>
<td style="text-align:left;">
DID nationalism familiarity
</td>
<td style="text-align:left;">
DID familiarity
</td>
<td style="text-align:right;">
-0.019
</td>
<td style="text-align:right;">
0.08
</td>
</tr>
<tr>
<td style="text-align:left;">
DID nationalism linked fate
</td>
<td style="text-align:left;">
DID nationalism linked fate
</td>
<td style="text-align:right;">
-0.053
</td>
<td style="text-align:right;">
0.04
</td>
</tr>
</tbody>
</table></div>
<!-- ## Debates over the value of PAPs --><!-- PAPs are often described as a tool for tying researchers' hand and reducing "researcher degrees of freedom" to seek out congenial analyses. PAPs are sometimes criticized because (A) they don't *actually* constrain what researchers do and (B) they *shouldn't*.   --><!-- PAPs might not actually constrain researchers because most journals and pressess do not check against PAPs. As reviewers, we have sometimes requested that authors send in the PAPs referenced in their papers. In nearly every case, some analyses promised in the PAP were not included, even in an appendix. Some analyses that appear in the paper were not included in the PAP. As we discuss in greater detail in section XXX on reconciliation, current practice is clearly too causal when distinguishing which analyses were pre-specified and which were not. --><!-- Some critics of PAPs charge that we shouldn't pre-register our analysis plans because we should be open to discovery. We learn once we arrive in the field what the interesting questions are, so we shouldn't be constrained by what we thought would happen when sitting in our offices. Furthermore, sometimes people pre-register analyses that are biased, misspecified, or are otherwise inappropriate, so they shouldn't be required to present them. We agree with all the above points -- researchers should create post-implementation reports (CITE JENS in PA) that follow the PAP. Analyses over and above the PAP should simply be labeled as such. --><!-- Our take is that PAPs are helpful tools for researchers to plan research better and they are useful for clarifying what the researcher was thinking at each stage.  --><!-- ## Other benefits of PAPS --><!-- - involving partners: agreeing on the analysis procedure ex ante reduces ex post conflict --><!-- - frontloading research design decisions (get more specific, identify problems) --><!-- - Anticipating what might go wrong: attrition, noncompliance, study failure, missing covariate data, etc. --><!-- - Faithful reanalysis. Reanalysts lose a degree of freedom in determining what an author might have intended by a given analysis.  --><!-- - Easier design comparison. If a design is declared at the preanalysis plan phase, then it enables direct comparison with the design as implemented in the final write-up. Side-by-side comparison of the code neatly clarifies which design choices were made ex-ante and ex-post. Side-by-side comparison of the performance of a planned and implemented designs clarify under what conditions deviations from plans are defensible improvements. --><!-- - ethics (summarize and cite Jay's ideas here: http://www.jasonlyall.com/wp-content/uploads/2020/08/PreregisterYourEthics.pdf) --><!-- - ethical outcomes are potential outcomes, so we need to think about them ex ante not just on the basis of revealed outcomes --><!-- ### countering objections: --><!-- - Time-consuming. Yes but in our experience we only pay this cost for failed studies. Fur successful studies, nearly all work that goes in to the pap pays off in terms of higher qualtity design, literal words we already wrote, and written-in-advance analysis code. --><!-- - Won't stop determined cheaters. Yes -- remember that the goal is not to prevent fraud, it's to help *researchers* improve their designs. Science depends on trust. --><!-- - Replication is better (@Coffman2015). These are complements, not substitutes. --><!-- - I can't preregister what I will do because I don't know what I will find. That's fine too, just write down how you will go about "finding" things so we (and YOU) can understand your own process. --><!-- ### Other thoughts --><!-- - when is the right moment to write a pap? --><!-- - relationship to registered reports? --><!-- - SOPs --><!-- ### citations on paps --><p><strong>Further reading</strong>.</p>
<ul>
<li>
<span class="citation">Casey, Glennerster, and Miguel (<a href="references.html#ref-Casey2012" role="doc-biblioref">2012</a>)</span> introduces PAPs in Economics.</li>
<li>
<span class="citation">Olken (<a href="references.html#ref-Olken2015" role="doc-biblioref">2015</a>)</span> is a prominent skeptical take on PAPs.</li>
<li>
<span class="citation">Green and Lin (<a href="references.html#ref-Green2015" role="doc-biblioref">2016</a>)</span> offers standard operating procedures as a way to plan for eventualities not covered in the PAP.</li>
<li>
<span class="citation">Christensen and Miguel (<a href="references.html#ref-Christensen2018" role="doc-biblioref">2018</a>)</span> reviews many issues surrounding PAPs</li>
<li>
<span class="citation">Coffman and Niederle (<a href="references.html#ref-Coffman2015" role="doc-biblioref">2015</a>)</span> argues for emphasizing replication studies over PAPs.</li>
<li>
<span class="citation">Humphreys, Sierra, and Windt (<a href="references.html#ref-Humphreys2013a" role="doc-biblioref">2013</a>)</span> introduces PAPs in Political Science.</li>
<li>
<span class="citation">Miguel et al. (<a href="references.html#ref-Miguel2014" role="doc-biblioref">2014</a>)</span> describes PAP adoption by journals</li>
<li>
<span class="citation">Ofosu and Posner (<a href="references.html#ref-Ofosu2020" role="doc-biblioref">2020</a>)</span> consider the relationship between preregistration and publication</li>
<li>
<span class="citation">Rennie (<a href="references.html#ref-Rennie2004" role="doc-biblioref">2004</a>)</span> and <span class="citation">Zarin and Tse (<a href="references.html#ref-Zarin2008" role="doc-biblioref">2008</a>)</span> explore the consequences of pre-registration for medical trials</li>
<li>
<span class="citation">Nosek et al. (<a href="references.html#ref-Nosek2015a" role="doc-biblioref">2015</a>)</span> introduces the TOP guidelines</li>
<li>
<span class="citation">Findley et al. (<a href="references.html#ref-Findley:2016" role="doc-biblioref">2016</a>)</span> describes results-blind review</li>
</ul>
<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book--><!-- start post here, do not edit above -->
</div>
</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="brainstorming.html"><span class="header-section-number">22</span> Brainstorming</a></div>
<div class="next"><a href="realization.html"><span class="header-section-number">24</span> Realization</a></div>
</div></main><div id="on-this-page-nav" class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#planning"><span class="header-section-number">23</span> Planning</a></li>
<li><a class="nav-link" href="#ethics"><span class="header-section-number">23.1</span> Ethics</a></li>
<li><a class="nav-link" href="#approvals"><span class="header-section-number">23.2</span> Approvals</a></li>
<li><a class="nav-link" href="#partners"><span class="header-section-number">23.3</span> Partners</a></li>
<li><a class="nav-link" href="#funding"><span class="header-section-number">23.4</span> Funding</a></li>
<li><a class="nav-link" href="#p4piloting"><span class="header-section-number">23.5</span> Piloting</a></li>
<li><a class="nav-link" href="#criticism"><span class="header-section-number">23.6</span> Criticism</a></li>
<li>
<a class="nav-link" href="#p4pap"><span class="header-section-number">23.7</span> Preanalysis Plan</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#example-12"><span class="header-section-number">23.7.1</span> Example</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="download-code" href="./planning.R"><i class="far fa-file-code"></i> Download R code</a></li>
          
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Research Design: Declare, Diagnose, Redesign</strong>" was written by Graeme Blair, Alexander Coppock, and Macartan Humphreys. </p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
