<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 9 Choosing an answer strategy | Research Design: Declare, Diagnose, Redesign</title>
<meta name="author" content="Graeme Blair, Jasper Cooper, Alexander Coppock, and Macartan Humphreys">
<!-- CSS --><!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.1.9000/tabs.js"></script><script src="libs/bs3compat-0.2.1.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://hypothes.is/embed.js" async></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Research Design: Declare, Diagnose, Redesign</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li class="book-part">Introduction</li>
<li><a class="" href="preamble.html"><span class="header-section-number">1</span> Preamble</a></li>
<li><a class="" href="improving-research-designs.html"><span class="header-section-number">2</span> Improving research designs</a></li>
<li><a class="" href="software-primer.html"><span class="header-section-number">3</span> Software primer</a></li>
<li><a class="" href="part-i-exercises.html"><span class="header-section-number">4</span> Part I Exercises</a></li>
<li class="book-part">Declaration, Diagnosis, Redesign</li>
<li><a class="" href="formalizing-mida.html"><span class="header-section-number">5</span> Formalizing MIDA</a></li>
<li><a class="" href="specifying-the-model.html"><span class="header-section-number">6</span> Specifying the model</a></li>
<li><a class="" href="defining-the-inquiry.html"><span class="header-section-number">7</span> Defining the inquiry</a></li>
<li><a class="" href="crafting-a-data-strategy.html"><span class="header-section-number">8</span> Crafting a data strategy</a></li>
<li><a class="active" href="choosing-an-answer-strategy.html"><span class="header-section-number">9</span> Choosing an answer strategy</a></li>
<li><a class="" href="diagnosis.html"><span class="header-section-number">10</span> Diagnosis</a></li>
<li><a class="" href="redesign-1.html"><span class="header-section-number">11</span> Redesign</a></li>
<li><a class="" href="part-ii-exercises.html"><span class="header-section-number">12</span> Part II Exercises</a></li>
<li class="book-part">Design Library</li>
<li><a class="" href="design-library.html"><span class="header-section-number">13</span> Design Library</a></li>
<li><a class="" href="observational-designs-for-descriptive-inference.html"><span class="header-section-number">14</span> Observational designs for descriptive inference</a></li>
<li><a class="" href="experimental-designs-for-descriptive-inference.html"><span class="header-section-number">15</span> Experimental designs for descriptive inference</a></li>
<li><a class="" href="observational-designs-for-causal-inference.html"><span class="header-section-number">16</span> Observational designs for causal inference</a></li>
<li><a class="" href="experimental-designs-for-causal-inference.html"><span class="header-section-number">17</span> Experimental designs for causal inference</a></li>
<li><a class="" href="exercises-6.html"><span class="header-section-number">18</span> Exercises</a></li>
<li><a class="" href="multi-study-designs.html"><span class="header-section-number">19</span> Multi-study designs</a></li>
<li><a class="" href="part-iii-exercises.html"><span class="header-section-number">20</span> Part III Exercises</a></li>
<li class="book-part">Research Design Lifecycle</li>
<li><a class="" href="research-design-lifecycle.html"><span class="header-section-number">21</span> Research Design Lifecycle</a></li>
<li><a class="" href="planning.html"><span class="header-section-number">22</span> Planning</a></li>
<li><a class="" href="ethical-review.html"><span class="header-section-number">23</span> Ethical Review</a></li>
<li><a class="" href="partners.html"><span class="header-section-number">24</span> Partners</a></li>
<li><a class="" href="funding.html"><span class="header-section-number">25</span> Funding</a></li>
<li><a class="" href="piloting.html"><span class="header-section-number">26</span> Piloting</a></li>
<li><a class="" href="implementation.html"><span class="header-section-number">27</span> Implementation</a></li>
<li><a class="" href="populated-preanalysis-plan.html"><span class="header-section-number">28</span> Populated Preanalysis Plan</a></li>
<li><a class="" href="reconciliation.html"><span class="header-section-number">29</span> Reconciliation</a></li>
<li><a class="" href="writing.html"><span class="header-section-number">30</span> Writing</a></li>
<li><a class="" href="publication.html"><span class="header-section-number">31</span> Publication</a></li>
<li><a class="" href="archiving.html"><span class="header-section-number">32</span> Archiving</a></li>
<li><a class="" href="reanalysis.html"><span class="header-section-number">33</span> Reanalysis</a></li>
<li><a class="" href="replication.html"><span class="header-section-number">34</span> Replication</a></li>
<li><a class="" href="resolving-disputes.html"><span class="header-section-number">35</span> Resolving Disputes</a></li>
<li><a class="" href="synthesis.html"><span class="header-section-number">36</span> Synthesis</a></li>
<li><a class="" href="part-iv-exercises.html"><span class="header-section-number">37</span> Part IV Exercises</a></li>
<li class="book-part">Epilogue</li>
<li><a class="" href="epilogue.html"><span class="header-section-number">38</span> Epilogue</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="glossary.html"><span class="header-section-number">39</span> Glossary</a></li>
<li><a class="" href="references-4.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/DeclareDesign/book">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="choosing-an-answer-strategy" class="section level1">
<h1>
<span class="header-section-number">9</span> Choosing an answer strategy<a class="anchor" aria-label="anchor" href="#choosing-an-answer-strategy"><i class="fas fa-link"></i></a>
</h1>
<!-- make sure to rename the section title below -->
<p>Your answer strategy is your plan for what you will do with the information gathered from the world in order to generate an answer to the inquiry. Qualtitative and quantitative methods courses overflow with advice about which answer strategies to choose. Under what conditions should you use Ordinary Least Squares, when should you use logit? When is a machine learning algorithm the appropriate choice and when would a comparative case study be more informative? When is <em>no</em> answer strategy worth persuing because of the fundamental limitations of the data strategy?</p>
<p>Our perspective on answer strategies is that they should be informed by the other three elements of research design: the model, the inquiry, and the data strategy. Sometimes answer strategy advice is offered on the on the basis of the realized data <span class="math inline">\(d\)</span> only, without any particular attention paid to important features of the question to be answered or the manner in which the data were collected and generated. For example, a bit of recieved methodological wisdom holds that whenever a dependent variable is binary, a binary choice statistical model like logit or probit must be used. This advice is based only the knowledge that <span class="math inline">\(d\)</span> contains a binary outcome; whether it is appropriate depends on features of <span class="math inline">\(I\)</span> and features of <span class="math inline">\(D\)</span>. For example, if <span class="math inline">\(I\)</span> is the average treatment effect and <span class="math inline">\(D\)</span> includes randomization of the treatment, answer strategies beyond binary choice models may serve just as well or better. If a student asks, “which estimator should I use?” the response is always, “it depends.” What does it depend on? The model, the inquiry, and the answer strategy.</p>
<p>Choosing “design-aware” answer strategies sounds straightforward enough, but the precise way in which this approach is applied in any real empricial setting will of course differ from case to case. Our highest-level advice is that we want to pick an answer strategy <span class="math inline">\(A\)</span> such that the answer it provides <span class="math inline">\(A(d) = a^d\)</span> is close to the answer under our model of the world, <span class="math inline">\(I(m) = a^m\)</span>. The implication is that we should strive for parallelism across <span class="math inline">\(A\)</span> and <span class="math inline">\(I\)</span> – this is the “plug-in principle.” When the function <span class="math inline">\(A\)</span> is very close to the function <span class="math inline">\(I\)</span>, then we can “plug in” <span class="math inline">\(d\)</span> for <span class="math inline">\(m\)</span>.</p>
<p>Because all answer strategies rely on assumptions. For descriptive inference, we have to assume that the sample represents the population well. For causal inference, we have to assume that treated and untreated units are similar in all other respects beyond treatment status. For all kinds of inference, we have to assume that our measurements are close to the latent construsts we wish to measure. Answer strategies are “model-based” when the most consequential of these assumptions are part of <span class="math inline">\(M\)</span>. Answer strategies are “design-based” to the extent that we can pull the assumptions out of <span class="math inline">\(M\)</span> and assure them by design, i.e., by choosing <span class="math inline">\(D\)</span> in such a way that we can be confident that the assumption is true. Observational causal inference often relies on an assumption of “selection on observables,” or the claim that within groups of units that have the same observed characteristics, treatments are as-if randomly assigned. Observational causal inference is model-based in the sense that the selection on observables assumption is grounded in researchers’ theoretical model of the world, which of course might be wrong. Experimental causal inference is “design-based” in the sense that we can be sure that treatments were <em>actually</em> randomly assigned because random assignment was part of the data. In both observational and experimental settings we need to make the same assumption, but in one case, we rely on a theoretical model and in the other, we rely on a data strategy. To the extent possible, we prefer assuring assumptions by design to asserting them on the basis of a theoretical model.</p>
<p>Answer strategies come in a number of varieties. The most familiar of these are point-estimators that produce estimates of parameters. Ordinary least squares, difference-in-means, logit, random forests, and a very long list of others are in the point-estimator answer strategy class. A second class is comprised by tests. Tests return a binary decision (True or False). Null hypothesis significance tests are a common form of test in quantitative research. Qualitative researchers also employ tests; these go by names like “hoop test” and “straw-in-the-wind” test. Bayesian answer strategies return full posterior distributions. In contrast to point-estimators some answer strategies are interval-estimators.</p>
<div id="using-the-model-to-inform-your-answer-strategy" class="section level2">
<h2>
<span class="header-section-number">9.1</span> Using the Model to inform your Answer strategy<a class="anchor" aria-label="anchor" href="#using-the-model-to-inform-your-answer-strategy"><i class="fas fa-link"></i></a>
</h2>
<p>As we described in chapter 6, we can (non-parametrically) express our model of the world as a directed acyclic graph, or DAG. DAGs express <em>some</em> but not all parts of our model, precisely because they are nonparametric. They don’t encode how variables cause each other, just whether they do. Even so, writing down a theoretical model in as parsimonious a form as a nonparametric structual causal model can guide answer strategies in an enormously powerful way. Given a DAG, we can learn whether <em>any</em> answer strategy would be sufficient for estimating a causal effect. Further, we can learn which variable our answer strategy must condition on, and which must be left alone.</p>
<p>When we want to estimate a particular causal relationship, such as the average causal effect of D on Y, we can read off the DAG whether that relationship is <em>identified</em> or not. The most common (and useful) criterion for identification is the “backdoor criterion.” If there exists an unblocked “backdoor path” from D to Y, then the relationship is not identified.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Footnote here about other criteria.&lt;/p&gt;"><sup>16</sup></a> A backdoor path is a causal path that begins with an arrow in to D and ends with an arrow in to Y. Backdoor paths can be blocked in two ways: conditioning the analysis on a variable along the path or <em>not</em> conditioning on a “collider” along the path.</p>
<p>Pearl (p. 61) defines the backdoor criterion:</p>
<p>Given an ordered pair of variables D, Y in a DAG G, a set of variables X, satifies the backdoor criterion relative to D, Y if no node in X is a descendant of D, and X blocks every path between D and Y that contains an arrow into D. (pg. 61 Pearl primer)</p>
<p>With this definition in hand, we can inspect DAGs to find “adjustment sets.” An adjustment set is a set of variables that are conditioned upon in the answer stratety. “Conditioned upon” is a sufficiently vague phrase to include conditioning procedures such as controlling for a variable in a regression setting or stratifying the analysis according to those varaibles.</p>
<p>In general, if <span class="math inline">\(X\)</span> is an adjustment set that satisfies the backdoor criterion, then we can estimate the conditional probability distributions of <span class="math inline">\(Y\)</span> for each level of <span class="math inline">\(D\)</span> using this expression.</p>
<p><span class="math display">\[\Pr(Y = y \mid do(D=d)) = \sum_x \Pr(Y = y \mid D = d, X = x) \Pr(X = x)\]</span></p>
<p>We can write the same expression using potential outcomes notation:</p>
<p><span class="math display">\[\Pr(Y_i(D_i = 1) = y) = \sum_x \Pr(Y_i(D_i = 1) = y \mid X_i = x) \Pr(X_i = x)\]</span></p>
<p>Figure XXX shows the three DAGs with the same three variables D, X, and Y. In all three cases, our inquiry is the average treatment effect of D on Y, and in all three cases, X, D, and Y are intercorrelated. In the first case, <span class="math inline">\(X\)</span> confounds the causal relationship between D and Y, which is to say if we simply compared units with different levels of D, our estimates of the causal effect would be prone to bias. However, if we conduct the analysis separately <em>within</em> levels of X (that is to say, we condition on X), then combine the separate analysis, our overall estimate will be unbiased. This first DAG is the setting that analysts have in mind when controlling for observables in order to estimate causal effects.</p>
<p>A dangerous possibiliy, however, is represented by the second DAG. In this causal graph, X doesn’t confound the relationship between D and Y – instead, it is a downstream consequence of both variables. If an analyst mistakenly conditions on X, a noncausal confounding path opens up between D and Y, biasing estimates of average effect on D on Y. The contrast between the first and second graphs is an illustration of the general principle that our theoretical models guide analytic choices. In the first case, our estimates are unbiased if and only if we <em>do</em> control for <span class="math inline">\(X\)</span>, in the second case only if we <em>do not</em> control for X.</p>
<p>The third case describes a setting in which D has both a direct effect on Y and an indirect effect that travels through X – in this case, X is a mediator. If we condition on X, our estimate of the effect D on Y is biased (X is a descendant of D). Like in the collider case, the effect is identified if we <em>do not</em> control for X, but is not identified if we <em>do</em> condition. Some intuition for the problems associated with controlling for mediations: controlling for X “controls away” some portion of the effect.</p>
<p>This example illustrates in a small way how your model of the world guides your answer strategy. In all three cases, we could in principle have the same dataset of D, X, and Y. If we followed some common regression advice, we would control for X because it is correlated with both D and Y – this approach works only if X is a confounder. If X is a collider or a mediator, then this control strategy would induce bias. Without further changes to the design, no empirical tests can distinguish between these three DAGs, so in a very real way, theoretical assumptions in the Model must be relied upon to correctly choose a control strategy.</p>
<div class="inline-figure"><img src="book_files/figure-html/unnamed-chunk-126-1.png" width="100%"></div>
<p>Definition: The frontdoor criterion. A set of variables X is said to satisfy the frontdoor criterion relative to an ordered pair of variables D, Y if X intercepts all directed paths from D to Y, there is no unblocked path from D to X, all backdoor paths from X to Y are blocked by D. (pg. 69 Pearl primer)</p>
<p><span class="math display">\[\Pr(Y = y \mid do(D = d)) = \sum_x \Pr(X = x \mid D = d) \sum_{d^{\prime}} \Pr(Y = y \mid D = d^{\prime}, X = x) \Pr(D = d^{\prime})\]</span></p>
<div id="descriptive-analysis" class="section level3">
<h3>
<span class="header-section-number">9.1.1</span> Descriptive analysis<a class="anchor" aria-label="anchor" href="#descriptive-analysis"><i class="fas fa-link"></i></a>
</h3>
<p>Answering descriptive inquiries involves studying the existence of nodes and the values they take on. We might study whether a behavior exists in the world, and measure its frequency. We might also study how the frequency of the behavior varies over time and across people. Our answer strategy, following the plug-in principle, will often involve the average value of the node in the sample as an estimator of the average value in the population.</p>
</div>
<div id="causal-analysis" class="section level3">
<h3>
<span class="header-section-number">9.1.2</span> Causal analysis<a class="anchor" aria-label="anchor" href="#causal-analysis"><i class="fas fa-link"></i></a>
</h3>
<p>By contrast, when we target a causal inquiry with our answer strategy, we are interested in the existence (or non-existence) of an edge between two nodes. We can label the two <span class="math inline">\(D\)</span> (treatment) and <span class="math inline">\(Y\)</span> (outcome).</p>
<p>We can only learn the answer to the inquiry when we can identify the causal effect, meaning if we had infinite data we could estimate without bias the causal effect. Identification can be obtained if the backdoor criterion is met, if the frontdoor criterion is met, or if there are no other causal relationships into both <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>. These conditions will be violated in several circumstances, including when an observed confounder <span class="math inline">\(X\)</span> confounds the relationship between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span> and is left unadjusted or when there is an unobserved confounder <span class="math inline">\(U\)</span>.</p>
<p>To reason about causal identification, we turn back to DAGs. We start with a simple DAG with four variables: a treatment <span class="math inline">\(D\)</span>, an outcome <span class="math inline">\(Y\)</span>, a observed variable <span class="math inline">\(X\)</span> (which may or may not confound the relationship between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>), and an unobserved variable <span class="math inline">\(U\)</span>. There are six edges between these variables, each with three possible relations: each variable may cause (e.g., <span class="math inline">\(D \rightarrow Y\)</span>), be caused by (e.g., <span class="math inline">\(D \leftarrow Y\)</span>), or not be causally related to every other variable. With three possible relationships and six edges, there are <span class="math inline">\(3^6 = 729\)</span> conceptually possible DAGs. We rule out DAGs in which other variables cause <span class="math inline">\(U\)</span>, because we defined <span class="math inline">\(U\)</span> as an unobserved confounder. This leaves 216 possible combinations.</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># four variable dag with undirected edges between all sides</span></code></pre></div>
<p>In the presence of possible confounding from <span class="math inline">\(X\)</span> and/or <span class="math inline">\(U\)</span>, we have several options for our research design: we can estimate the causal effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> by controlling for the observed confounder <span class="math inline">\(X\)</span> (or not), by invoking additional conditional independence assumptions, and by randomizing the treatment. In each case, our aim is to rule out DAGs in which the causal effect is not identified.</p>
<div id="causal-identification-through-controls" class="section level4">
<h4>
<span class="header-section-number">9.1.2.1</span> Causal identification through controls<a class="anchor" aria-label="anchor" href="#causal-identification-through-controls"><i class="fas fa-link"></i></a>
</h4>
<p>The first strategy is that we can control for the observed variable <span class="math inline">\(X\)</span> or not. Whether controlling for <span class="math inline">\(X\)</span> enables, prevents, or does not affect the causal identification of the effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> depends on our beliefs about which DAG is the true DAG.</p>
<p>We illustrate possible beliefs about these edges by visualizing all of the 216 DAGs in which <span class="math inline">\(U\)</span> is an unobserved confounder (see Figure XX). The large groups of three squares of nine group DAGs based on how <span class="math inline">\(U\)</span> affects other variables in the model: the top left grouping of 27 DAGs represents those in which <span class="math inline">\(U\)</span> affects all of <span class="math inline">\(D\)</span>, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Within that grouping, there are three squares of nine squares. Each group of nine squares represents a set of DAGs with a single relationship between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>. The top left group of nine are those DAGs in which <span class="math inline">\(D\rightarrow Y\)</span>.</p>
<p>We can rule out several of these 216 through acyclicity: the gray squares are graphs that are cyclical. (We operate under the view that cyclicity is not possible in the world, which would imply that these variables simulataneously cause each other.)</p>
<p>We color the rest of the squares in terms of whether controlling for <span class="math inline">\(X\)</span> will identify the causal effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span>.</p>
<p>In some cases, the effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> will be identified regardless of whether we control for <span class="math inline">\(X\)</span> (white squares). For example, in the left DAG, <span class="math inline">\(X\)</span> affects <span class="math inline">\(D\)</span> and <span class="math inline">\(U\)</span> affects <span class="math inline">\(Y\)</span> but neither affect both. The causal effect is identified because there is no path between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span> except for the direct effect <span class="math inline">\(D\rightarrow Y\)</span>. In other words, neither <span class="math inline">\(X\)</span> nor <span class="math inline">\(U\)</span> confound the relationship, and the potential outcomes of <span class="math inline">\(Y\)</span> are independent of <span class="math inline">\(D\)</span>.</p>
<p>In other cases, the effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> is identified if and only if we control for <span class="math inline">\(X\)</span> (blue squares). These are situations in which <span class="math inline">\(X\)</span> confounds the relationship and there is no additional confounding from unmeasured confounders. These are cases in which the potential outcomes of <span class="math inline">\(Y\)</span> are independent of <span class="math inline">\(D\)</span> <em>conditional</em> on <span class="math inline">\(X\)</span>.</p>
<p>However, conditioning on <span class="math inline">\(X\)</span> is risky, because if we are not in one of the blue DAGs we might be in the purple DAGs in which the effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> is identified only if we do <em>not</em> condition on <span class="math inline">\(X\)</span> (purple squares). These are DAGs in which <span class="math inline">\(X\)</span> is a collider, opening a backdoor path between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span> aside from the direct effect when <span class="math inline">\(X\)</span> is conditioned on. If we knew we were in one of these DAGs, we would not control for <span class="math inline">\(X\)</span>.</p>
<p>There are also many situations — a majority in fact, the pink squares — in which the relationship between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span> is <em>never</em> identified, regardless of whether you control for <span class="math inline">\(X\)</span>. Most of these result from confounding from unobservable confounders <span class="math inline">\(U\)</span>. The upper left quadrant contains the cases where <span class="math inline">\(U\)</span> affects all of the other variables, and the middle left those where <span class="math inline">\(U\)</span> affects <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>. In both cases, identification would require at a minimum the ability to control for these unmeasured confounders. The other situations in which causal identification fails are those in which the causal order between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span> is reversed, i.e. <span class="math inline">\(Y\)</span> causes <span class="math inline">\(D\)</span>. Without additional assumptions or control of the order in which variables are collected from the data strategy, we cannot rule out this possibility, the first and fourth columns of subgraphs labeled <span class="math inline">\(D\leftarrow Y\)</span>.</p>
<p>Without additional assumptions or manipulation in our data strategy, we cannot know where we are among the 200 acyclic DAGs represented in the plot. As a result, we are in danger either of having the effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> unidentified regardless of what we do, or of making the wrong choice to control or not to control.</p>
<div class="inline-figure"><img src="book_files/figure-html/fig-dags-adjustment-1.png" width="100%"></div>
</div>
<div id="causal-identification-by-assumption" class="section level4">
<h4>
<span class="header-section-number">9.1.2.2</span> Causal identification by assumption<a class="anchor" aria-label="anchor" href="#causal-identification-by-assumption"><i class="fas fa-link"></i></a>
</h4>
<p>We can address the problem of unmeasured confounding by invoking conditional independence assumptions. The ``selection-on-observables’’ answer strategy invokes the assumption that <span class="math inline">\(D\)</span> is statistically independent of the potential outcomes of <span class="math inline">\(Y\)</span> <em>given</em> X, i.e. after adjusting for <span class="math inline">\(X\)</span>. In other words, controlling for <span class="math inline">\(X\)</span> blocks all backdoor paths between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>. This assumption is also known as a conditional independence or ignorability assumption.</p>
<p>In Figure XX, we display the 216 possible causal graphs again, ruling out in gray those that are cyclical. Among the 200 that remain, we color in the same way as under controlling for <span class="math inline">\(X\)</span> but add a fourth color: lavender for DAGs that we rule out based on our conditional independence assumption. Those that are ruled out, in the upper left quadrants, have unobserved confounding from <span class="math inline">\(U\)</span> that cannot be addressed by adjusting for <span class="math inline">\(X\)</span>.</p>
<p>Analysts who invoke this conditional independence assumption assure that there are many fewer circumstances in which identification is not possible either through controlling for <span class="math inline">\(X\)</span> or not controlling for <span class="math inline">\(X\)</span>. However, this is a strong assumption that is not possible to test directly. Instead, the analyst must justify the assumption based on circumstantial qualitative or quantitative evidence. The task is to rule out through this evidence either a relationship between <span class="math inline">\(U\)</span> and <span class="math inline">\(D\)</span> or a relationship between <span class="math inline">\(U\)</span> and <span class="math inline">\(Y\)</span> or both. In the first case, this evidence might take the form of background knowledge about how values of <span class="math inline">\(D\)</span> are determined. The treatment might be assigned using a cut-off rule, in which case all those above the cut-off are assigned to treatment (e.g., are admitted to a college) and those below are not. In this case, there is no relationship between unobserved variables <span class="math inline">\(U\)</span> and treatment <span class="math inline">\(D\)</span>, there is only a relationship between <span class="math inline">\(X\)</span> (score) and <span class="math inline">\(D\)</span>. Controlling for <span class="math inline">\(X\)</span> will enable causal identification even if <span class="math inline">\(Y\)</span> is affected by <span class="math inline">\(U\)</span>. However, the assumption of conditional independence between <span class="math inline">\(U\)</span> and <span class="math inline">\(D\)</span> given <span class="math inline">\(X\)</span> is a strong assumption: the analyst must be sure that there is no unobserved variable <span class="math inline">\(U\)</span> that directly affects <span class="math inline">\(D\)</span>, such as legacy applicants who may be “pushed” over the threshold of the cut-off if they are close enough to it.</p>
<p>Under selection-on-observables, there are still many DAGs that raise problems for us. There are still many DAGs in which <span class="math inline">\(D\leftarrow Y\)</span>, <span class="math inline">\(D\)</span> is caused by <span class="math inline">\(Y\)</span> instead of the other way around. If we cannot rule those out by assumption, we will never identify the causal effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> regardless of whether we control for <span class="math inline">\(X\)</span>. The DAGs in blue (the effect is identified only when we condition on <span class="math inline">\(X\)</span> and not otherwise) and purple (the opposite, that we only achieve identification when we do not condition on <span class="math inline">\(X\)</span>) still remain. Those in blue involve <span class="math inline">\(X\)</span> confounding the relationship between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span> and those in purple are when <span class="math inline">\(X\)</span> is a collider so conditioning on it opens up a backdoor path to <span class="math inline">\(U\)</span>. In other words, the conditional independence of <span class="math inline">\(D\)</span> and <span class="math inline">\(U\)</span> given <span class="math inline">\(X\)</span> is insufficient to identify the effect, without ruling out these other scenarios.</p>
<div class="inline-figure"><img src="book_files/figure-html/unnamed-chunk-128-1.png" width="100%"></div>
</div>
<div id="causal-identification-through-random-assignment" class="section level4">
<h4>
<span class="header-section-number">9.1.2.3</span> Causal identification through random assignment<a class="anchor" aria-label="anchor" href="#causal-identification-through-random-assignment"><i class="fas fa-link"></i></a>
</h4>
<p>When we are unable to rule out confounding by assumption and adjustment, we can randomly assign <span class="math inline">\(D\)</span> to sever connections between unobserved variables <span class="math inline">\(U\)</span> and <span class="math inline">\(D\)</span> by design. Ruling out confounders by assumption or adjustment requires the <em>model</em> to be correct, so is often known as model-based inference, whereas ruling out confounders by design is labeled design-based inference.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;In truth, there is a continuum between the two. Design-based inferences that rely on non-parametric estimators of the average treatment effect using data from a randomized experiment are a classic design-based estimator, yet they also rely on a modeling assumption: the stable unit treatment-value assumption.&lt;/p&gt;"><sup>17</sup></a> In addition, we can measure <span class="math inline">\(X\)</span> before treatment to rule out situations in which <span class="math inline">\(D\)</span> causes <span class="math inline">\(X\)</span>, which can lead to collider bias or opening backdoor paths from <span class="math inline">\(D\)</span> to <span class="math inline">\(Y\)</span>.</p>
<p>In doing so, we dramatically reduce the set of possible DAGs, because we set the causal order between <span class="math inline">\(X\)</span> and <span class="math inline">\(D\)</span>, and dramatically expand the number of settings under which the effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> is identified both due to this restriction on causal order and the randomization of <span class="math inline">\(D\)</span> which guarantees ignorability of <span class="math inline">\(U\)</span>.</p>
<p>In Figure XX, we swap the colors to now indicate DAGs ruled out by measuring <span class="math inline">\(X\)</span> before treatment (salmon squares), and those ruled out by random assignment (blue squares). In all of the remaining white squares, the effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> is causally identified, regardless of whether we adjust for <span class="math inline">\(X\)</span> or not. We remove the conditionality of inference depending on whether we control. This is good, because ultimately even in the presence of strong ignorability assumptions outlined in the last section there are many possible DAGs in which controlling or failing to control lead to bias. Now, our inferences do not depend on guessing the correct DAG.</p>
<div class="inline-figure"><img src="book_files/figure-html/unnamed-chunk-129-1.png" width="100%"></div>
<p>In short, what we do by controlling the timing of measurement of <span class="math inline">\(X\)</span> and randomizing <span class="math inline">\(D\)</span> is to move our assumptions about conditional independence from <span class="math inline">\(M\)</span> our assumed (but possible incorrect!) model of the world into our data strategy, which we control and so can guarantee by design.</p>
<p>However, in order to benefit from these two controlled decisions in our data strategy, we must follow the dictum due to R.A. Fisher to “analyze as you randomize.” Your answer strategy should follow your data strategy. There are four components: make comparisons only across randomly-assigned conditions; analyze data at the level of random assignment; make comparisons only in groups within which random assignment was conducted (e.g., strata); and adjust for differences in probabilities of random assignment.</p>
<p>Making comparisons across randomly-assigned conditions within groups in which random assignment was conducted directly follow from our comparison of causal identification by assignment vs. by design. If we make comparisons that rely on differences both in <span class="math inline">\(D\)</span> and <span class="math inline">\(X\)</span>, for example a difference in treatment effects between two subgroups, we are susceptible to confounding from <span class="math inline">\(U\)</span>, because <span class="math inline">\(X\)</span> is not randomly-assigned. Similarly, analysis of data from block-randomized experiments can be broken by failing to account for blocking, because blocks are not randomly assigned and in fact are typically constructed so that the outcomes of units in the block are similar within blocks and very different across blocks. If there are differential probabilities of assignment across blocks and we pool our data ignoring the blocking structure, our unweighted comparisons may be contrasting groups that differ systematically.</p>
</div>
</div>
<div id="how-weights-help" class="section level3">
<h3>
<span class="header-section-number">9.1.3</span> How weights help<a class="anchor" aria-label="anchor" href="#how-weights-help"><i class="fas fa-link"></i></a>
</h3>
<p>One of the best ways to analyze as you randomize is by weighting data to reflect the sampling and assignment probabilities generated by your data strategy.</p>
<p>Remember that, in random sampling, the sampling probability quantifies each person’s likelihood of being in the sample. By taking the inverse of this probability, we can generate weights that allow us to make a really skewed sample representative of the target population. This basic insight can be extended from random sampling to many other contexts. It applies to random treatment assignment, where we use inverse probability weighting to make unbiased inferences in the presence of spillovers and heterogeneous assignment probabilities. It even extends to the use of poststratification in nonrandom sampling and inverse propensity weighting for unbiased causal inference in the presence of confounding. For this reason, understanding the connection between sampling probabilities and inverse probability weights is one of the most important concepts in descriptive and causal inference. However, where these weights come from and what they mean can often seem confusing. In fact, the basic intuition is very simple and the random sampling analogy extends directly to these other contexts.</p>
<p>When we sample, we select a subset of units to stand in for the unselected units. That’s what we mean when we say the sample is “representative”—the units in it literally represent the units that are not in it (but could have been). We can even quantify the exact number of units in the population that each unit in the sample represents. If I sample <span class="math inline">\(n = 10\)</span> people from a group of <span class="math inline">\(N = 1000\)</span> people, then when I make an inference about the larger group from the smaller group, each of the 10 people in the sample is standing in for <span class="math inline">\(N/n = 100\)</span> people in the population. If I sample all people, then each person just represents one person, themselves: <span class="math inline">\(N/n = 1\)</span>. Let’s call <span class="math inline">\(w\)</span> the number of people in the population each person in the sample represents: <span class="math inline">\(w = N / n\)</span>. And let’s call <span class="math inline">\(p\)</span> the probability of being in the sample: <span class="math inline">\(p = n / N\)</span>. Notice that <span class="math inline">\(p\)</span> and <span class="math inline">\(w\)</span> are the reciprocal of one another. Since the number 1 divided by a fraction gives its reciprocal, we can use the inverse of <span class="math inline">\(p\)</span> to find <span class="math inline">\(w\)</span>: <span class="math inline">\(\frac{1}{p} = \frac{1}{1} \times \frac{N}{n} = w\)</span>. Now you know what an inverse probability weight is: it is a count of the number of people in the population that a given unit in the sample represents.</p>
<p>Now suppose you have two samples, each of size <span class="math inline">\(n_1 = n_2 = 10\)</span>. The first sample is drawn from a population of 10 people, each of whom has <span class="math inline">\(X = 1\)</span>. The second sample is drawn from a population of 20 people, each of whom has <span class="math inline">\(X = 0\)</span>. We want to know the true mean of <span class="math inline">\(X\)</span> across both populations: <span class="math inline">\(\bar{X} = \frac{10 + 0}{10 + 20} = \frac{1}{3}\)</span>. If we pool the data and take the average of <span class="math inline">\(X\)</span>, we get the wrong answer: <span class="math inline">\(\hat{\bar{X}} = \frac{1}{2}\)</span>. We get the wrong answer because people from the first group are overrepresented: while <span class="math inline">\(1/2\)</span> of the sample is from group 1, only <span class="math inline">\(1/3\)</span> of the combined population is from group 1. In terms of sampling probabilities and weights, every person in the first sample only represents one person: <span class="math inline">\(\frac{1}{p_1} = \frac{1}{1} \frac{N_1}{n_1} = \frac{1}{1} \frac{1}{1} = 1 = w_1\)</span>, whereas every person in the second sample stands in for two people, <span class="math inline">\(\frac{1}{p_2} = \frac{1}{1} \frac{20}{10} = 2 = w_2\)</span>. By weighting our sample estimate of the average by the number of people each person in the pooled sample represents, we recover the right answer:</p>
<p><span class="math display">\[\hat{\bar{X}}_{IPW} = \frac{\sum X_i w_i}{\sum w_i} = \frac{n_1 \times 1 \times w_1 + n_2 \times 0 \times w_2}{n_1 \times w_1 + n_2 \times w_2} = \frac{10 \times 1\times 1 + 10 \times 0 \times 2}{10 \times 1 + 10 \times 2} = \frac{1}{3} = \bar{X}.\]</span></p>
<p>Notice that this example is equivalent to a stratified random sampling strategy, in which units from group 1 are sampled with <span class="math inline">\(p_1 = 1\)</span> and units from group 2 are sampled with probability <span class="math inline">\(p_2 = 1/2\)</span>. Any time we use stratified random sampling and the probabilities vary among strata, we should weight estimates so that each observation’s contribution is equivalent to the number of units it represents, which corrects for any over- and underrepresentation introduced by the sampling procedure.</p>
<p>This way of thinking provides a framework for poststratification on nonrandom samples. Suppose a researcher comes across our dataset of 20 people. They don’t know anything about the sampling strategy—to them, it’s a non-random sample. However, they do know that there are 10 people from group 1 and 20 people from group 2 in the population, so they are able to construct estimates of the sampling probabilities using <span class="math inline">\(\hat{p_1} = n_1/N_1\)</span> and <span class="math inline">\(\hat{p_2} = n_2/N_2\)</span>. From there, they can construct weights using <span class="math inline">\(1/p_1\)</span> and <span class="math inline">\(1/p_2\)</span> that will reweight their data so that it is representative. That’s the basic intuition behind stratification: you use known population counts to reverse engineer the probability weights that a hypothetical stratified random sampling strategy would have given you. See entry X in the design library for more on this.</p>
<p>The analogy extends even further when we consider that all random treatment assignment procedures are also sampling procedures. Rather than sampling entire units, however, treatment assignments randomly sample from different potential outcomes. If you assign 5/15 people to treatment and the rest to control, for example, then the five treated potential outcomes need to “represent” <span class="math inline">\(1/(5/15) = 3\)</span> people’s treated potential outcomes and the ten people assigned to control represent <span class="math inline">\(1/(10/15) = 1.5\)</span> people’s control potential outcomes. If you tried to pool different experiments to get the average treatment effect across all people in all experiments, you would need to take account of the fact that different experiments might over or underrepresent treatment or control potential outcomes, and weight accordingly. This issue arises in block randomized designs where treatment assignment probabilities vary by block (see entry X in the design library), in designs with spillovers where spatial networks induce differential assignment probabilities for spillovers (see entry X in the design library), and in stepped wedge designs where earlier waves overrepresent control potential outcomes and later waves overrepresent treatment potential outcomes (see entry X in the design library). Finally, in the same way that poststratification uses covariates to construct sample weights corresponding to a hypothetical random  procedure, matching and selection observable designs use covariates to reverse engineer probabilities of sampling treatment and control potential outcomes in order to reweight the data to account for the systematic selection of certain kinds of units into or out of treatment (confounding).</p>
<div id="effect-estimation-and-distinguishing-among-dags" class="section level4">
<h4>
<span class="header-section-number">9.1.3.1</span> Effect estimation and distinguishing among DAGs<a class="anchor" aria-label="anchor" href="#effect-estimation-and-distinguishing-among-dags"><i class="fas fa-link"></i></a>
</h4>
<p>The identification of the causal effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span> either by assumption or design enables us to undertake two tasks: estimate the average treatment effect, estimate the sign of the effect, or estimate whether there is an affect or not.</p>
<p>The first task, estimating the magnitude of the effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span>, can be accomplished using model-based inference under the selection-on-observables design or under a randomized experiment. In both cases, we apply the plug-in principle, replacing the true but unknown average potential outcomes under treatment (control) with the sample analogues, the average outcomes in the treatment (control) group. With data from randomized experiments, <span class="math inline">\(X\)</span> is ignorable, so we can either adjust for it (which may reduce variability in estimates) or not without bias. But under selection-on-observables, we have to rule out many DAGs by assumption that include <span class="math inline">\(X\)</span> as a collider or in which <span class="math inline">\(X\)</span> opens a backdoor path between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span> in order to safely select an answer strategy.</p>
<p>For estimating the sign of the effect, we can calculate the sign of the effect magnitude, and then conduct a statistical test of the null hypothesis of zero effect to distinguish among zero, positive, and negative effects.</p>
<p>The third task, determining whether there is an effect or not, similarly involves a statistical test of the null hypothesis of zero effect. If we fail to reject the null, then our posterior belief is that there is no effect, but if we reject in a two-sided test then we leave believing there is an effect. This zero average effect null hypothesis test can help us take the final step in distinguishing among the 216 possible DAGs representing the relationships between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span> and the confounders <span class="math inline">\(X\)</span> and <span class="math inline">\(U\)</span>. In Figure XX, we display the 16 DAGs that are identified under random assignment and pretreatment measurement of <span class="math inline">\(X\)</span>. We need to use data and the two-sided null hypothesis test to distinguish between the top row (there is an effect <span class="math inline">\(D\rightarrow Y\)</span>) and the bottom row (there is no effect). Our design got us most of the way there, but then we need to use the data to narrow further to one of the two rows of eight DAGs. Since our inquiry is about the causal relationship between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>, we may not be concerned about distinguishing among the eight. If we are, we need to develop an alternative research design, to learn about the causal effects of <span class="math inline">\(X\)</span>.</p>
<div class="inline-figure"><img src="book_files/figure-html/unnamed-chunk-130-1.png" width="100%"></div>
</div>
</div>
</div>
<div id="point-estimation" class="section level2">
<h2>
<span class="header-section-number">9.2</span> Point estimation<a class="anchor" aria-label="anchor" href="#point-estimation"><i class="fas fa-link"></i></a>
</h2>
<p>Point estimation is possibly the most common class of answer strategy in quantitative social science. Point estimators are things like the difference-in-means, ordinary least squares regression, instrumental variables regression, random forests, the LASSO, ridge regression, BART… the list goes on and on. These are the data analysis tools taught in many graduate methods courses. What’s incredible is that even though the population of estimators proliferates with each passing year, the number of kinds of inquiries they are useful for estimating stays relatively flat. When we do point estimatation, we are mainly interested in estimating averages, differences, variances, and conditional expectation functions of increasing dimensionality. There are of course many other kinds of estimands (like ratios and quantiles), but the main point is, most of the variation in how scholars conduct point estimation is in the answer strategy, not in the inquiry.</p>
<div id="bias-variance-tradeoff" class="section level3">
<h3>
<span class="header-section-number">9.2.1</span> Bias variance tradeoff<a class="anchor" aria-label="anchor" href="#bias-variance-tradeoff"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>overfitting</li>
<li>add modeling assumptions that might decrease variance a lot at the cost of a little bias.</li>
<li>interacts with testing: could win on RMSE, but have a higher false positive rate.</li>
</ul>
<p>(point people to Hastie and Tibshirani)</p>
</div>
</div>
<div id="when-parameters-are-not-point-identified" class="section level2">
<h2>
<span class="header-section-number">9.3</span> When parameters are not point identified<a class="anchor" aria-label="anchor" href="#when-parameters-are-not-point-identified"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>confounding</li>
<li>EV bounds</li>
<li>trimming bounds</li>
</ul>
</div>
<div id="characterizing-uncertainty" class="section level2">
<h2>
<span class="header-section-number">9.4</span> Characterizing uncertainty<a class="anchor" aria-label="anchor" href="#characterizing-uncertainty"><i class="fas fa-link"></i></a>
</h2>
<p>Variance estimation is often more difficult than point estimation.</p>
<p>We can often do the bootstrap, which plugs in (re-) sampling from the sample for sampling from the population.</p>
<!-- (s.e., CIs, posterior probs) -->
</div>
<div id="qualitative-methods-of-inference" class="section level2">
<h2>
<span class="header-section-number">9.5</span> Qualitative methods of inference<a class="anchor" aria-label="anchor" href="#qualitative-methods-of-inference"><i class="fas fa-link"></i></a>
</h2>
<!-- DIscuss process-tracing, QCA, and deterministic / probabilistic case comparison. Summarize Sekhon on Geddes + Skocpol. Ragin. Lijphart on problems with case comparison. Elman on explanatory typologies. -->
<!-- Skocpol clearly believes she is relying on Mill’s methods. -->
<!-- She states that “[c]omparative historical analysis has a long -->
<!-- and distinguished pedigree in social science” and that “[i]ts -->
<!-- logic was explicitly laid out by John Stuart Mill in his A System -->
<!-- of Logic.”9 Further, she asserts that she is using both the Method -->
<!-- of Agreement and the more powerful Method of Difference.10 -->
<!-- For these methods to lead to valid inferences, though, there -->
<!-- must be only one possible cause of the effect of interest, the -->
<!-- relationship between cause and effect must be deterministic, -->
<!-- and there must be no measurement error. If these assumptions -->
<!-- are to be relaxed, random factors must be accounted for. And -->
<!-- because of these random factors, statistical and probabilistic -->
<!-- methods of inference are necessary. -->
</div>
<div id="tests" class="section level2">
<h2>
<span class="header-section-number">9.6</span> Tests<a class="anchor" aria-label="anchor" href="#tests"><i class="fas fa-link"></i></a>
</h2>
<p>Tests are an elemental kind of answer strategy. Tests yield binary yes/no answers to an inquiry. In some qualitative traditions, hoop tests, straw-in-the-wind tests, smoking-gun tests, and doubly-decisive tests are common. These tests are procedures for making analysis decisions in a structured way. In frequentist statistics, significance tests are used to make a decision whether to reject or fail to reject a particular null hypothesis.</p>
<!-- Null hypothesis significance testing has developed a (rightfully) sketchy reputation in recent years as too much weight has been put on the reject / fail to reject decision. That said, sometimes that decision is rightfully important and in such cases, null hypothesis significance testing is a great tool. -->
<!-- - significance testing (incl. sign test) -->
<!-- - equivalence testing -->
<!-- - straw in the wind / hoop test -->
<!-- - doubly decisive -->
<!-- - 1997 book on tests -->
<!-- [cite erin and naoki on sign tests] -->
<!-- [cite erin on equivalence testinf] -->
<div id="randomization-inference" class="section level3">
<h3>
<span class="header-section-number">9.6.1</span> randomization inference<a class="anchor" aria-label="anchor" href="#randomization-inference"><i class="fas fa-link"></i></a>
</h3>
</div>
</div>
<div id="answer-strategies-as-procedures" class="section level2">
<h2>
<span class="header-section-number">9.7</span> Answer strategies as procedures<a class="anchor" aria-label="anchor" href="#answer-strategies-as-procedures"><i class="fas fa-link"></i></a>
</h2>
<p>Consider a randomized experiment that seeks to estimate the causal effect of a treatment. The answer strategy is not just “Logistic Regression with Covariate adjustment”. It includes every step in the process that takes the raw data, cleans and recodes it, considers 5 alternative estimators (DIM, OLS with covariate adjustment, a fancy thing your colleague suggested but you couldn’t get to converge), before finally settling on logit.</p>
<p><strong>Multiple estimates.</strong> Answer strategies can account how many statistical tests you are conducting. Often, when generating an answer to a single inquiry, we may construct multiple estimates that provide different types of answers of varying quality. When you present the results from many null hypothesis tests, the rate of falsely rejecting at least one of those tests even when all are true goes up, due to the multiple comparisons problem. If you plan to adjust for this problem, those adjustments are part of your answer strategy, because they will typically adjust the p-values you report and the decisions readers make with them. We may have three survey items that imperfectly estimate a latent quantity. In presenting the results, we could present three estimates from three regressions, we could adjust the three estimates using a procedure such as a family-wise error rate correction, or we could average the three items together into an index and present one estimate from one regression. Which of these three methods we select will change the properties of our answer strategy.</p>
<p><strong>Analysis procedures</strong>. The final estimator that goes into a paper is neither the beginning nor the end of the answer strategy. Procedures, if any, by which you explore the data and determine a final set of estimates are part of the answer strategy. Procedures for summarizing multiple estimates are one example of many.</p>
<p>Commonly, the final estimator that is selected depended on a exploratory procedure in which multiple models are assessed, for example by comparing model fit statistics. The answer strategy of our research design is not to fit the final model — is it this multiple step if-then procedure. These procedures may be part of a prespecified analysis plan or they may be informal, so it may sometimes only be possible to declare the full design after the data is obtained. (We may find that a different analysis procedure that was not data dependent would have been preferable, if we diagnose the design after the fact.) The reason to declare the procedure rather than the final estimator is that the diagnosis of the design may differ. The procedure may be more powerful, if for example we assessed multiple sets of covariate controls and selecting the specification with the lowest standard error of the estimate. But the procedure may also exhibit poor coverage, accounting for these multiple bites at the apple.</p>
<p>We also sometimes find that the model we planned to run to analyze the data cannot be estimated. In these cases, there is an iterative estimation procedure in which a first model is run, changes to the specification are made, and a second or third model is presented as the result. The full set of steps — a decision tree, depending on what is estimable — is the answer strategy and we can evaluate whether it is a good one not only under the realized data but under other possible realizations where the decision <em>tree</em> would be the same but the decisions different.</p>
<p>In fact, there are examples of analysis procedures in most types of research, quantitative or qualitative. Many strategies for causal inference with observational data involve not only an estimation strategy but a set of falsification or placebo tests. The answer provided by these research designs depends in a crucial way on the results of these tests: if the tests fail, the design provides no definitive answer. In qualitative research, process tracing involves a set of steps, the results of which depend on information gathered in earlier steps. Many mixed methods strategies are also multi-step procedures. Nested designs involve running a quantitative analysis and then selecting cases on the basis of predictions from the regression. These designs cannot be assessed by considering a single step of the procedure in isolation.
<!-- need cites --></p>
<p><strong>When things do not go according to plan.</strong> To compare answer strategies, you can imagine the estimators that are possible <em>if things go well</em> as well as <em>if things go wrong</em>, when there is missing data or there are outliers in variables. A good answer strategy, which might be a single estimator, or a procedure if-this-then-that, can handle both states of the world. Procedures for addressing deviations from expected analyses are part of the answer strategy. Even in the absence of a preanalysis plan, we often have a way we expect to analyze the data if things go well. When they do not — because data are missing, there is noncompliance with an intervention, or the study is suspended for example — the answers will change. These procedures determine the answer the study provides (or in some cases does not), so are part of the answer strategy. <em>Standard operating procedures</em> (lin and green) are documents that systematize these procedures in advance.</p>
<p>We demonstrate the fact that the properties of procedures differ from the properties of a design with the final estimator in a simple example. We compare two possible estimation specifications, with and without covariates, to a procedure in which we run both models and report the model in our paper that has the lower p-value. The models are exactly the same, but the properties of the <em>procedure</em> differ from the properties of either of the two possible models. In particular, the procedure has higher power than either of the two models, but it exhibits poor coverage, which means we have a bias in our measure of uncertainty.</p>
</div>
<div id="robustness" class="section level2">
<h2>
<span class="header-section-number">9.8</span> Robustness<a class="anchor" aria-label="anchor" href="#robustness"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Robustness checks</strong> are part of the answer strategy. Often, a single estimator is presented as the main analysis but then a series of alternative specifications are displayed in an appendix (such as including or excluding covariates and their interactions, different subsets of the data, or alternative statistical models). These differ from multiple estimates of a latent quantity in that the goal is not a primary analysis, but rather to support the main analysis. The purpose is to provide readers with evidence about how dependent the main results are on the specification, data subset, and statistical model used. The decision a reader makes from a paper depends not only on the main estimate but also the robustness checks. As a result, we want to assess the properties of the two together.</p>
<p>We illustrate with a simple analysis of the correlation between two variables <code>y1</code> and <code>y2</code>, who have a true positive correlation. <code>y2</code> is also a function of an observed covariate <code>x</code> and measurement error. Our main analysis is a bivariate regression predicting <code>y2</code> with <code>y1</code>. We compare this answer strategy to one in which we run that analysis, but also run a robustness check controlling for <code>x</code>. We do this because as the analyst we are unsure of the true DGP and wish to demonstrate to reviewer’s that our results are not dependent on the functional form we choose.</p>
<!-- - distinguish this from changes to the model where we do robustnesss vis a vis a fixed answer and data strategy. i.e. two notions of "robustness". one is fix I D A and change M, is this "design" robust to changes in M. the other is, within a given run, is the estimate "robust" to changing the estimation procedure, so this is a diagnostic statistic. note I must be defined across these changes in M. -->
<p>Using the MIDA way of thinking about designs, we discuss in the diagnosis section another notion of the “robustness” of a design. The typical way we think of robustness checks is multiple secondary analyses <em>conditional on the observed data</em> to build confidence in an analysis of that fixed data. However, the motivation for these robustness checks is uncertainty about the true data generating process. By declaring a design in terms of MIDA, we can think about the robustness of a <em>single</em> estimator to multiple possible true data generating processes. An estimator that is robust in this sense is one that is unbiased with low uncertainty regardless of, say, the true functional form between <code>y1</code> and <code>y2</code>. To determine whether an estimator is robust, we can redefine a set of designs with different functional forms and assess the rate of correct decisions of our robustness checks strategy under each different model.</p>
</div>
<div id="visualization" class="section level2">
<h2>
<span class="header-section-number">9.9</span> Visualization<a class="anchor" aria-label="anchor" href="#visualization"><i class="fas fa-link"></i></a>
</h2>
<p>How results are presented in tables and figures is an important part of the answer strategy. Considerable attention has been paid to how to display data, including arguments for switching from tables to graphs as the primary way to present statistical models (Kastellec) and for visually present raw data and models together (Coppock). The reason for this attention is that what inferences readers make when reading a paper depends not only on the statistical procedures used for estimation but the medium in which they are displayed. When numerical estimates are not provided at all, and only visualizations of results, clearly aesthetic choices about which estimates are displayed and even the width of axes will determine what the reader takes away from the answer strategy. This principle applies not just to tables and visualizations; how we describe results in the text of a paper also shapes readers’ inferences from the data. Registered reports are a format for preparing scientific papers that involves prespecifying not only the form of graphs and tables but the text the author plans to write depending on the results. In short, decisions made from your results by readers are not just a function of numerical estimates but how they are presented.</p>
</div>
<div id="further-reading-4" class="section level2">
<h2>
<span class="header-section-number">9.10</span> Further reading<a class="anchor" aria-label="anchor" href="#further-reading-4"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>
<span class="citation">Gelman and Hill (<a href="references-4.html#ref-gelman2006data">2006</a>)</span> and [other stories] on multilevel modeling.</li>
<li>
<span class="citation">Aronow and Samii (<a href="references-4.html#ref-aronow2016does">2016</a>)</span> on the generalizability of regression estimators in observational settings.</li>
<li>
<span class="citation">Van Evera (<a href="references-4.html#ref-VanEvera1997">1997</a>)</span> on hoop tests.</li>
</ul>
<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book--><!-- start post here, do not edit above -->
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="crafting-a-data-strategy.html"><span class="header-section-number">8</span> Crafting a data strategy</a></div>
<div class="next"><a href="diagnosis.html"><span class="header-section-number">10</span> Diagnosis</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#choosing-an-answer-strategy"><span class="header-section-number">9</span> Choosing an answer strategy</a></li>
<li>
<a class="nav-link" href="#using-the-model-to-inform-your-answer-strategy"><span class="header-section-number">9.1</span> Using the Model to inform your Answer strategy</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#descriptive-analysis"><span class="header-section-number">9.1.1</span> Descriptive analysis</a></li>
<li><a class="nav-link" href="#causal-analysis"><span class="header-section-number">9.1.2</span> Causal analysis</a></li>
<li><a class="nav-link" href="#how-weights-help"><span class="header-section-number">9.1.3</span> How weights help</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#point-estimation"><span class="header-section-number">9.2</span> Point estimation</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#bias-variance-tradeoff"><span class="header-section-number">9.2.1</span> Bias variance tradeoff</a></li></ul>
</li>
<li><a class="nav-link" href="#when-parameters-are-not-point-identified"><span class="header-section-number">9.3</span> When parameters are not point identified</a></li>
<li><a class="nav-link" href="#characterizing-uncertainty"><span class="header-section-number">9.4</span> Characterizing uncertainty</a></li>
<li><a class="nav-link" href="#qualitative-methods-of-inference"><span class="header-section-number">9.5</span> Qualitative methods of inference</a></li>
<li>
<a class="nav-link" href="#tests"><span class="header-section-number">9.6</span> Tests</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#randomization-inference"><span class="header-section-number">9.6.1</span> randomization inference</a></li></ul>
</li>
<li><a class="nav-link" href="#answer-strategies-as-procedures"><span class="header-section-number">9.7</span> Answer strategies as procedures</a></li>
<li><a class="nav-link" href="#robustness"><span class="header-section-number">9.8</span> Robustness</a></li>
<li><a class="nav-link" href="#visualization"><span class="header-section-number">9.9</span> Visualization</a></li>
<li><a class="nav-link" href="#further-reading-4"><span class="header-section-number">9.10</span> Further reading</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/DeclareDesign/book/blob/master/02_Declaration_Diagnosis_Redesign/05_Choosing_an_Answer_Strategy.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/DeclareDesign/book/edit/master/02_Declaration_Diagnosis_Redesign/05_Choosing_an_Answer_Strategy.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Research Design: Declare, Diagnose, Redesign</strong>" was written by Graeme Blair, Jasper Cooper, Alexander Coppock, and Macartan Humphreys. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
