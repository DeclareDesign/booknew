<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 24 Integration | Research Design: Declare, Diagnose, Redesign</title>
<meta name="author" content="Graeme Blair, Alexander Coppock, and Macartan Humphreys">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.4.9001/tabs.js"></script><script src="libs/bs3compat-0.2.4.9001/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<link href="libs/bs4_book-1.0.0/dd_imgpopup.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/bs4_book-1.0.0/dd_imgpopup.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://hypothes.is/embed.js" async></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS --><link rel="stylesheet" href="headers/style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Research Design: Declare, Diagnose, Redesign</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li class="book-part">Introduction</li>
<li><a class="" href="preamble.html"><span class="header-section-number">1</span> Preamble</a></li>
<li><a class="" href="design-principles.html"><span class="header-section-number">2</span> Design principles</a></li>
<li><a class="" href="primer.html"><span class="header-section-number">3</span> Software primer</a></li>
<li><a class="" href="part-i-exercises.html"><span class="header-section-number">4</span> Part I Exercises</a></li>
<li class="book-part">Declaration, Diagnosis, Redesign</li>
<li><a class="" href="declaration-1.html"><span class="header-section-number">5</span> Declaration</a></li>
<li><a class="" href="specifying-the-model.html"><span class="header-section-number">6</span> Specifying the model</a></li>
<li><a class="" href="defining-the-inquiry.html"><span class="header-section-number">7</span> Defining the inquiry</a></li>
<li><a class="" href="crafting-a-data-strategy.html"><span class="header-section-number">8</span> Crafting a data strategy</a></li>
<li><a class="" href="choosing-an-answer-strategy.html"><span class="header-section-number">9</span> Choosing an answer strategy</a></li>
<li><a class="" href="p2diagnosis.html"><span class="header-section-number">10</span> Diagnosis</a></li>
<li><a class="" href="redesign-2.html"><span class="header-section-number">11</span> Redesign</a></li>
<li><a class="" href="part-ii-exercises.html"><span class="header-section-number">12</span> Part II Exercises</a></li>
<li class="book-part">Research Design Library</li>
<li><a class="" href="research-design-library.html"><span class="header-section-number">13</span> Research Design Library</a></li>
<li><a class="" href="observational-descriptive.html"><span class="header-section-number">14</span> Observational | descriptive</a></li>
<li><a class="" href="observational-causal.html"><span class="header-section-number">15</span> Observational | causal</a></li>
<li><a class="" href="experimental-causal.html"><span class="header-section-number">16</span> Experimental | causal</a></li>
<li><a class="" href="experimental-descriptive.html"><span class="header-section-number">17</span> Experimental | descriptive</a></li>
<li><a class="" href="complex-designs-1.html"><span class="header-section-number">18</span> Complex designs</a></li>
<li><a class="" href="part-iii-exercises.html"><span class="header-section-number">19</span> Part III Exercises</a></li>
<li class="book-part">Research Design Lifecycle</li>
<li><a class="" href="research-design-lifecycle.html"><span class="header-section-number">20</span> Research Design Lifecycle</a></li>
<li><a class="" href="brainstorming.html"><span class="header-section-number">21</span> Brainstorming</a></li>
<li><a class="" href="planning.html"><span class="header-section-number">22</span> Planning</a></li>
<li><a class="" href="realization.html"><span class="header-section-number">23</span> Realization</a></li>
<li><a class="active" href="integration.html"><span class="header-section-number">24</span> Integration</a></li>
<li><a class="" href="part-iv-exercises.html"><span class="header-section-number">25</span> Part IV Exercises</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="integration" class="section level1">
<h1>
<span class="header-section-number">24</span> Integration<a class="anchor" aria-label="anchor" href="#integration"><i class="fas fa-link"></i></a>
</h1>
<p>Researchers may build on the results of a past study in three ways: reanalyze the original data, holding <span class="math inline">\(d\)</span> constant but changing <span class="math inline">\(A\)</span> (reanalysis); providing a new answer to the same <span class="math inline">\(I\)</span> with new data, possibly changing <span class="math inline">\(D\)</span> and <span class="math inline">\(A\)</span> (replication); or synthesizing the study’s answer <span class="math inline">\(a^d\)</span> to the inquiry along with other past studies (meta-analysis). In this section, we outline archiving procedures to enable later researchers to reanalyze, replicate, or synthesize; and we describe procedures for doing each of these three integration tasks.</p>
<div id="archiving" class="section level2">
<h2>
<span class="header-section-number">24.1</span> Archiving<a class="anchor" aria-label="anchor" href="#archiving"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>One of the biggest successes in the push for greater research transparency has been changing norms surrounding the sharing of data and analysis code after studies have been published. It has been become de rigeur at many journals to post these materials at publicly-available repositories like the OSF or Dataverse. This development is undoubtedly a good thing. In older manuscripts, sometimes data or analyses are described as being “available upon request” but of course such requests are sometimes ignored. Furthermore, a century from now, study authors will no longer be with us even if they wanted to respond to such requests. Public repositories have a much better chance of preserving study information for the future.</p>
<!-- That's the promise of publicly-posted replication archives, but the mundane reality of replication archives often falls short. We see many archives that are disorganized, poorly documented, and contain dozens of bugs and inconsistencies.  -->
<p>What belongs in a replication archive? Enough detail so that those who wish to reanalyze, replicate, and synthesize results can do so without contacting the authors.</p>
<p><strong>Data.</strong> First, the data <span class="math inline">\(d\)</span> itself. Sometimes this is the raw data, sometimes it is only the “cleaned” data that is actually called by analysis scripts. Where ethically possible, we think it is preferable to post as much of the raw data as possible, for example after removing information like IP address or geographic location that could be used to identify a subject. We usually consider data processing scripts that clean and prepare data for analysis as part of the data strategy <span class="math inline">\(D\)</span> in the sense that they complete the measurement procedures laid out in <span class="math inline">\(D\)</span>. Cleaning scripts might also be considered part of the answer strategy in the sense that they apply an interpretation to the data provided by the world. The output of cleaning scripts – the cleaned data – should be included in the replication archive as well.</p>
<p><strong>Analysis code.</strong> Replication archives also include <span class="math inline">\(A\)</span>, or the set of functions applied to <span class="math inline">\(d\)</span> that produce <span class="math inline">\(a^D\)</span>. It is vitally important that the <em>actual</em> analysis code is archived because the natural-language descriptions of <span class="math inline">\(A\)</span> that are typically given in papers are imprecise. As a small example, many articles describe their answer strategies as “ordinary least squares” but do not fully describe the set of covariates used or what flavor of standard errors was estimated. These differences can substantively affect the quality of the research design. The actual analysis code makes <span class="math inline">\(A\)</span> explicit.</p>
<p><strong>Data strategy materials.</strong> Increasingly, replication archives include the materials needed to implement treatments and measurement strategies. Without the survey questionnaires in the languages and formats they were enumerated, we cannot exactly replicate them in future studies – and we cannot build on and adapt them. The treatment stimuli used in the study should be included also. A central problem in replicating studies in the Many Labs projects was that the exact stimuli were either not retained or no longer availble for past psychology studies. This loss led to confusion over whether failures to replicate were due to changes in the stimuli, different populations, or the underpowered original study designs.</p>
<p><strong>Design declaration.</strong> While typical replication archives include <span class="math inline">\(d\)</span> and <span class="math inline">\(A\)</span>, we think that future replication archives should also include a design declaration that fully describes <span class="math inline">\(M\)</span>, <span class="math inline">\(I\)</span>, <span class="math inline">\(D\)</span>, and <span class="math inline">\(A\)</span> – that is, we should archive designs, not just data and analysis code. This should be done in code and words. In addition, a diagnosis should be included, demonstrating the properties as understood by the author and also indicating the diagnosands that the author considered in judging the quality of the design.</p>
<p>Design details help future scholars not only assess, but replicate, reanalyze, and extend the study. Reanalysts need to understand the answer strategy so they can modify or extend it but also the data strategy that was used in order to ensure that their new analysis respects the details of the sampling, treatment assignment, and measurement procedures. Data and analysis sharing enables reanalysts to adopt or adapt the analysis strategy, but a declaration of the data strategy as well would help more. Replicators who wish to exactly replicate, or even just to provide an answer to the same inquiry, need to understand the inquiry, data strategy, and answer strategy. Replication practice today involves inferring most of these details from descriptions in text. The result is disputes that result after the replication is sent out for peer review, when the original authors may not agree with inferences the replicators made about what the inquiry or data strategy or answer strategy actually were. To protect the original authors as well as the replicators, including a research design declaration specifying each of these elements resolves these issues so that replication and extension can focus on the substance of the research question and innovation in research design.</p>
<!-- Figure \@ref(fig:filestructure)  -->
<p>The Figure below shows the file structure for an example replication. Our view on replication archives shares much in common with the <a href="https://www.projecttier.org">TIER protocol</a>. It includes raw data in a platform-independent format (.csv) and cleaned data in a language-specific format (.rds, a format for R data files), so that data features like labels, attributes, and factor levels are preserved when imported by the analysis scripts. The analysis scripts are labeled by the outputs they create, such as figures and tables. A master script is included that runs the cleaning and analysis scripts in the correct order. The documents folder includes the paper, the supplemental appendix, the pre-analysis plan, the populated analysis plan, and codebooks that describe the data. A README file explains each part of the replication archive. We also suggest that authors include a script that includes a design declaration and diagnosis.</p>
<div class="figure">
<img src="figures/file_structure.png" alt=""><p class="caption">File structure for archiving</p>
</div>
<!-- Example is archive at OSF: https://osf.io/4vuqh -->

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
<!-- start post here, do not edit above -->
</div>
<div id="reanalysis" class="section level2">
<h2>
<span class="header-section-number">24.2</span> Reanalysis<a class="anchor" aria-label="anchor" href="#reanalysis"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>A reanalysis of an existing study is a follow-up study in which <span class="math inline">\(d\)</span>, the original realized data, is fixed and changes to the answer strategy <span class="math inline">\(A\)</span> and sometimes the model <span class="math inline">\(M\)</span> or inquiry <span class="math inline">\(I\)</span> are proposed. Given <span class="math inline">\(d\)</span> is fixed, so too is the data strategy <span class="math inline">\(D\)</span>. The results given the new MIDA, which may differ from the original study’s results, are reported. We can learn from reanalyses in several ways.</p>
<p>We can confirm that there were no errors in the analysis strategy. Many reanalyses correct simple mathematical errors, typos in data transcription, or failures to analyze following the data strategy faithfully. These reanalyses show whether results do or do not depend on these corrections.</p>
<p>We can reassess what is known about the same inquiry, using new information about the world that was learned after the original study was published. Here, we may learn about new confounders or alternative causal channels that undermine the credibility of the original answer strategy. When reanalyzed, demonstrating the results do (or do not) change improves our understanding of the true inquiry.</p>
<p>Many reanalyses show that original findings are not “robust” to alternative answer strategies. These are better conceptualized as claims about robustness to alternative models: one model may imply one answer strategy and a different model, with another confounder, implies another. If both models are plausible, a good answer strategy should be robust to both and even help to distinguish between them and a reanalysis could uncover robustness to these alternative models or lack thereof.</p>
<p>Reanalyses may also aim to answer new questions that were not considered by the original study, but for which the realized data can provide useful answers. For example, authors may analyze outcomes not originally analyzed.</p>
<p>Reanalyses are themselves research designs. Whether a reanalysis is a good design, and how much it can contribute to our knowledge about the original inquiry, depend on <em>possible</em> realizations of the data not just the realized data. Because <span class="math inline">\(d\)</span> is fixed in a reanalysis, analysts are often instead tempted to judge the reanalysis based on whether it overturns or confirms the results of the original study. A successful reanalysis in this way of thinking demonstrates, by showing that the original results are changed under an alternative answer strategy, that the results are not robust to other plausible models. This way of thinking can lead to incorrect assessments of reanalyses. We need to consider what answers would obtain under the original answer strategy <span class="math inline">\(A\)</span> and the reanalysis strategy <span class="math inline">\(A^{\prime}\)</span> under many <em>possible</em> realizations of the data. A good reanalysis strategy reveals with high probability the set of models of the world under which we can make credible claims about the inquiry. Whether or not the results from the fixed <span class="math inline">\(d\)</span> that was realized change under the answer strategies <span class="math inline">\(A\)</span> and <span class="math inline">\(A^{\prime}\)</span> tells us little about this probability. It is only one draw.</p>
<p>To diagnose a reanalysis, we need to define two answer strategies — <span class="math inline">\(A\)</span> and <span class="math inline">\(A^{\prime}\)</span> — but also a new diagnostic-statistic. We need to decide how we summarize the answers from the two answer strategies. If one returns TRUE and one FALSE, what do we conclude about the inquiry? The function we define to summarize the two results depends on the inquiry and the goals of the reanalysis. But our diagnosis of the reanalysis should assess the properties of this summary of the two studies under possible realizations of the data. If the goal of the reanalysis is instead to learn about a new question, then we should simply construct a new MIDA altogether, but holding constant <span class="math inline">\(D\)</span> from the original study, which we cannot change because we already collected <span class="math inline">\(d\)</span> using it.</p>
<p>We illustrate the flaw in assessing reanalyses on the basis of changing significance of results from realized data below. We demonstrate how to assess the properties of reanalysis plans, comparing the properties of original answer strategies to proposed reanalysis answer strategies.</p>
<p>The design we consider is an observational study with a binary treatment <span class="math inline">\(Z\)</span> that may or may not be confounded by a covariate <span class="math inline">\(X\)</span>. The original answer strategy is a difference-in-means in the outcome <span class="math inline">\(Y\)</span> between the treatment and control group defined by <span class="math inline">\(Z\)</span>, call it <code>A</code>. The reanalyst collects the covariate <span class="math inline">\(X\)</span> and proposes to control for it in a linear regression; call that strategy <code>A_prime</code>.</p>
<div class="sourceCode" id="cb147"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">A</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">Z</span>, model <span class="op">=</span> <span class="va">lm_robust</span>, label <span class="op">=</span> <span class="st">"A"</span><span class="op">)</span>
<span class="va">A_prime</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">Z</span> <span class="op">+</span> <span class="va">X</span>, model <span class="op">=</span> <span class="va">lm_robust</span>, label <span class="op">=</span> <span class="st">"A_prime"</span><span class="op">)</span></code></pre></div>
<p>We set up the model in the shoes of the renalyst, who believes <span class="math inline">\(Z\)</span> and <span class="math inline">\(Y\)</span> are confounded by <span class="math inline">\(X\)</span>:</p>
<div class="sourceCode" id="cb148"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># X is a confounder and is measured pretreatment</span>
<span class="va">model_1</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_model.html">declare_model</a></span><span class="op">(</span>
    N <span class="op">=</span> <span class="fl">100</span>,
    U <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>,
    X <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>, <span class="co"># X is pretreatment</span>
    Z <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html">plogis</a></span><span class="op">(</span><span class="fl">0.5</span> <span class="op">+</span> <span class="va">X</span><span class="op">)</span><span class="op">)</span>,
    <span class="fu">potential_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="fl">0.1</span> <span class="op">*</span> <span class="va">Z</span> <span class="op">+</span> <span class="fl">0.25</span> <span class="op">*</span> <span class="va">X</span> <span class="op">+</span> <span class="va">U</span><span class="op">)</span>,
    Y <span class="op">=</span> <span class="fu">reveal_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">Z</span><span class="op">)</span>
  <span class="op">)</span> </code></pre></div>
<p>Drawing data from this strategy and applying the two answer strategies, we get differing results:</p>
<div class="sourceCode" id="cb149"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/draw_functions.html">draw_estimates</a></span><span class="op">(</span><span class="va">model_1</span> <span class="op">+</span> <span class="va">A</span> <span class="op">+</span> <span class="va">A_prime</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table class="table table-sm">
<thead><tr>
<th style="text-align:left;">
estimator_label
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
p.value
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
0.385
</td>
<td style="text-align:right;">
0.176
</td>
<td style="text-align:right;">
0.031
</td>
</tr>
<tr>
<td style="text-align:left;">
A_prime
</td>
<td style="text-align:right;">
0.219
</td>
<td style="text-align:right;">
0.188
</td>
<td style="text-align:right;">
0.246
</td>
</tr>
</tbody>
</table></div>
<p>Commonly, reanalysts would infer from this two things: that there is not an average treatment effect, and that the answer strategy <code>A_prime</code> is preferred. It is preferred because it is unbiased under confounding and also unbiased (and lower variance than <code>A</code>) even when there is no confounding. As we show below, these claims depend on the validity of other parts of the model <span class="math inline">\(M\)</span>. In particular, we define two other possible models, both where <span class="math inline">\(X\)</span> is not a confounder. In model 2, <span class="math inline">\(X\)</span> is measured before treatment, as in the first model. In model 3, however, <span class="math inline">\(X\)</span> is measured <em>post</em>treatment, and is affected by <span class="math inline">\(Y\)</span>. In many observational settings, it is now always clear when <span class="math inline">\(X\)</span> is realized or measured relative to treatment, so it is useful to explore the implications of the timing of measurement on the diagnosands of the design as we do below.</p>
<div class="sourceCode" id="cb150"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># X is not a confounder and is measured pretreatment</span>
<span class="va">model_2</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_model.html">declare_model</a></span><span class="op">(</span>
    N <span class="op">=</span> <span class="fl">100</span>,
    U <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>,
    X <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>,
    Z <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html">plogis</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span><span class="op">)</span>,
    <span class="fu">potential_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="fl">0.1</span> <span class="op">*</span> <span class="va">Z</span> <span class="op">+</span> <span class="fl">0.25</span> <span class="op">*</span> <span class="va">X</span> <span class="op">+</span> <span class="va">U</span><span class="op">)</span>,
    Y <span class="op">=</span> <span class="fu">reveal_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">Z</span><span class="op">)</span>
  <span class="op">)</span> 

<span class="co"># X is not a confounder and is measured posttreatment</span>
<span class="va">model_3</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_model.html">declare_model</a></span><span class="op">(</span>
    N <span class="op">=</span> <span class="fl">100</span>,
    U <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>,
    Z <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html">plogis</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span><span class="op">)</span>,
    <span class="fu">potential_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="fl">0.1</span> <span class="op">*</span> <span class="va">Z</span> <span class="op">+</span> <span class="va">U</span><span class="op">)</span>,
    Y <span class="op">=</span> <span class="fu">reveal_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">Z</span><span class="op">)</span>,
    X <span class="op">=</span> <span class="fl">0.1</span> <span class="op">*</span> <span class="va">Z</span> <span class="op">+</span> <span class="fl">5</span> <span class="op">*</span> <span class="va">Y</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>
  <span class="op">)</span> 

<span class="va">design_1</span> <span class="op">&lt;-</span> <span class="va">model_1</span> <span class="op">+</span> <span class="va">I</span> <span class="op">+</span> <span class="va">A</span> <span class="op">+</span> <span class="va">A_prime</span>
<span class="va">design_2</span> <span class="op">&lt;-</span> <span class="va">model_2</span> <span class="op">+</span> <span class="va">I</span> <span class="op">+</span> <span class="va">A</span> <span class="op">+</span> <span class="va">A_prime</span>
<span class="va">design_3</span> <span class="op">&lt;-</span> <span class="va">model_3</span> <span class="op">+</span> <span class="va">I</span> <span class="op">+</span> <span class="va">A</span> <span class="op">+</span> <span class="va">A_prime</span></code></pre></div>
<p>What we see in the diagnosis below is that <code>A_prime</code> is only preferred if we know that <span class="math inline">\(X\)</span> is measured pretreatment. In design 2, where <span class="math inline">\(X\)</span> is measured posttreatment, <code>A</code> is preferred, because controlling for <span class="math inline">\(X\)</span> leads to posttreatment bias. Including the <span class="math inline">\(X\)</span> variable in the regression misattributes some of the effect of <span class="math inline">\(Z\)</span> on <span class="math inline">\(Y\)</span> to <span class="math inline">\(X\)</span>. The reanalyst, this diagnosis indicates, needs to justify their beliefs about when <span class="math inline">\(X\)</span> is measured in order to claim that <code>A_prime</code> is preferred to <code>A</code>. It is not always preferred, as they might have concluded just by looking at the realized estimates from the two answer strategies.</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr>
<th style="text-align:left;">
design_label
</th>
<th style="text-align:left;">
estimator_label
</th>
<th style="text-align:right;">
bias
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
design_1
</td>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
0.213
</td>
</tr>
<tr>
<td style="text-align:left;">
design_1
</td>
<td style="text-align:left;">
A_prime
</td>
<td style="text-align:right;">
-0.002
</td>
</tr>
<tr>
<td style="text-align:left;">
design_2
</td>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
0.003
</td>
</tr>
<tr>
<td style="text-align:left;">
design_2
</td>
<td style="text-align:left;">
A_prime
</td>
<td style="text-align:right;">
0.002
</td>
</tr>
<tr>
<td style="text-align:left;">
design_3
</td>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
0.013
</td>
</tr>
<tr>
<td style="text-align:left;">
design_3
</td>
<td style="text-align:left;">
A_prime
</td>
<td style="text-align:right;">
0.016
</td>
</tr>
</tbody>
</table></div>
<p>Three principles emerge from the idea that changes from answer strategy <span class="math inline">\(A\)</span> to <span class="math inline">\(A^{\prime}\)</span> should be justified by diagnosis, not comparison of the results <span class="math inline">\(a^d\)</span> to <span class="math inline">\(a^{\prime d}\)</span>:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Home ground dominance.</strong> Holding the original <span class="math inline">\(M\)</span> constant (i.e., the home ground of the original study) as well as <span class="math inline">\(I\)</span>, if you can show that a new answer strategy <span class="math inline">\(A^{\prime}\)</span> yields better diagnosands than the original <span class="math inline">\(A\)</span>, then the new <span class="math inline">\(A^{\prime}\)</span> can be justified by a reanalyst on the basis of home ground dominance. In this situation, we would prefer <span class="math inline">\(A^{\prime}\)</span> and the estimates produced by it to <span class="math inline">\(A\)</span> and the original estimates produced by it, regardless of what those realized estimates are. <!-- parallel idea about finding a replication with a new D that rules out confounders -->
</li>
<li>
<strong>Robustness to alternative models.</strong> A second justification for a change in answer strategy is that you can show that a new answer strategy is robust to both the original model <span class="math inline">\(M\)</span> and a new, also plausible, <span class="math inline">\(M^{\prime}\)</span>. In observational studies, commonly we are uncertain about many features of the model such as the existence of unobserved confounders. In the example above, the reanalyst identified a confounder and found an answer strategy — controlling for <span class="math inline">\(X\)</span> — that they convinced themself through diagnosis was robust to the original model (no confounding) and the alternative model (confounding). An answer strategy that is robust to these two alternative models is preferred to one that is only unbiased under the no confounding model.</li>
<li>
<strong>Model plausibility.</strong> If the diagnosands for a design with <span class="math inline">\(A^{\prime}\)</span> are worse than those with <span class="math inline">\(A\)</span> under <span class="math inline">\(M\)</span> but better under <span class="math inline">\(M^{\prime}\)</span>, then the switch to <span class="math inline">\(A^{\prime}\)</span> can only be justified by a claim or demonstration that <span class="math inline">\(M^{\prime}\)</span> is more plausible than <span class="math inline">\(M\)</span>. As we saw in the example, there was a third possible model in which <span class="math inline">\(X\)</span> was realized posttreatment and so controlling for <span class="math inline">\(X\)</span> led to posttreatment bias. In that case, neither controlling for <span class="math inline">\(X\)</span> or not controlling for <span class="math inline">\(X\)</span> is robust to all three alternative models. The justification of model plausibility would have to be used this case in order to justify controlling for <span class="math inline">\(X\)</span>: substantive knowledge or additional data would have to be brought to bear to rule out the third model with posttreatment measurement of <span class="math inline">\(X\)</span>. The reanalyst could demonstrate that data collection of <span class="math inline">\(X\)</span> took place before the treatment was realized, for example.</li>
<li>
<strong>Undefined or unidentifiable inquiries</strong>. When inquiries are undefined or not identifiable, then it is fair game in a reanalysis to change the inquiry <span class="math inline">\(I\)</span> to a new <span class="math inline">\(I^{\prime}\)</span> that is defined and at least partially identifiable. Disputes may of course arise as to whether the new <span class="math inline">\(I^{\prime}\)</span> is sufficiently faithful to the original aims of the research.</li>
</ol>
<!-- 1. M always changes! (you have more information on $\tau$ or $\sd(\tau)$) --><!-- 2. Home ground dominance: Change A or D-and-A if A$^\prime$ > A under M --><!-- 3. Robustness to alternative models: Change A or D-and-A if A$^\prime$ $\geq$ A under M AND A$^\prime$ > A under M$^\prime$ E.g. change from simple to complete RA --><!-- 4. Model plausibility: If A$^\prime$ < A under M AND A$^\prime$ > A under M$^\prime$, then change to A$^\prime$ or D-and-A IFF M$^\prime$ is more plausible than M E.g. switching to balanced design if you believe variances equal across treatment groups --><!-- 5. Undefined inquiries. Change I to I$^\prime$ if I is undefined under M If I is defined under M: You can't change to I$^\prime$, You can’t change D to D$^\prime$ if that means I unidentifiable. --><!-- how do we update from the reanalysis research design (the original design plus the reanalysis of d)? --><!-- -- the design is the research design from before with two sets of estimates from two different A's --><!-- -- need an aggregation function (decisionmaking function) that converts the two sets of results into a decision or posterior --><!-- what can be learned from reanalysis? --><!-- (1) confirm there were not errors (consider changing A only) --><!-- (2) reassess what is known about the same inquiry, using new information about the world (change M, change A to suit new M) --><!-- (3) learn something new from the data about another node or edge or a different summary about the same ones (change I and possibly A to match it; possibly M if a node was missing; possibly add data) --><!-- (4) assess "robustness" of findings - point to discussion of this in answer strategy (or move it here) (change A) --><!-- (5) update M based on new research and assess what d can tell us from this study (change M and possibly I, possibly A to fit changed M and I) --><!-- how can we assess the properties of a *reanalysis*? diagnose changed MIDA. important to not condition on d, the design includes the actual D, and we need to consider what results d' we would get from the reanalysis under different realizations of D. --><!-- there are now two A's, so need to specify a decision function about how to integrate the two findings. this could be throw away the old a, or combine them in some way. if it's a "robustness" to alternative A, then you may want to combine not throw out for example. it's crucial to specify how you do that, that's part of the answer strategy. --><!-- ## Example --><!-- Knox, Lowe, and Mummolo (2020) (https://www.cambridge.org/core/journals/american-political-science-review/article/administrative-records-mask-racially-biased-policing/66BC0F9998543868BB20F241796B79B8) study the statistical biases that accompany estimates of racial bias in police use of force when presence in the dataset (being stopped by police) is conditioned on an outcome that is a downstream consequence of race. They show the estimate is not identified unless additional modelling assumptions are brought to bear. --><!-- Gaebler et al. (2020) (https://5harad.com/papers/post-treatment-bias.pdf) study the same question and make such modeling assumptions (subset ignorability, definition 2). --><!-- In a twitter thread (https://twitter.com/jonmummolo/status/1275790509647241222?s=20), Mummolo shows the three DAGs that are compatible with subset ignorability. We agree with Mummolo that these DAGs assume away causal paths that are very plausible. --><!-- ![DAG](figures/mummolo_dag.png) --><!-- This document provides a design declaration for this setting and shows how estimates of the controlled direct effect (effect of race on force among the stopped) are biased unless those paths are set to zero by assumption. --><!-- Design Declaration --><!-- There are four variables: (D: minority, M: stop, U: suspicion (unobserved), Y: force) and five paths: --><!-- ```{r} --><!-- D_M = 1 # effect of minority on stop --><!-- U_M = 1 # effect of suspicion on stop --><!-- D_Y = 1 # effect of minority on force --><!-- U_Y = 1 # effect of suspicion on force --><!-- M_Y = 1 # effect of stop on force --><!-- ``` --><!-- This basic design allows all five paths. --><!-- ```{r} --><!-- design_1 <- --><!--   declare_model(N = 1000, --><!--                      D = rbinom(N, size = 1, prob = 0.5), --><!--                      U = rnorm(N)) + --><!--   declare_potential_outcomes(M ~ rbinom(N, size = 1, prob = pnorm(D_M * --><!--                                                                     D + U_M * U)), --><!--                              assignment_variable = "D") + --><!--   declare_reveal(M, D) + --><!--   declare_potential_outcomes(Y ~ rnorm(N, D_Y * D + M_Y * M + U_Y * U), --><!--                              conditions = list(D = c(0, 1), M = c(0, 1))) + --><!--   declare_reveal(outcome_variables = "Y", --><!--                  assignment_variables = c("D", "M")) + --><!--   declare_inquiry(CDE = mean(Y_D_1_M_1 - Y_D_0_M_1)) + --><!--   declare_estimator(Y ~ D, subset = M == 1, inquiry = "CDE") --><!-- ``` --><!-- We redesign the design 3 times, removing one path at a time, then simulate all four designs. --><!-- ```{r, message=FALSE} --><!-- # no effect of D on M --><!-- design_2 <- redesign(design_1, D_M = 0) --><!-- # no effect of U on M --><!-- design_3 <- redesign(design_1, U_M = 0) --><!-- # no effect of U on Y --><!-- design_4 <- redesign(design_1, U_Y = 0) --><!-- ``` --><!-- This chunk is set to `echo = TRUE` and `eval = do_diagnosis` --><!-- ```{r, eval = do_diagnosis & !exists("do_bookdown")} --><!-- simulations <- simulate_designs(design_1, design_2, design_3, design_4, sims = sims) --><!-- ``` --><!-- Right after you do simulations, you want to save the simulations rds. --><!-- ```{r, echo = FALSE, purl = FALSE} --><!-- # figure out where the dropbox path is, create the directory if it doesn't exist, and name the RDS file --><!-- rds_file_path <- paste0(get_dropbox_path("policing"), "/simulations_policing.RDS") --><!-- if (do_diagnosis & !exists("do_bookdown")) { --><!--   write_rds(simulations, path = rds_file_path) --><!-- } --><!-- simulations <- read_rds(rds_file_path) --><!-- ``` --><!-- ```{r, echo=FALSE, message = FALSE} --><!-- simulations <- --><!--   simulations %>% --><!--   mutate(`Assumed DAG` = factor( --><!--     design_label, --><!--     levels = c("design_1", "design_2", "design_3", "design_4"), --><!--     labels = c( --><!--       "All paths possible", --><!--       "no effect of D on M", --><!--       "no effect of U on M", --><!--       "no effect of U on Y" --><!--     ) --><!--   )) --><!-- summary_df <- --><!--   simulations %>% --><!--   group_by(`Assumed DAG`) %>% --><!--   summarise( --><!--     mean_estimand = mean(estimand), --><!--     mean_estimate = mean(estimate), --><!--     bias = mean(estimate - estimand) --><!--   ) %>% --><!--   pivot_longer(cols = c("mean_estimand", "mean_estimate")) --><!-- ``` --><!-- This plot confirms that unless one of those implausible assumptions hold, estimates of the CDE are biased. --><!-- ```{r, echo=FALSE} --><!-- ggplot(simulations, aes(estimate)) + --><!--   geom_histogram(bins = 50) + --><!--   geom_vline(data = summary_df, aes(xintercept = value, color = name)) + --><!--   facet_wrap(~`Assumed DAG`) + --><!--   xlab("Simulated CDE estimates") + --><!--   theme_bw() + --><!--   theme(legend.position = "bottom", --><!--         strip.background = element_blank(), --><!--         axis.title.y = element_blank(), --><!--         legend.title = element_blank()) --><!-- ``` --><!-- ### Grab bag --><!-- - @Clemens2017 on taxonomy of these kinds of efforts --><!-- - if you're going to use d to learn about a different M for a different I, you need to understand their D --><!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book--><!-- start post here, do not edit above -->
</div>
<div id="replication" class="section level2">
<h2>
<span class="header-section-number">24.3</span> Replication<a class="anchor" aria-label="anchor" href="#replication"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>After your study is completed, it may one day be replicated. Replication differs from reanalysis in that a replication study involves the collection of new data to study the same inquiry. A new model, data strategy, or answer strategy may also be proposed. By contrast, a reanalysis may re-specify parts of the research design, but always re-uses the original data <span class="math inline">\(d\)</span> in some way.</p>
<p>So-called “exact” replications hold key features of I, D, and A fixed, but draw a new dataset <span class="math inline">\(d_{\rm new}\)</span> from data strategy <span class="math inline">\(D()\)</span> and apply the same answer strategy <span class="math inline">\(A\)</span> to the new <span class="math inline">\(d\)</span> in order to produce a fresh answer <span class="math inline">\(a_{\rm new}^D\)</span>. Replications are said to “succeed” when <span class="math inline">\(a_{\rm old}^D\)</span> and <span class="math inline">\(a_{\rm new}^D\)</span> are similar and to “fail” when they are not. Dichotomizing replication attempts into successes and failures is usually not that helpful, and it would be better to simply characterize how similar <span class="math inline">\(a_{\rm old}^D\)</span> and <span class="math inline">\(a_{\rm new}^D\)</span> are.</p>
<p>Exact replication is impossible: at least some elements of M have changed between the first study and the replication. Specifying how they might have changed, e.g., how outcomes vary with time, will help judge differences observed between <span class="math inline">\(a_{\rm old}^D\)</span> and <span class="math inline">\(a_{\rm new}^D\)</span>. Statistical noise will also play a role.</p>
<p>Replication studies can benefit enormously from the knowledge gains produced by the original studies. For example, we learn a large amount about the model <span class="math inline">\(M\)</span> and the likely value of the estimand <span class="math inline">\(a^M\)</span> from the original study. The <span class="math inline">\(M\)</span> of the replication study can and should incorporate this new information. For example, if we learn from the original study that <span class="math inline">\(a^M\)</span> is positive but it might be small, the replication study could respond by changing <span class="math inline">\(D\)</span> in order to increase the sample size. Design diagnosis can help you learn about how to change the design of the replication study in light of the original study.</p>
<p>When changes to the data strategy <span class="math inline">\(D\)</span> or answer strategy <span class="math inline">\(A\)</span> can be made to produce more informative answers about the same inquiry <span class="math inline">\(I\)</span>, exact replication may not be preferred. Holding the treatment and outcomes the same may be required to provide an answer to the same <span class="math inline">\(I\)</span>, but increasing the sample size or sampling individuals rather than villages or other changes may be preferable to exact replication. Replication designs can also take advantage of new best practices in research design.</p>
<!-- When designing **original** studies, you should anticipate that someday your work will be replicated. To the extent that you want future replication studies to arrive at similar answers to the original study you produce (i.e., you want their $a_{\rm new}^D$ to match your $a_{\rm old}^D$ as closely as possible), you will want to choose designs that bring $a_{\rm old}^D$ as close to $a^M$ as possible, under the presupposition that faithful replicators will also design their studies in such a way that $a_{\rm new}^D$ will also be close to $a^M$. -->
<!-- Replication studies necessarily differ from original studies -- it is literally impossible to reproduce the exact conditions of the original study in the same way it's impossible to step in the same river twice. Another way of putting that same statement is that $D_{\rm new}$ is necessarily different from $D_{\rm old}$. Theory (i.e., beliefs about $M$) is the tool we use to say that $D_{\rm old}$ is similar enough to $D_{\rm new}$ to constitute a close enough replication study. As a concrete example, many survey experimental replications involve using the exact same experimental stimuli but changing the study sample, e.g., from a nationally representative sample to a convenience sample. -->
<p>So-called “conceptual” replications alter both <span class="math inline">\(M\)</span> and <span class="math inline">\(D\)</span>, but keep <span class="math inline">\(I\)</span> and <span class="math inline">\(A\)</span> as similar as possible. That is, a conceptual replication tries to ascertain whether a relationship in one context (<span class="math inline">\(I(M_{\rm old})\)</span>) also holds in a new context (<span class="math inline">\(I(M_{\rm new}\)</span>). The trouble and promise of conceptual replications lies in the success of the designer at holding <span class="math inline">\(I\)</span> constant. Too often, a conceptual replication fails because in changing <span class="math inline">\(M\)</span>, too much changes about <span class="math inline">\(I\)</span> such that too much changes about the “concept” under replication. The key is holding <span class="math inline">\(I\)</span> fixed.</p>
<p>A summary function is neededto interpret the difference between <span class="math inline">\(a_{\rm old}^D\)</span> and <span class="math inline">\(a_{\rm new}^D\)</span>. This may take the new one and throw out the old if MIDA was poor in the first. It may be taking the average. It may be a precision-weighted average. Specifying this function ex ante may be useful, to avoid the choice of summary depending on the results of the replication. This summary function will be reflected in <span class="math inline">\(A\)</span> and in the discussion section of the replication paper.</p>
<div id="example-15" class="section level3">
<h3>
<span class="header-section-number">24.3.1</span> Example:<a class="anchor" aria-label="anchor" href="#example-15"><i class="fas fa-link"></i></a>
</h3>
<p>Here we have an original study design with size 1000. The true SATE for the original study design is 0.2 because the original authors happened to study a reasonably treatment responsive population.</p>
<p>We seek to replicate the original results, whatever they may be. We want to characterize the probability of concluding that we “failed” to replicate the original results. We have some alternative metrics for assessing this.</p>
<ol style="list-style-type: decimal">
<li><p>Are the original and replication estimates statistically significantly different from each other? If yes, we conclude that we failed to replicate the original results, and if no, we conclude that the study replicated.</p></li>
<li><p>Is the original estimate within the replication 95% CI? (as advocated by gilbert)</p></li>
<li><p>Is the replication estimate within the original 95% CI? (as cacluated by nosek)</p></li>
<li><p>Do we fail to affirm equivalence between the replication and original estimate, using a tolerance of 0.2?</p></li>
</ol>
<p>The figure shows that no matter how big we make the study, we find that the rate of concluding the difference-in-SATEs is nonzero only occurs about 10% of the time. The relatively high variance of the original study estimate means that it is so uncertain, it’s tough to distinguish it from any number in particular.</p>
<p>For a similar reason, the replication estimate is almost never outside of the original ci, because it’s rare to be more extreme than a wide CI.</p>
<p>As the size of the replication study grows, we become more and more likely to conclude that the study fails to replicate. At very large sample sizes, the repliccation CI because extremely small, so in the limit, it will never include the original study.</p>
<p>Equivalence testing has the nice property that as the sample size grows, we get closer to the correct answer – the true SATEs are indeed within 0.2 standard units together. However, again because the original study is so noisy, it’s difficult to affirm its equivalence with anything.</p>
<p>The upshot of this exercise is that, curiously, when original studies are weak (in that they generate imprecise estimates), it becomes <strong>harder</strong> to conclusively affirm that they did not replicate.</p>
<div class="figure">
<span id="fig:unnamed-chunk-513"></span>
<img src="book_files/figure-html/unnamed-chunk-513-1.svg" alt="Rates of 'Failure to Replicate' according to four diagnosands" width="100%"><p class="caption">
Figure 24.1: Rates of ‘Failure to Replicate’ according to four diagnosands
</p>
</div>
<p><strong>Further reading</strong>.</p>
<ul>
<li>
<span class="citation">Clemens (<a href="references.html#ref-Clemens2017" role="doc-biblioref">2017</a>)</span> on distinctions between replication and reanalysis</li>
</ul>
<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book--><!-- start post here, do not edit above -->
</div>
</div>
<div id="synthesis" class="section level2">
<h2>
<span class="header-section-number">24.4</span> Synthesis<a class="anchor" aria-label="anchor" href="#synthesis"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>One of the last, if not the last, stage of the lifecycle of a research design is its eventual incorporation in to our common scientific understanding of the world. Research findings about specific Is – specific <span class="math inline">\(a^D\)</span>s need to be synthesized into our broader scientific understanding. A research synthesis comprises a new research design that summarizes past research.</p>
<p>Research synthesis takes two basic forms. The first is meta-analysis, in which a series of <span class="math inline">\(a^D\)</span>s are analyzed together in order to better understand features of the distribution of answers obtained in the literature. Traditional meta-analysis typically focuses on the average of k answers: <span class="math inline">\(a_1^D\)</span>,<span class="math inline">\(a_2^D\)</span>,…<span class="math inline">\(a_k^D\)</span>. Studies can be averaged together in many ways that are better and worse. Sometimes the answers are averaged together according to their precision – a precision weighted average of estimates from many studies is equivalent to fixed-effects meta-analysis. Sometimes studies are “averaged” by counting up how many of the estimates are positive and significant, how many are negative and significant, and how many are null. This is the typical averaging approach taken in a literature review. Regardless of the averaging approach, the goal of this kind of synthesis is to learn as much as possible about a particular <span class="math inline">\(I\)</span> by drawing on evidence from many studies.</p>
<p>A second kind of synthesis is an attempt to bring together many <span class="math inline">\(a^D\)</span>, each of which targets a different inquiry about a common model. This is the kind of synthesis that takes place across an entire research literature. Different scholars focus on different nodes and edges of the common model, so a synthesis needs to incorporate the diverse sources of evidence.</p>
<p>How can you best anticipate how your research findings will be synthesized? For the first kind of synthesis – meta-analysis – you must be cognizant of keeping a commonly understood <span class="math inline">\(I\)</span> in mind. You want to select inquiries not for their novelty, but because of their commonly-understood importance. We want <em>many</em> studies on the effects of having women versus men elected officials on public goods because we want to understand this particular <span class="math inline">\(I\)</span> in great detail and specificity. While the specifics of the model <span class="math inline">\(M\)</span> might differ from study to study, the fact that the <span class="math inline">\(I\)</span>s are all similar enough to be synthesized allows for a specific kind of knowledge accumulation.</p>
<p>For the second kind of synthesis – literature-wide progress on a full causal model – even greater care is required. Specific studies cannot make up bespoke models <span class="math inline">\(M\)</span> but instead must understand how the specific <span class="math inline">\(M\)</span> adopted in the study is a special case of some master <span class="math inline">\(M\)</span> that is in principle agreed to by a wider research community. The nonstop, neverending proliferation of study-specific theories is a threat to this kind of knowledge accumulation.
<!-- (Cite cyrus on causal empiricism, that psych paper on crazy proliferation of theories). --></p>
<p>Declaring and diagnosing the properties of the meta design can be as informative as doing so in planning for an individual study. The first step of every research synthesis is the process of collecting past studies. Search strategies are sampling strategies, and they can be biased in the same ways as convenience samples of individuals. Conducting a Census of past literature on a topic is impossible: much research conducted is not published or not yet published. Selecting studies from major journals alone may induce additional publication bias in your sample. Collecting working papers and soliciting unpublished abandoned research on a topic are strategies to mitigate these risks. The choice of answer strategy for research synthesis is typically driven by assumptions about a model of how studies are related and how the contexts and units within them were selected. The model for declaring a research synthesis thus must include assumptions not only about how studies reach you as the synthesizer, but how the contexts and units were selected in those original studies. Diagnosis can help assess the conditions under which your analysis strategies will provide unbiased, efficient estimates of true effects either in a subset of contexts which were studies’r flagit()’(CONFUSED ABOUT “which were studies”) or about a broader population.</p>
<div class="sourceCode" id="cb151"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">study_design_fixed</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_model.html">declare_model</a></span><span class="op">(</span>N <span class="op">=</span> <span class="fl">100</span>, U <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>, <span class="fu">potential_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="fl">0.1</span> <span class="op">*</span> <span class="va">Z</span> <span class="op">+</span> <span class="va">U</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_assignment.html">declare_assignment</a></span><span class="op">(</span>Z <span class="op">=</span> <span class="fu">complete_ra</span><span class="op">(</span><span class="va">N</span>, m <span class="op">=</span> <span class="fl">50</span><span class="op">)</span>, legacy <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_measurement.html">declare_measurement</a></span><span class="op">(</span>Y <span class="op">=</span> <span class="fu">reveal_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">Z</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">Z</span>, model <span class="op">=</span> <span class="va">difference_in_means</span><span class="op">)</span>

<span class="va">study_design_random</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_model.html">declare_model</a></span><span class="op">(</span>N <span class="op">=</span> <span class="fl">100</span>, U <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>, <span class="fu">potential_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1</span>, mean <span class="op">=</span> <span class="fl">0.1</span>, sd <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span> <span class="op">*</span> <span class="va">Z</span> <span class="op">+</span> <span class="va">U</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_assignment.html">declare_assignment</a></span><span class="op">(</span>Z <span class="op">=</span> <span class="fu">complete_ra</span><span class="op">(</span><span class="va">N</span>, m <span class="op">=</span> <span class="fl">50</span><span class="op">)</span>, legacy <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_measurement.html">declare_measurement</a></span><span class="op">(</span>Y <span class="op">=</span> <span class="fu">reveal_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">Z</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">Z</span>, model <span class="op">=</span> <span class="va">difference_in_means</span><span class="op">)</span>

<span class="va">model</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_model.html">declare_model</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/simulate_design.html">simulate_design</a></span><span class="op">(</span><span class="va">study_design_fixed</span>, <span class="va">study_design_random</span>, sims <span class="op">=</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span>

<span class="va">answer_strategy</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span>handler <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">label_estimator</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">data</span>, <span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span><span class="fu">rma.uni</span><span class="op">(</span>yi <span class="op">=</span> <span class="va">estimate</span>, sei <span class="op">=</span> <span class="va">std.error</span>, subset <span class="op">=</span> <span class="va">design_label</span> <span class="op">==</span> <span class="st">"study_design_fixed"</span>, method <span class="op">=</span> <span class="st">"REML"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
  <span class="op">}</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"FE-RE"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span>handler <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">label_estimator</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">data</span>, <span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span><span class="fu">rma.uni</span><span class="op">(</span>yi <span class="op">=</span> <span class="va">estimate</span>, sei <span class="op">=</span> <span class="va">std.error</span>, subset <span class="op">=</span> <span class="va">design_label</span> <span class="op">==</span> <span class="st">"study_design_random"</span>, method <span class="op">=</span> <span class="st">"REML"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
  <span class="op">}</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"RE-RE"</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span>handler <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">label_estimator</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">data</span>, <span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span><span class="fu">rma.uni</span><span class="op">(</span>yi <span class="op">=</span> <span class="va">estimate</span>, sei <span class="op">=</span> <span class="va">std.error</span>, subset <span class="op">=</span> <span class="va">design_label</span> <span class="op">==</span> <span class="st">"study_design_fixed"</span>, method <span class="op">=</span> <span class="st">"FE"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
  <span class="op">}</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"FE-FE"</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">declare_estimator</a></span><span class="op">(</span>handler <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/DeclareDesign/man/declare_estimator.html">label_estimator</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/base/with.html">with</a></span><span class="op">(</span><span class="va">data</span>, <span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span><span class="fu">rma.uni</span><span class="op">(</span>yi <span class="op">=</span> <span class="va">estimate</span>, sei <span class="op">=</span> <span class="va">std.error</span>, subset <span class="op">=</span> <span class="va">design_label</span> <span class="op">==</span> <span class="st">"study_design_random"</span>, method <span class="op">=</span> <span class="st">"FE"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
  <span class="op">}</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"RE-FE"</span><span class="op">)</span>

<span class="va">design</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op">+</span> <span class="va">answer_strategy</span></code></pre></div>
<!-- A research synthesis is a "meta MIDA" -->
<!-- M: A model that subsumes portions of the sub Ms -->
<!-- I: This is a summary of all of the Is across the studies -->
<!-- D: This is the inclusion / exclusion criteria. Transformations of the study data. standardization. (sampling, measurement.) -->
<!-- A: things like random effects or fixed effects -->
<!-- $I_1 \approx I_2 \approx I_3$ -->
<!-- Not -->
<!-- $a^M_1 \approx a^M_2 \approx a^M_3$ -->
<!-- Meta-analysis can be used not just to guess about effects out-of-sample but also to re-evaluate effects in sample: https://declaredesign.org/blog/2018-12-11-meta-analysis.html -->
<!-- - don't select on DV -->
<!-- - select on high quality MIDAs (drop those with bias) -->
<!-- - precision weighting (accounting for the quality of the design indirectly!) -->
<!-- ## grab bag -->
<!-- -- systematic reviews are sign and significance, meta-analysis are point estimates -->

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
<!-- start post here, do not edit above -->
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="realization.html"><span class="header-section-number">23</span> Realization</a></div>
<div class="next"><a href="part-iv-exercises.html"><span class="header-section-number">25</span> Part IV Exercises</a></div>
</div></main><div id="on-this-page-nav" class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#integration"><span class="header-section-number">24</span> Integration</a></li>
<li><a class="nav-link" href="#archiving"><span class="header-section-number">24.1</span> Archiving</a></li>
<li><a class="nav-link" href="#reanalysis"><span class="header-section-number">24.2</span> Reanalysis</a></li>
<li>
<a class="nav-link" href="#replication"><span class="header-section-number">24.3</span> Replication</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#example-15"><span class="header-section-number">24.3.1</span> Example:</a></li></ul>
</li>
<li><a class="nav-link" href="#synthesis"><span class="header-section-number">24.4</span> Synthesis</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="download-code" href="./integration.R"><i class="far fa-file-code"></i> Download R code</a></li>
          
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Research Design: Declare, Diagnose, Redesign</strong>" was written by Graeme Blair, Alexander Coppock, and Macartan Humphreys. </p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
