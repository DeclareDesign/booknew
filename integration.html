<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 24 Integration | Research Design: Declare, Diagnose, Redesign</title>
<meta name="author" content="Graeme Blair, Alexander Coppock, and Macartan Humphreys">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.4.9000/tabs.js"></script><script src="libs/bs3compat-0.2.4.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<link href="libs/bs4_book-1.0.0/dd_imgpopup.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/bs4_book-1.0.0/dd_imgpopup.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://hypothes.is/embed.js" async></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Research Design: Declare, Diagnose, Redesign</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li class="book-part">Introduction</li>
<li><a class="" href="preamble.html"><span class="header-section-number">1</span> Preamble</a></li>
<li><a class="" href="improving-research-designs.html"><span class="header-section-number">2</span> Improving research designs</a></li>
<li><a class="" href="primer.html"><span class="header-section-number">3</span> Software primer</a></li>
<li><a class="" href="part-i-exercises.html"><span class="header-section-number">4</span> Part I Exercises</a></li>
<li class="book-part">Declaration, Diagnosis, Redesign</li>
<li><a class="" href="declaration.html"><span class="header-section-number">5</span> Declaration</a></li>
<li><a class="" href="specifying-the-model.html"><span class="header-section-number">6</span> Specifying the model</a></li>
<li><a class="" href="defining-the-inquiry.html"><span class="header-section-number">7</span> Defining the inquiry</a></li>
<li><a class="" href="crafting-a-data-strategy.html"><span class="header-section-number">8</span> Crafting a data strategy</a></li>
<li><a class="" href="choosing-an-answer-strategy.html"><span class="header-section-number">9</span> Choosing an answer strategy</a></li>
<li><a class="" href="p2diagnosis.html"><span class="header-section-number">10</span> Diagnosis</a></li>
<li><a class="" href="redesign-2.html"><span class="header-section-number">11</span> Redesign</a></li>
<li><a class="" href="part-ii-exercises.html"><span class="header-section-number">12</span> Part II Exercises</a></li>
<li class="book-part">Research Design Library</li>
<li><a class="" href="research-design-library.html"><span class="header-section-number">13</span> Research Design Library</a></li>
<li><a class="" href="observational-designs-for-descriptive-inference.html"><span class="header-section-number">14</span> Observational designs for descriptive inference</a></li>
<li><a class="" href="observational-designs-for-causal-inference.html"><span class="header-section-number">15</span> Observational designs for causal inference</a></li>
<li><a class="" href="experimental-designs-for-causal-inference.html"><span class="header-section-number">16</span> Experimental designs for causal inference</a></li>
<li><a class="" href="experimental-designs-for-descriptive-inference.html"><span class="header-section-number">17</span> Experimental designs for descriptive inference</a></li>
<li><a class="" href="complex-designs-1.html"><span class="header-section-number">18</span> Complex designs</a></li>
<li><a class="" href="part-iii-exercises.html"><span class="header-section-number">19</span> Part III Exercises</a></li>
<li class="book-part">Research Design Lifecycle</li>
<li><a class="" href="research-design-lifecycle.html"><span class="header-section-number">20</span> Research Design Lifecycle</a></li>
<li><a class="" href="brainstorming.html"><span class="header-section-number">21</span> Brainstorming</a></li>
<li><a class="" href="planning.html"><span class="header-section-number">22</span> Planning</a></li>
<li><a class="" href="realization.html"><span class="header-section-number">23</span> Realization</a></li>
<li><a class="active" href="integration.html"><span class="header-section-number">24</span> Integration</a></li>
<li><a class="" href="part-iv-exercises.html"><span class="header-section-number">25</span> Part IV Exercises</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="integration" class="section level1">
<h1>
<span class="header-section-number">24</span> Integration<a class="anchor" aria-label="anchor" href="#integration"><i class="fas fa-link"></i></a>
</h1>
<div id="archiving" class="section level2">
<h2>
<span class="header-section-number">24.1</span> Archiving<a class="anchor" aria-label="anchor" href="#archiving"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>One of the biggest successes in the push for greater research transparency has been changing norms surrounding the sharing of data and analysis code after studies have been published. It has been become de rigeur at many journals to post these materials at publicly-available repositories like the OSF or Dataverse. This development is undoubtedly a good thing. In older manuscripts, sometimes data or analyses are described as being “available upon request” but of course such requests are sometimes ignored. Furthermore, a century from now, study authors will no longer be with us even if they wanted to respond to such requests. Public repositories have a much better chance of preserving study information for the future.</p>
<!-- That's the promise of publicly-posted replication archives, but the mundane reality of replication archives often falls short. We see many archives that are disorganized, poorly documented, and contain dozens of bugs and inconsistencies.  -->
<p>What belongs in a replication archive? First, the data <span class="math inline">\(d\)</span> itself. Sometimes this is the raw data, sometimes it is only the “cleaned” data that is actually called by analysis scripts. Where ethically possible, we think it is preferable to post as much of the raw data as possible, for example after removing information like IP address or geographic location that could be used to identify a subject. We usually consider data processing scripts that clean and prepare data for analysis as part of the data strategy <span class="math inline">\(D\)</span> in the sense that they complete the measurement procedures laid out in <span class="math inline">\(D\)</span>. Cleaning scripts might also be considered part of the answer strategy in the sense that they apply an interpretation to the data provided by the world. The output of cleaning scripts – the cleaned data – should be included in the replication archive as well.</p>
<p>Replication archives also include <span class="math inline">\(A\)</span>, or the set of functions applied to <span class="math inline">\(d\)</span> that produce <span class="math inline">\(a^D\)</span>. It is vitally important that the <em>actual</em> analysis code is archived because the natural-language descriptions of <span class="math inline">\(A\)</span> that are typically given in papers are imprecise. As a small example, many articles describe their answer strategies as “ordinary least squares” but do not fully describe the set of covariates used or what flavor of standard errors was estimated. These differences can substantively affect the quality of the research design. The actual analysis code makes <span class="math inline">\(A\)</span> explicit.</p>
<p>While typical replication archives include <span class="math inline">\(d\)</span> and <span class="math inline">\(A\)</span>, we think that future replication archives should also include a design declaration that fully describes <span class="math inline">\(M\)</span>, <span class="math inline">\(I\)</span>, <span class="math inline">\(D\)</span>, and <span class="math inline">\(A\)</span> – that is, we should archive designs, not just data and analysis code. This should be done in code and words. In addition, a diagnosis should be included, demonstrating the properties as understood by the author and also indicating the diagnosands that the author considered in judging the quality of the design.</p>
<!-- Figure \@ref(fig:filestructure)  -->
<p>The Figure below shows the file structure for an example replication. Our view on replication archives shares much in common with the TIER protocol, which can be found here: <a href="https://www.projecttier.org/" class="uri">https://www.projecttier.org/</a>. It includes raw data in a platform-independent format (.csv) and cleaned data in a language-specific format (.rds), so that data features like labels, attributes, and factor levels are preserved when imported by the analysis scripts. The analysis scripts are labeled by the outputs they create, such as figures and tables. A master script is included that runs the cleaning and analysis scripts in the correct order. The documents folder includes the paper, the supplemental appendix, the pre-analysis plan, the populated analysis plan, and codebooks that describe the data. A README file explains each part of the replication archive. We also suggest that authors include a script that includes a design declaration and diagnosis.</p>
<div class="figure">
<img src="figures/file_structure.png" alt=""><p class="caption">File structure for archiving</p>
</div>
<!-- Example is archive at OSF: https://osf.io/4vuqh -->

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
<!-- start post here, do not edit above -->
</div>
<div id="reanalysis" class="section level2">
<h2>
<span class="header-section-number">24.2</span> Reanalysis<a class="anchor" aria-label="anchor" href="#reanalysis"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>A reanalysis of an existing study is a follow-up study in which <span class="math inline">\(d\)</span>, the original realized data, is fixed and changes to <span class="math inline">\(A\)</span> and sometimes <span class="math inline">\(M\)</span> or <span class="math inline">\(I\)</span> are proposed. Given <span class="math inline">\(d\)</span> is fixed, so too is the data strategy <span class="math inline">\(D\)</span>. The results given the new MIDA, which may differ from the original study’s results, are reported.</p>
<p>We can learn from reanalyses in at least five ways’r flagit()’(WHICH FIVE?). We can confirm that there were no errors in the analysis strategy. Many reanalyses correct simple mathematical errors, typos in data transcription, or failures to analyze following the data strategy faithfully. These reanalyses show whether results do or do not depend on these corrections.</p>
<p>We can reassess what is known about the same <span class="math inline">\(I\)</span>, using new information about the world that was learned after the original study was published. Here, we may learn about new confounders or alternative causal channels that undermine the credibility of the original answer strategy. When reanalyzed, demonstrating the results do (or do not) change improves our understanding of <span class="math inline">\(a^W\)</span>.</p>
<p>Many reanalyses show that original findings are not “robust” to alternative answer strategies. These are better conceptualized as claims about robustness to alternative models: one model may imply one answer strategy and a different model, with another confounder, implies another. If both models are plausible, a good answer strategy should be robust to both and even help to distinguish between them and a reanalysis could uncover robustness to these alternative models or lack thereof.</p>
<p>Reanalyses may also aim to answer new questions that were not considered by the original study, but for which the realized data can provide useful answers. For example, authors may analyze outcomes not originally analyzed.</p>
<p>Reanalyses are themselves research designs. Whether a reanalysis is a good design, and how much it can contribute to our knowledge about the original inquiry, depend on possible realizations of the data. Because <span class="math inline">\(d\)</span> is fixed in a reanalysis, analysts are often instead tempted to judge the reanalysis based on whether it overturns or confirms the results of the original study. A successful reanalysis in this way of thinking demonstrates, by showing that the original results are changed under an alternative <span class="math inline">\(A\)</span>, that the results are not robust to other plausible models. This way of thinking can lead to incorrect assessments of reanalyses. We need to consider what answers would obtain under the original answer strategy <span class="math inline">\(A\)</span> and the reanalysis strategy <span class="math inline">\(A^{\prime}\)</span> under many <em>possible</em> realizations of the data. A good reanalysis strategy reveals with high probability the set of models of the world under which we can make credible claims about <span class="math inline">\(I\)</span>. Whether or not the results from the fixed <span class="math inline">\(d\)</span> that was realized change under <span class="math inline">\(A\)</span> and <span class="math inline">\(A^{\prime}\)</span> tells us little about this probability. It is only one draw.</p>
<p>To diagnose a reanalysis, we need to define two answer strategies — <span class="math inline">\(A\)</span> and <span class="math inline">\(A^{\prime}\)</span> — but also a new diagnostic-statistic. We need to decide how we summarize the answers from the two answer strategies. If one returns TRUE and one FALSE, what do we conclude about the inquiry? The function we define to summarize the two results depends on the inquiry and the goals of the reanalysis. But our diagnosis of the reanalysis should assess the properties of this summary of the two studies under possible realizations of the data. If the goal of the reanalysis is instead to learn about a new question, then we should simply construct a new MIDA altogether, but holding constant <span class="math inline">\(D\)</span> from the original study, which we cannot change because we already collected <span class="math inline">\(d\)</span> using it.</p>
<!-- how do we update from the reanalysis research design (the original design plus the reanalysis of d)? -->
<!-- -- the design is the research design from before with two sets of estimates from two different A's -->
<!-- -- need an aggregation function (decisionmaking function) that converts the two sets of results into a decision or posterior -->
<!-- what can be learned from reanalysis? -->
<!-- (1) confirm there were not errors (consider changing A only) -->
<!-- (2) reassess what is known about the same inquiry, using new information about the world (change M, change A to suit new M) -->
<!-- (3) learn something new from the data about another node or edge or a different summary about the same ones (change I and possibly A to match it; possibly M if a node was missing; possibly add data) -->
<!-- (4) assess "robustness" of findings - point to discussion of this in answer strategy (or move it here) (change A) -->
<!-- (5) update M based on new research and assess what d can tell us from this study (change M and possibly I, possibly A to fit changed M and I) -->
<!-- how can we assess the properties of a *reanalysis*? diagnose changed MIDA. important to not condition on d, the design includes the actual D, and we need to consider what results d' we would get from the reanalysis under different realizations of D. -->
<!-- there are now two A's, so need to specify a decision function about how to integrate the two findings. this could be throw away the old a, or combine them in some way. if it's a "robustness" to alternative A, then you may want to combine not throw out for example. it's crucial to specify how you do that, that's part of the answer strategy. -->
<!-- ## Example -->
<!-- Knox, Lowe, and Mummolo (2020) (https://www.cambridge.org/core/journals/american-political-science-review/article/administrative-records-mask-racially-biased-policing/66BC0F9998543868BB20F241796B79B8) study the statistical biases that accompany estimates of racial bias in police use of force when presence in the dataset (being stopped by police) is conditioned on an outcome that is a downstream consequence of race. They show the estimate is not identified unless additional modelling assumptions are brought to bear. -->
<!-- Gaebler et al. (2020) (https://5harad.com/papers/post-treatment-bias.pdf) study the same question and make such modeling assumptions (subset ignorability, definition 2). -->
<!-- In a twitter thread (https://twitter.com/jonmummolo/status/1275790509647241222?s=20), Mummolo shows the three DAGs that are compatible with subset ignorability. We agree with Mummolo that these DAGs assume away causal paths that are very plausible. -->
<!-- ![DAG](figures/mummolo_dag.png) -->
<!-- This document provides a design declaration for this setting and shows how estimates of the controlled direct effect (effect of race on force among the stopped) are biased unless those paths are set to zero by assumption. -->
<!-- Design Declaration -->
<!-- There are four variables: (D: minority, M: stop, U: suspicion (unobserved), Y: force) and five paths: -->
<!-- ```{r} -->
<!-- D_M = 1 # effect of minority on stop -->
<!-- U_M = 1 # effect of suspicion on stop -->
<!-- D_Y = 1 # effect of minority on force -->
<!-- U_Y = 1 # effect of suspicion on force -->
<!-- M_Y = 1 # effect of stop on force -->
<!-- ``` -->
<!-- This basic design allows all five paths. -->
<!-- ```{r} -->
<!-- design_1 <- -->
<!--   declare_population(N = 1000, -->
<!--                      D = rbinom(N, size = 1, prob = 0.5), -->
<!--                      U = rnorm(N)) + -->
<!--   declare_potential_outcomes(M ~ rbinom(N, size = 1, prob = pnorm(D_M * -->
<!--                                                                     D + U_M * U)), -->
<!--                              assignment_variable = "D") + -->
<!--   declare_reveal(M, D) + -->
<!--   declare_potential_outcomes(Y ~ rnorm(N, D_Y * D + M_Y * M + U_Y * U), -->
<!--                              conditions = list(D = c(0, 1), M = c(0, 1))) + -->
<!--   declare_reveal(outcome_variables = "Y", -->
<!--                  assignment_variables = c("D", "M")) + -->
<!--   declare_estimand(CDE = mean(Y_D_1_M_1 - Y_D_0_M_1)) + -->
<!--   declare_estimator(Y ~ D, subset = M == 1, estimand = "CDE") -->
<!-- ``` -->
<!-- We redesign the design 3 times, removing one path at a time, then simulate all four designs. -->
<!-- ```{r, message=FALSE} -->
<!-- # no effect of D on M -->
<!-- design_2 <- redesign(design_1, D_M = 0) -->
<!-- # no effect of U on M -->
<!-- design_3 <- redesign(design_1, U_M = 0) -->
<!-- # no effect of U on Y -->
<!-- design_4 <- redesign(design_1, U_Y = 0) -->
<!-- ``` -->
<!-- This chunk is set to `echo = TRUE` and `eval = do_diagnosis` -->
<!-- ```{r, eval = do_diagnosis & !exists("do_bookdown")} -->
<!-- simulations <- simulate_designs(design_1, design_2, design_3, design_4, sims = sims) -->
<!-- ``` -->
<!-- Right after you do simulations, you want to save the simulations rds. -->
<!-- ```{r, echo = FALSE, purl = FALSE} -->
<!-- # figure out where the dropbox path is, create the directory if it doesn't exist, and name the RDS file -->
<!-- rds_file_path <- paste0(get_dropbox_path("policing"), "/simulations_policing.RDS") -->
<!-- if (do_diagnosis & !exists("do_bookdown")) { -->
<!--   write_rds(simulations, path = rds_file_path) -->
<!-- } -->
<!-- simulations <- read_rds(rds_file_path) -->
<!-- ``` -->
<!-- ```{r, echo=FALSE, message = FALSE} -->
<!-- simulations <- -->
<!--   simulations %>% -->
<!--   mutate(`Assumed DAG` = factor( -->
<!--     design_label, -->
<!--     levels = c("design_1", "design_2", "design_3", "design_4"), -->
<!--     labels = c( -->
<!--       "All paths possible", -->
<!--       "no effect of D on M", -->
<!--       "no effect of U on M", -->
<!--       "no effect of U on Y" -->
<!--     ) -->
<!--   )) -->
<!-- summary_df <- -->
<!--   simulations %>% -->
<!--   group_by(`Assumed DAG`) %>% -->
<!--   summarise( -->
<!--     mean_estimand = mean(estimand), -->
<!--     mean_estimate = mean(estimate), -->
<!--     bias = mean(estimate - estimand) -->
<!--   ) %>% -->
<!--   pivot_longer(cols = c("mean_estimand", "mean_estimate")) -->
<!-- ``` -->
<!-- This plot confirms that unless one of those implausible assumptions hold, estimates of the CDE are biased. -->
<!-- ```{r, echo=FALSE} -->
<!-- ggplot(simulations, aes(estimate)) + -->
<!--   geom_histogram(bins = 50) + -->
<!--   geom_vline(data = summary_df, aes(xintercept = value, color = name)) + -->
<!--   facet_wrap(~`Assumed DAG`) + -->
<!--   xlab("Simulated CDE estimates") + -->
<!--   theme_bw() + -->
<!--   theme(legend.position = "bottom", -->
<!--         strip.background = element_blank(), -->
<!--         axis.title.y = element_blank(), -->
<!--         legend.title = element_blank()) -->
<!-- ``` -->
<!-- ### Grab bag -->
<!-- - @Clemens2017 on taxonomy of these kinds of efforts -->
<!-- - if you're going to use d to learn about a different M for a different I, you need to understand their D -->

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
<!-- start post here, do not edit above -->
</div>
<div id="replication" class="section level2">
<h2>
<span class="header-section-number">24.3</span> Replication<a class="anchor" aria-label="anchor" href="#replication"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>After your study is completed, it may one day be replicated. Replication differs from reanalysis in that a replication study involves the specification of a new MIDA and collection of new data to study the same inquiry. As discussed in the previous, a reanalysis may re-specify parts of the research design, but always re-uses the original data <span class="math inline">\(d\)</span> in some way.</p>
<p>So-called “exact” replications hold key features of I, D, and A fixed, but draw a new dataset <span class="math inline">\(d_{\rm new}\)</span> from <span class="math inline">\(D()\)</span> and apply the same <span class="math inline">\(A\)</span> to the new <span class="math inline">\(d\)</span> in order to produce a fresh answer <span class="math inline">\(a_{\rm new}^D\)</span>. Replications are said to “succeed” when <span class="math inline">\(a_{\rm old}^D\)</span> and <span class="math inline">\(a_{\rm new}^D\)</span> are similar and to “fail” when they are not. Dichotomizing replication attempts into successes and failures is usually not that helpful, and it would be better to simply characterize how similar <span class="math inline">\(a_{\rm old}^D\)</span> and <span class="math inline">\(a_{\rm new}^D\)</span> are.</p>
<p>Of course, exact replication is impossible: at least some elements of M have changed between the first study and the replication. Specifying how they might have changed, e.g., how outcomes vary with time, will help judge differences observed between <span class="math inline">\(a_{\rm old}^D\)</span> and <span class="math inline">\(a_{\rm new}^D\)</span>. Statistical noise will also play a role.</p>
<p>Replication studies benefit enormously from the knowledge gains produced by the original studies. For example, we learn a large amount about <span class="math inline">\(M\)</span> and the likely value of <span class="math inline">\(a^M\)</span> from the original study. The <span class="math inline">\(M\)</span> of the replication study can and should incorporate this new information. For example, if we learn from the original study that <span class="math inline">\(a^M\)</span> is positive but it might be small, the replication study could respond by changing <span class="math inline">\(D\)</span> in order to increase the sample size. Design diagnosis can help you learn about how to change the design of the replication study in light of the original study.</p>
<p>When changes to <span class="math inline">\(D\)</span> or <span class="math inline">\(A\)</span> can be made to produce more informative answers about the same <span class="math inline">\(I\)</span>, exact replication may not be preferred. Holding the treatment and outcomes the same may be required to provide an answer to the same <span class="math inline">\(I\)</span>, but increasing the sample size or sampling individuals rather than villages or other changes may be preferable to exact replication. Replication designs can take advantage of new best practices in research design.</p>
<p>When designing <strong>original</strong> studies, you should anticipate that someday your work will be replicated. This improves your <em>ex ante</em> incentives. To the extent that you want future replication studies to arrive similar answers to the original study you produce (i.e., you want their <span class="math inline">\(a_{\rm new}^D\)</span> to match your <span class="math inline">\(a_{\rm old}^D\)</span> as closely as possible), you will want to choose designs that bring <span class="math inline">\(a_{\rm old}^D\)</span> as close to <span class="math inline">\(a^M\)</span> as possible, under the presupposition that faithful replicators will also design their studies in such a way that <span class="math inline">\(a_{\rm new}^D\)</span> will also be close to <span class="math inline">\(a^M\)</span>.</p>
<p>Replication studies necessarily differ from original studies – it is literally impossible to reproduce the exact conditions of the original study in the same way it’s impossible to step in the same river twice. Another way of putting that same statement is that <span class="math inline">\(D_{\rm new}\)</span> is necessarily different from <span class="math inline">\(D_{\rm old}\)</span>. Theory (i.e., beliefs about <span class="math inline">\(M\)</span>) is the tool we use to say that <span class="math inline">\(D_{\rm old}\)</span> is similar enough to <span class="math inline">\(D_{\rm new}\)</span> to constitute a close enough replication study. As a concrete example, many survey experimental replications involve using the exact same experimental stimuli but changing the study sample, e.g., from a nationally representative sample to a convenience sample.</p>
<p>So-called “conceptual” replications alter both <span class="math inline">\(M\)</span> and <span class="math inline">\(D\)</span>, but keep <span class="math inline">\(I\)</span> and <span class="math inline">\(A\)</span> as similar as possible. That is, a conceptual replication tries to ascertain whether a relationship in one context (<span class="math inline">\(I(M_{\rm old})\)</span>) also holds in a new context (<span class="math inline">\(I(M_{\rm new}\)</span>). The trouble and promise of conceptual replications lies in the success of the designer at holding <span class="math inline">\(I\)</span> constant. Too often, a conceptual replication fails because in changing <span class="math inline">\(M\)</span>, too much changes about <span class="math inline">\(I\)</span> such that too much changes about the “concept” under replication.</p>
<p>There should be a summary function for how to interpret the difference between <span class="math inline">\(a_{\rm old}^D\)</span> and <span class="math inline">\(a_{\rm new}^D\)</span>. This may take the new one and throw out the old if MIDA was poor in the first. It may be taking the average. It may be a precision-weighted average. Specifying this function ex ante may be useful, to avoid the choice of summary depending on the results of the replication. This summary function will be reflected in A and in the discussion section of the replication paper.</p>
<p><strong>Further reading</strong>.</p>
<ul>
<li>
<span class="citation">Clemens (<a href="references.html#ref-Clemens2017" role="doc-biblioref">2017</a>)</span> on distinctions between replication and reanalysis</li>
</ul>
<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book--><!-- start post here, do not edit above -->
</div>
<div id="resolving-disputes" class="section level2">
<h2>
<span class="header-section-number">24.4</span> Resolving Disputes<a class="anchor" aria-label="anchor" href="#resolving-disputes"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<!-- The problem: Acrimonious debates arise; Hard to interpret contribution of replication and reanalysis; First main task (accumulation of knowledge) damaged. -->
<!-- The solution: Some of this comes down to basic disagreements we can't resolve. But some of it comes down to a lack of principles guiding how design decisions are made and how the results they produce should be interpreted. And a lack of procedures for understanding the consequences of decisions. -->
<!-- - Principles for making design choices, tailored to the distinct challenges posed to reanalysis and to replication -->
<!-- - Some changes are justifiable / encouraged, some things are not justifiable / discouraged, conditions for justification are clarified -->
<!-- - Procedures for putting principles into practice  -->
<!-- - Declaration and diagnosis through DD -->
<!-- Current practice for replication is to exactly replicate data strategy and analysis strategy in new or same context. This is not needed! Standard should be: best answer to same inquiry in new or same context! But how can we justify changes to D and A that give a "better" answer to same inquiry? -->
<p>Disputes arise when reanalyses and replication studies are conducted and claims are made about the past studies or what we learn from the pair. The realized data from the two studies, <span class="math inline">\(d\)</span> and <span class="math inline">\(d^{\prime}\)</span>, as well as the two designs <span class="math inline">\(MIDA\)</span> and <span class="math inline">\(MIDA^{\prime}\)</span>, together inform what we learn from the two studies. Disputes arise over whether changes to <span class="math inline">\(M^{\prime}\)</span>, <span class="math inline">\(I^{\prime}\)</span>, <span class="math inline">\(D^{\prime}\)</span>, or <span class="math inline">\(A^{\prime}\)</span> in the new study mean <span class="math inline">\(d^{\prime}\)</span> can be informative about the original <span class="math inline">\(I\)</span>.</p>
<p><span class="math inline">\(M\)</span> always changes. When a reanalysis or replication is conducted after the original study, we have by definition learned at least about <span class="math inline">\(a^w\)</span> from <span class="math inline">\(a^d\)</span> in the first study. We often have learned much more, about the distribution of variables, the existence of new nodes and edges, and sometimes much more when other related studies have been published in between. However, the original author may not agree with <em>how</em> the new author updated <span class="math inline">\(M\)</span>. These disputes are substantive.</p>
<p>We offer five rules for resolving disputes about changes to <span class="math inline">\(I\)</span>, <span class="math inline">\(D\)</span>, and <span class="math inline">\(A\)</span>.</p>
<p>Replacing them with alternative practices justified by design simulation
1. M always changes! (you have more information on <span class="math inline">\(\tau\)</span> or <span class="math inline">\(sd(\tau)\)</span>)
2. Home ground dominance: Change A or D-and-A if A<span class="math inline">\(^\prime\)</span> &gt; A under M
3. Robustness to alternative models: Change A or D-and-A if A<span class="math inline">\(^\prime\)</span> <span class="math inline">\(\geq\)</span> A under M AND A<span class="math inline">\(^\prime\)</span> &gt; A under M<span class="math inline">\(^\prime\)</span> E.g. change from simple to complete RA
4. Model plausibility: If A<span class="math inline">\(^\prime\)</span> &lt; A under M AND A<span class="math inline">\(^\prime\)</span> &gt; A under M<span class="math inline">\(^\prime\)</span>, then change to A<span class="math inline">\(^\prime\)</span> or D-and-A IFF M<span class="math inline">\(^\prime\)</span> is more plausible than M E.g. switching to balanced design if you believe variances equal across treatment groups
5. Undefined inquiries. Change I to I<span class="math inline">\(^\prime\)</span> if I is undefined under M If I is defined under M: You can’t change to I<span class="math inline">\(^\prime\)</span>, You can’t change D to D<span class="math inline">\(^\prime\)</span> if that means I unidentifiable.</p>
<!-- Disorganized thoughts: -->
<!-- - Changes to D include both interventions (sampling and randomization), as well as the inclusion of different / new datasets on the same model (this is common in econ reanalyses at state-level). The collection of "different" data through a change in question wording also fits into this. Need to think about a good typology of data strategies. -->
<!-- - There’s often a broader research question that’s being answered, and when I changes sometimes both are answering the same broader question. But focuses debate on whether that claim is true that I and I’ answer the same broader I.  -->
<!-- - In replication can you use data from study 1 to assess the plausibility of M? -->
<!-- - When does changing outcomes change the inquiry? -->
<!-- Example: you used z-scores in your original analysis in order to measure an effect on five different measures of some latent construct. I show that taking a simple average has better properties (e.g., statistical power), and use this instead of z-score. Have I changed estimand? If so, are there any instances of "recoding" or even "rewording" of outcome measures that we would be OK with, insofar as they get better answers to the inquiry without changing the inquiry? -->
<!-- One way of looking at this: inquiry is in reference to summary of a latent variable, which stays constant, but D changes which is different measurement of the latent variable -->
<!-- Point to keep in mind from this: D change might be in sampling/treat assignment or measurement -->
<!-- Key thing we are saying here: there are two dimensions of change with measurement. (1) are you changing estimands because the latent construct is changing implicitly; (2) are you changing to a better/worse measurement of the same latent construct. -->

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
<!-- start post here, do not edit above -->
</div>
<div id="synthesis" class="section level2">
<h2>
<span class="header-section-number">24.5</span> Synthesis<a class="anchor" aria-label="anchor" href="#synthesis"><i class="fas fa-link"></i></a>
</h2>
<!-- make sure to rename the section title below -->
<p>One of the last, if not the last, stage of the lifecycle of a research design is its eventual incorporation in to our common scientific understanding of the world. Research findings about specific Is – specific <span class="math inline">\(a^D\)</span>s need to be synthesized into our broader scientific understanding. A research synthesis comprises a new research design that summarizes past research.</p>
<p>Research synthesis takes two basic forms. The first is meta-analysis, in which a series of <span class="math inline">\(a^D\)</span>s are analyzed together in order to better understand features of the distribution of answers obtained in the literature. Traditional meta-analysis typically focuses on the average of k answers: <span class="math inline">\(a_1^D\)</span>,<span class="math inline">\(a_2^D\)</span>,…<span class="math inline">\(a_k^D\)</span>. Studies can be averaged together in many ways that are better and worse. Sometimes the answers are averaged together according to their precision – a precision weighted average of estimates from many studies is equivalent to fixed-effects meta-analysis. Sometimes studies are “averaged” by counting up how many of the estimates are positive and significant, how many are negative and significant, and how many are null. This is the typical averaging approach taken in a literature review. Regardless of the averaging approach, the goal of this kind of synthesis is to learn as much as possible about a particular <span class="math inline">\(I\)</span> by drawing on evidence from many studies.</p>
<p>A second kind of synthesis is an attempt to bring together many <span class="math inline">\(a^D\)</span>, each of which targets a different inquiry about a common model. This is the kind of synthesis that takes place across an entire research literature. Different scholars focus on different nodes and edges of the common model, so a synthesis needs to incorporate the diverse sources of evidence.</p>
<p>How can you best anticipate how your research findings will be synthesized? For the first kind of synthesis – meta-analysis – you must be cognizant of keeping a commonly understood <span class="math inline">\(I\)</span> in mind. You want to select inquiries not for their novelty, but because of their commonly-understood importance. We want <em>many</em> studies on the effects of having women versus men elected officials on public goods because we want to understand this particular <span class="math inline">\(I\)</span> in great detail and specificity. While the specifics of the model <span class="math inline">\(M\)</span> might differ from study to study, the fact that the <span class="math inline">\(I\)</span>s are all similar enough to be synthesized allows for a specific kind of knowledge accumulation.</p>
<p>For the second kind of synthesis – literature-wide progress on a full causal model – even greater care is required. Specific studies cannot make up bespoke models <span class="math inline">\(M\)</span> but instead must understand how the specific <span class="math inline">\(M\)</span> adopted in the study is a special case of some master <span class="math inline">\(M\)</span> that is in principle agreed to by a wider research community. The nonstop, neverending proliferation of study-specific theories is a threat to this kind of knowledge accumulation.
<!-- (Cite cyrus on causal empiricism, that psych paper on crazy proliferation of theories). --></p>
<p>Declaring and diagnosing the properties of the meta design can be as informative as doing so in planning for an individual study. The first step of every research synthesis is the process of collecting past studies. Search strategies are sampling strategies, and they can be biased in the same ways as convenience samples of individuals. Conducting a Census of past literature on a topic is impossible: much research conducted is not published or not yet published. Selecting studies from major journals alone may induce additional publication bias in your sample. Collecting working papers and soliciting unpublished abandoned research on a topic are strategies to mitigate these risks. The choice of answer strategy for research synthesis is typically driven by assumptions about a model of how studies are related and how the contexts and units within them were selected. The model for declaring a research synthesis thus must include assumptions not only about how studies reach you as the synthesizer, but how the contexts and units were selected in those original studies. Diagnosis can help assess the conditions under which your analysis strategies will provide unbiased, efficient estimates of true effects either in a subset of contexts which were studies’r flagit()’(CONFUSED ABOUT “which were studies”) or about a broader population.</p>
<!-- A research synthesis is a "meta MIDA" -->
<!-- M: A model that subsumes portions of the sub Ms -->
<!-- I: This is a summary of all of the Is across the studies -->
<!-- D: This is the inclusion / exclusion criteria. Transformations of the study data. standardization. (sampling, measurement.) -->
<!-- A: things like random effects or fixed effects -->
<!-- $I_1 \approx I_2 \approx I_3$ -->
<!-- Not -->
<!-- $a^M_1 \approx a^M_2 \approx a^M_3$ -->
<!-- Meta-analysis can be used not just to guess about effects out-of-sample but also to re-evaluate effects in sample: https://declaredesign.org/blog/2018-12-11-meta-analysis.html -->
<!-- - don't select on DV -->
<!-- - select on high quality MIDAs (drop those with bias) -->
<!-- - precision weighting (accounting for the quality of the design indirectly!) -->
<!-- ## grab bag -->
<!-- -- systematic reviews are sign and significance, meta-analysis are point estimates -->

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
<!-- start post here, do not edit above -->
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="realization.html"><span class="header-section-number">23</span> Realization</a></div>
<div class="next"><a href="part-iv-exercises.html"><span class="header-section-number">25</span> Part IV Exercises</a></div>
</div></main><div id="on-this-page-nav" class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#integration"><span class="header-section-number">24</span> Integration</a></li>
<li><a class="nav-link" href="#archiving"><span class="header-section-number">24.1</span> Archiving</a></li>
<li><a class="nav-link" href="#reanalysis"><span class="header-section-number">24.2</span> Reanalysis</a></li>
<li><a class="nav-link" href="#replication"><span class="header-section-number">24.3</span> Replication</a></li>
<li><a class="nav-link" href="#resolving-disputes"><span class="header-section-number">24.4</span> Resolving Disputes</a></li>
<li><a class="nav-link" href="#synthesis"><span class="header-section-number">24.5</span> Synthesis</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="download-code" href="./integration.R"><i class="far fa-file-code"></i> Download R code</a></li>
          
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Research Design: Declare, Diagnose, Redesign</strong>" was written by Graeme Blair, Alexander Coppock, and Macartan Humphreys. </p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
