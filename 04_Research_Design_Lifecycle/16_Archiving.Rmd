---
title: "Archiving"
output: html_document
bibliography: ../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

# Integration

## Archiving

<!-- make sure to rename the section title below -->

```{r archiving, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```

One of the biggest successes in the push for greater research transparency has been changing norms surrounding the sharing of data and analysis code after studies have been published. It has been become de rigeur at many journals to post these materials at publicly-available repositories like the OSF or Dataverse. This development is undoubtedly a good thing. In older manuscripts, sometimes data or analyses are described as being "available upon request" but of course such requests are sometimes ignored. Furthermore, a century from now, study authors will no longer be with us even if they wanted to respond to such requests. Public repositories have a much better chance of preserving study information for the future.

<!-- That's the promise of publicly-posted replication archives, but the mundane reality of replication archives often falls short. We see many archives that are disorganized, poorly documented, and contain dozens of bugs and inconsistencies.  -->

What belongs in a replication archive? First, the data $d$ itself. Sometimes this is the raw data, sometimes it is only the "cleaned" data that is actually called by analysis scripts. Where ethically possible, we think it is preferable to post as much of the raw data as possible, for example after removing information like IP address or geographic location that could be used to identify a subject. We usually consider data processing scripts that clean and prepare data for analysis as part of the data strategy $D$ in the sense that they complete the measurement procedures laid out in $D$. Cleaning scripts might also be considered part of the answer strategy in the sense that they apply an interpretation to the data provided by the world. The output of cleaning scripts -- the cleaned data -- should be included in the replication archive as well.

Replication archives also include $A$, or the set of functions applied to $d$ that produce $a^D$. It is vitally important that the *actual* analysis code is archived because the natural-language descriptions of $A$ that are typically given in papers are imprecise. As a small example, many articles describe their answer strategies as "ordinary least squares" but do not fully describe the set of covariates used or what flavor of standard errors was estimated. These differences can substantively affect the quality of the research design. The actual analysis code makes $A$ explicit.

While typical replication archives include $d$ and $A$, we think that future replication archives should also include a design declaration that fully describes $M$, $I$, $D$, and $A$ -- that is, we should archive designs, not just data and analysis code. This should be done in code and words. In addition, a diagnosis should be included, demonstrating the properties as understood by the author and also indicating the diagnosands that the author considered in judging the quality of the design.

<!-- Figure \@ref(fig:filestructure)  -->
The Figure below shows the file structure for an example replication. Our view on replication archives shares much in common with the TIER protocol, which can be found here: https://www.projecttier.org/. It includes raw data in a platform-independent format (.csv) and cleaned data in a language-specific format (.rds), so that data features like labels, attributes, and factor levels are preserved when imported by the analysis scripts. The analysis scripts are labeled by the outputs they create, such as figures and tables. A master script is included that runs the cleaning and analysis scripts in the correct order. The documents folder includes the paper, the supplemental appendix, the pre-analysis plan, the populated analysis plan, and codebooks that describe the data. A README file explains each part of the replication archive. We also suggest that authors include a script that includes a design declaration and diagnosis. 

![File structure for archiving\label{filestructure}](figures/file_structure.png)


<!-- Example is archive at OSF: https://osf.io/4vuqh -->
