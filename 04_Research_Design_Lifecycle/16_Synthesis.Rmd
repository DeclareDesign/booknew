---
title: "Synthesis"
output: html_document
bibliography: ../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

## Synthesis

<!-- make sure to rename the section title below -->

```{r synthesis, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```


One of the last, if not the last, stage of the lifecyle of a research design is its eventual incorportation in to our common scientific understanding of the world. Research findings about specific Is -- specific $a^D$s need to be synthesized into our broader scientific understanding. A research synthesis comprises a new research design that summarizes past research.

Research synthesis takes two basic forms. The first is meta-analysis, in which a series of $a^D$s are analyzed together in order to better understand features of the distribution of answers obtained in the literature. Traditional meta-analysis typically focuses on the average of k answers: $a_1^D$,$a_2^D$,...$a_k^D$. Studies can be averaged together in many ways that are better and worse. Sometimes the answers are averaged together according to their precision -- a precision weighted average of estimates from many studies is equivalent to fixed-effects meta analysis. Sometimes studies are "averaged" by counting up how many of the estimates are positive and significant, how many are negative and significant, and how many are null. This is the typical averaging approach taken in a literature review. Regardless of the averaging approach, the goal of this kind of synthesis is to learn as much as possible about a particular $I$ by drawing on evidence from many studies.

A second kind of synthesis is an attempt to bring together many $a^D$, each of which targets a different inquiry about a common model. This is the kind of synthesis that takes place across an entire research literature. Different scholars focus on different nodes and edges of the common model, so a synthesis needs to incorporate the diverse sources of evidence.

How can you best anticipate how your research findings will be synthesized? For the first kind of synthesis -- meta-analysis -- you must be cognizant of keeping a commonly understood $I$ in mind. You want to select inquiries not for their novelty, but because of their commonly-understood importance. We want *many* studies on the effects of having women versus men elected officials on public goods because we want to understand this particular $I$ in great detail and specificity. While the specifics of the models $M$ might differ from study to study, the fact that the $I$s are all similar enough to be synthesized allows for a specific kind of knowledge accumulation.

For the second kind of synthesis -- literature-wide progress on a full causal model -- even greater care is required. Specific studies cannot make up bespoke models $M$ but instead must understand how the specific $M$ adopted in the study is a specical case of some master $M$ that is in principle agreed to by a wider research community. The nonstop, neverending proliferation of study-specific theories is a threat to this kind of knowledge accumulation. 
<!-- (Cite cyrus on causal empiricism, that psych paper on crazy proliferation of theories). -->

Declaring and diagnosing the properties of the meta design can be as informative as doing so in planning for an individual study. The first step of every research synthesis is the process of collecting past studies. Search strategies are sampling strategies, and they can be biased in the same ways as convenience samples of individuals. Conducting a Census of past literature on a topic is impossible: much research conducted is not published or not yet published. Selecting studies from major journals alone may induce additional publication bias in your sample. Collecting working papers and soliciting unpublished abandoned research on a topic are strategies to mitigate these risks. The choice of answer strategy for research synthesis is typically driven by assumptions about a model of how studies are related and how the contexts and units within them were selected. The model for declaring a research synthesis thus must include assumptions not only about how studies reach you as the synthesizer, but how the contexts and units were selected in those original studies. Diagnosis can help assess the conditions under which your analysis strategies will provide unbiased, efficient estimates of true effects either in a subset of contexts which were studies or about a broader population.

<!-- A research synthesis is a "meta MIDA" -->

<!-- M: A model that subsumes portions of the sub Ms -->
<!-- I: This is a summary of all of the Is across the studies -->
<!-- D: This is the inclusion / exclusion criteria. Transformations of the study data. standardization. (sampling, measurement.) -->
<!-- A: things like random effects or fixed effects -->


<!-- $I_1 \approx I_2 \approx I_3$ -->

<!-- Not -->

<!-- $a^M_1 \approx a^M_2 \approx a^M_3$ -->


<!-- Meta-analysis can be used not just to guess about effects out-of-sample but also to re-evaluate effects in sample: https://declaredesign.org/blog/2018-12-11-meta-analysis.html -->

<!-- - don't select on DV -->
<!-- - select on high quality MIDAs (drop those with bias) -->
<!-- - precision weighting (accounting for the quality of the design indirectly!) -->




<!-- ## grab bag -->

<!-- -- systematic reviews are sign and significance, meta-analysis are point estimates -->
