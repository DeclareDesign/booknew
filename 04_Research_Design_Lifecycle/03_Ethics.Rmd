---
title: "Ethics"
output: html_document
bibliography: ../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->
# Planning

[To be written: Planning introduction]

From when the idea is real (after brainstorming, we have a MIDA) all the way up to PAP.


## Ethics

<!-- make sure to rename the section title below -->

```{r ethics, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```

As researchers, we have ethical obligations beyond the requirements of national laws and the regulations of institutional review boards. The considerations at play in any particular study vary from context to context. For example, @slough2020ethics considers the ethics of field experimentation in the context of elections, and @wood2006ethical addresses the ethical encumbrances specific to interview-based field research in conflict zones. Despite the ethical heterogeneity across research projects, the common ethical principles laid out in the Belmont report -- respect for persons, beneficence, and justice -- apply across designs and research modes.

As conceptions of how to follow these principles evolve, however, the standards to which research communities hold their members also shift. For example, journal editors and peer reviewers have begun to request ethical appendices, and the ethical status of studies is regularly discussed in public academic forums.

Most design declarations and diagnoses elide ethical considerations. For instance, a declaration that is diagnosand-complete for statistical power may tell you little about the level of care and respect accorded to subjects. Many declarations are diagnosand-complete for bias, but obtaining an unbiased treatment effect estimate is not always the highest goal. When obtaining a credible answer would come at too high an ethical cost, the study may need to be scrapped altogether.

However, ethical diagnosands can be (and we think should be!) directly incorporated into the declare-diagnose-redesign framework. Diagnosands could include the total cost to participants, how many participants were harmed, the average level of informed consent measured by a survey about comprehension of study goals, or the risks of adverse events. More complex ethical diagnosands are possible as well: @slough2020ethics provides a formal analysis of the "aggregate electoral impact" diagnosand for experiments that take place in the context of elections. We consider two specific ethical diagnosands here, costs and potential harms, though many others may apply in particular research scenarios.

**Costs.** A common concern is that measurement imposes a cost on subjects, if only by wasting their time. Subjects' time is a valuable resource they often donate willingly to the scientific enterprise by participating in a survey or other measurement. Although subjects' generosity is sometimes repaid with financial compensation, in many scenarios direct payments are not feasible. Regardless of whether subjects are paid, the costs to subjects should be top of mind when designing the study.

**Potential harms.** Different realizations of the data from the same data strategy may differ in their ethical status. Ex-post, a study may not have ended up harming subjects, but ex-ante, there may have been a risk of harm [@young2020]. The project's ethical status depends on judgments about *potential* harms and *potential* participants: not only what did happen, but what could have happened. The potential harm diagnosand might be formalized as the maximum harm that could eventuate under any realization of the data strategy. Researchers could then follow a minimax redesign procedure to find the design that minimizes this maximum potential harm.

When the design is diagnosed, we can characterize the ethical status of possible realizations of the design. The first way these ethical diagnosands can be used is to determine whether the study design meets a set of ethical thresholds. Is the probability of harm minimal enough? Is the average level of informed consent sufficient? Given that these characteristics vary across designs and across realizations of the same design, writing down concretely both the measure of the ethical status and the ethical threshold can help structure thinking. These diagnoses and the considerations that inspire them can be shared in funding proposals, preanalysis plans, or other report.

Often, once an ethical threshold is met, we select among feasible designs based on research design criteria such as statistical power and bias. This approach has appeal since we should only implement designs that meet the relevant research community's ethical standards. However, dichotomizing designs into "ethical" and "unethical" is a difficult task in general. Instead, we should continue to assess ethical considerations alongside the quality of the research design. Even among ethical designs, we still face tradeoffs between how much time is asked of subjects and the risk of harm. We should select designs that weigh these considerations (perhaps highly!) against other desiderata. A difficult challenge in this process is that we have to measure the two on a common scale to weigh ethical criteria against other diagnosands such as power and cost. 

**Further readings**. 

- @humphreys2015reflections
- @teele2020
- @meyer2015two
- @luft2020you
- @young2020
- @lyall2020
- @slough2020ethics
- @wood2006ethical
- [American Political Science Association ethics guidelines](https://www.apsanet.org/Portals/54/diversity%20and%20inclusion%20prgms/Ethics/Final_Principles%20with%20Guidance%20with%20intro.pdf?ver=2020-04-20-211740-153)
- [American Sociological Association Code of Ethics](https://www.asanet.org/sites/default/files/asa_code_of_ethics-june2018.pdf)
- [American Psychological Association Ethical Principles of Psychologists and Code of Conduct](https://www.apa.org/ethics/code)

<!-- By declaring your expectations about the ethical outcomes of an experiment in terms of diagnosands such as the time participants devote to the study and the probability of harm to individuals, a declared research design can be an input to ethical reporting. Readers can review how you considered ethical outcomes in your design and judge the mitigation efforts you undertook in relation to those expectations. Other scholars have proposed including ethical assessments in preanalysis plans. Declarations of ethical diagnosands are a natural complement to these preregistered assessments. -->


<!-- ### Illustration: Estimating expected costs and expected learning  -->

<!-- <!-- I would prefer to have an example where there is consent but people are willing to tkae part because they value the outcome --> 

<!-- We illustrate how researchers can weigh the tradeoffs between the value of research and its ethical costs with an audit study of discrimination in government hiring. The characteristics of applicants to a municipal government job are randomized. The rate of callbacks for a job interview are compared across applicant characteristics. We consider three different inquiries that could be studied with the design: the hiring rate for job applications from a Black applicant and a White applicant; the hiring rate between someone from the local area vs. someone equally qualified who lives far away; and the rates between someone who went to East High School and someone who went to West High School in town. We judge the questions to rank in importance between high (the question of racial discrimination), medium (local favoratism), and low (personal interest). The value of the research is a function of the importance of the inquiry, but also how much we learn about it. We proxy for the learning from the experiment by sample size: the higher the $N$, the more we learn, but with decreasing marginal returns (it's a lot better to have a sample of 100 compared to 10; it matters less if it 1010 or 1100). Figure \@ref(fig:ethicsplot) shows the three research value curves labeled by the importance of the inquiry. -->

<!-- Because the job applicants are fictitious but appear real, a primary ethical concern in audit experiments is how much time hiring managers (the participants in the research) spend reviewing the fictitious applications. In the case of government hiring, it is public money spent on their review. The time cost to participants is linear in the number of applications: each application takes about ten minutes to review, regardless of how many are sent. We represent the cost to participants as the purple line in Figure \@ref(ethicsplot).  -->

<!-- We have placed the costs to participants on the same scale as the value of the research, by placing a value to society of the research and the value to society of the time of the hiring managers. When benefit exceeds cost (upper blue region), we decide to move forward with the research; if costs exceed benefits (lower gray region), we do not conduct the study. -->

<!-- The conclusion of the graph is that for high-importance inquiries, it is almost always worth doing the study. We get a lot of value from the research, despite the costs to participants. However, there is a region at low sample sizes where the cost to participants exceed the benefits from the research, because of the very imprecise answers we get from the research. We don't learn enough about the inquiry, despite its importance, to make it worth wasting the hiring managers time. By contrast, for low importance inquiries, it is never worth conducting the study. The costs to participants always exceed the (low) value of the research. Medium importance questions are in the middle: there is a region of the benefits curve (highlighted in blue) where it is worth doing the study, but two regions (highlighted in gray) where it is not worth it. The left region is where the sample is too small so the value of the research is low both because of its medium importance and we do not learn enough about it. The second gray region at right in the medium importance curve is where though we learn a lot about the inquiry, the cost is too high from the many hours of hiring manager time to justify what we learn because the inquiry is not important enough.  -->

<!-- In short, ethical determinations require diagnosis both of how much we learn and how much it costs to participants (along with other ethical costs), and we must place a value on both ethical costs and research benefits in order to compare them on the same scale.  -->

<!-- ```{r ethicsplot, echo=FALSE, fig.cap = "Tradeoffs between ethical costs and scientific benefits. A design might have too *many* subjects but also too *few* subjects.", fig.height=5, fig.width=5} -->
<!-- dat <-  -->
<!--   tibble( -->
<!--     X = seq(1, 10, 0.001), -->
<!--     cost =  4* X + 6 , -->
<!--     high = log(X, base = 1.05), -->
<!--     med = log(X, base = 1.06), -->
<!--     low = log(X, base = 1.10) -->
<!--   )  -->

<!-- dat_long <- -->
<!--   dat %>%  -->
<!--   pivot_longer(c(high, med, low)) %>% -->
<!--   mutate(cost_benefit = if_else(value > cost, "A", "B")) -->

<!-- label_df <- -->
<!--   tibble( -->
<!--     X = c(9.9, 9.9, 9.9), -->
<!--     value = c(22, 36, 48), -->
<!--     label = c("Low", -->
<!--               "Medium", -->
<!--               "Inquiry importance: High"), -->
<!--     cost_benefit = c("B", "B", "A") -->
<!--   ) -->

<!-- ggplot(dat_long, aes(X)) + -->
<!--   geom_ribbon(data = dat, aes(ymax = cost, x = X, ymin = 0), fill = gray(0.8, alpha = 0.3)) +  -->
<!--   geom_ribbon(data = dat, aes(ymin = cost, x = X, ymax = 50), fill = "#72B4F344") +  -->
<!--   geom_line(aes(y = value, color = cost_benefit, group = name)) + -->
<!--   geom_line(data = dat, aes(y = cost), color = dd_pink) + -->
<!--   geom_text(data = label_df, aes(y = value, label = label, color = cost_benefit), hjust = 1) + -->
<!--   scale_color_manual("", values = c(dd_dark_blue, gray(0.5))) +  -->
<!--   annotate("text", x = 1.5, y = 42, label = "Scientific benefits exceed ethical costs", hjust = 0, color = dd_dark_blue) +  -->
<!--   annotate("text", x = 4, y = 7, label = "Ethical costs exceed scientific benefits", hjust = 0, color = dd_gray) +  -->
<!--   labs(x = "Sample size", y = "Costs and benefits") +  -->
<!--   dd_theme() + -->
<!--     theme(legend.position = "none", -->
<!--           axis.text = element_blank(), -->
<!--           panel.grid.major = element_blank()) -->

<!-- ``` -->

<!-- ### Illustration: Assessing risks of adverse events  -->

<!-- <!-- Tara like exampe of swinging an election --> 

<!-- * * * -->


<!-- - Is it the measurement they object to? Is it the random assignment?  -->

<!-- papers to cite here: the A/B illusion (Michelle Mayer); Cite APSA guidelines; preregistering ethics guidelines (Lyall paper); report on ethics in paper (Lauren Young's paper); Mac's paper; Belmont report -->


<!-- We must be able to think about the value to society of the research to weigh against the risks to participants and others. Similarly, we must be able to weigh more precise estimates of the same question against ethical considerations that also change based on the number of units and the proportion treated among other design features. By moving forward with research we must implicitly weigh these considerations. In IRB applications, we are often more directly asked to weigh the costs to subjects against the benefits of the research *to subjects* as well as to society as a whole. -->