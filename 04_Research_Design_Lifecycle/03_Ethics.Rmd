---
title: "Ethics"
output: html_document
bibliography: ../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->
# Planning

## Ethics

<!-- make sure to rename the section title below -->

```{r ethics, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```

Social scientists are also increasingly focused on meeting ethical standards that go beyond the requirements of these national laws. Ethical appendices are required by some journals describing protections for human subjects and many funding agencies now require defenses of the ethics of a research study before funds are disbursed.

Common ethical principles include respect for persons, beneficence (researchers must have the welfare of participants in mind in designing the research), informed consent by participants, and minimizing harm to participants and others. 

Ethical considerations extend well beyond the elements that are captured by a design declaration. For instance, a declaration of analytic relevant components of a design may tell you little about the level of care and respect accorded to subjects. Nevertheless, we think it useful to identify when design relevant features can be informative for ethical judgments. 

### Ethical principles as diagnosands

Researchers can use the declare-diagnose-redesign process to help inform some ethical judgments. In particular, a diagnostic-statistic could be defined for each relevant ethical criterion. For example, a design can be scored based on the total cost to participants, how many participants were harmed (i.e., how many were retraumatized by being asked out past experience with violence),  the average level of informed consent measured by a survey about comprehension of the study goals, or the risks of adverse events. 

Consider two examples.

**Costs.** A common concern is that measurement imposes a cost on subjects, if only by wasting their time. Subjects' time is a valuable resource -- they often donate willingly to the scientific enterprise by taking a survey or similar. Sometimes their generosity is repaid with financial compensation for their time. Sometimes subjects are unknowing participants in a research study because obtaining informed consent would so distort their behavior as to hinder the ability of the researchers to study it.

**Risks not just realizations.** More subtly, different realizations of the data from the same data strategy may also differ in their ethical status. As a result, the ethics of the study cannot only be determined by looking at what in fact happened during the study --- how many participants were there and how many were treated, how many were harmed, and how many raised complaints. Instead, the ethical status of the project depends on judgments about *potential* harms and *potential* participants: not only what did happen, but what could have happened.

<!-- tara's paper relevant here -->

When the design is diagnosed, then diagnosands can be constructed that summarize the level of ethical encumbrance across possible realizations of the design. The first way these ethical diagnosands can be used is to determine whether the study design meets a set of ethical thresholds. Is the probability of harm minimal enough? Is the average level of informed consent sufficient? Given that these characteristics vary across designs and across realizations of the same design, writing down concretely both what the measure of the ethical characteristic is and what the threshold is for the design to be ethical can help structure thinking. (These diagnoses and threshold determinations can also be shared in ethical writeups of the design.)

Among ethical designs, researchers must select a single design to implement. Often, once an ethical threshold is met, we select among feasible designs based on research design criteria such as statistical power and bias. Instead, we should continue to assess ethical considerations alongside the quality of the research design. Among ethical designs, there are still often tradeoffs between how much time is asked of subjects and the risk of harm. We should select the designs that weight these considerations (perhaps highly!) against the power of our designs. To do so, we can simply continue to include the diagnosands related to ethical criteria in our diagnoses and the redesign of studies. 

A difficult challenge in this process is that in order to weigh ethical criteria against research design criteria such as power and cost, we must put be able to measure the two on a common scale. We must be able to think about the value to society of the research to weigh against the risks to participants and others. Similarly, we must be able to weigh more precise estimates of the same question against ethical considerations that also change based on the number of units and the proportion treated among other design features. By moving forward with research we must implicitly weigh these considerations. In IRB applications, we are often more directly asked to weigh the costs to subjects against the benefits of the research *to subjects* as well as to society as a whole.

<!-- ### Illustration: Estimating expected costs and expected learning  -->

<!-- <!-- I would prefer to have an example where there is consent but people are willing to tkae part because they value the outcome --> 

<!-- We illustrate how researchers can weigh the tradeoffs between the value of research and its ethical costs with an audit study of discrimination in government hiring. The characteristics of applicants to a municipal government job are randomized. The rate of callbacks for a job interview are compared across applicant characteristics. We consider three different inquiries that could be studied with the design: the hiring rate for job applications from a Black applicant and a White applicant; the hiring rate between someone from the local area vs. someone equally qualified who lives far away; and the rates between someone who went to East High School and someone who went to West High School in town. We judge the questions to rank in importance between high (the question of racial discrimination), medium (local favoratism), and low (personal interest). The value of the research is a function of the importance of the inquiry, but also how much we learn about it. We proxy for the learning from the experiment by sample size: the higher the $N$, the more we learn, but with decreasing marginal returns (it's a lot better to have a sample of 100 compared to 10; it matters less if it 1010 or 1100). Figure \@ref(fig:ethicsplot) shows the three research value curves labeled by the importance of the inquiry. -->

<!-- Because the job applicants are fictitious but appear real, a primary ethical concern in audit experiments is how much time hiring managers (the participants in the research) spend reviewing the fictitious applications. In the case of government hiring, it is public money spent on their review. The time cost to participants is linear in the number of applications: each application takes about ten minutes to review, regardless of how many are sent. We represent the cost to participants as the purple line in Figure \@ref(ethicsplot).  -->

<!-- We have placed the costs to participants on the same scale as the value of the research, by placing a value to society of the research and the value to society of the time of the hiring managers. When benefit exceeds cost (upper blue region), we decide to move forward with the research; if costs exceed benefits (lower gray region), we do not conduct the study. -->

<!-- The conclusion of the graph is that for high-importance inquiries, it is almost always worth doing the study. We get a lot of value from the research, despite the costs to participants. However, there is a region at low sample sizes where the cost to participants exceed the benefits from the research, because of the very imprecise answers we get from the research. We don't learn enough about the inquiry, despite its importance, to make it worth wasting the hiring managers time. By contrast, for low importance inquiries, it is never worth conducting the study. The costs to participants always exceed the (low) value of the research. Medium importance questions are in the middle: there is a region of the benefits curve (highlighted in blue) where it is worth doing the study, but two regions (highlighted in gray) where it is not worth it. The left region is where the sample is too small so the value of the research is low both because of its medium importance and we do not learn enough about it. The second gray region at right in the medium importance curve is where though we learn a lot about the inquiry, the cost is too high from the many hours of hiring manager time to justify what we learn because the inquiry is not important enough.  -->

<!-- In short, ethical determinations require diagnosis both of how much we learn and how much it costs to participants (along with other ethical costs), and we must place a value on both ethical costs and research benefits in order to compare them on the same scale.  -->

<!-- ```{r ethicsplot, echo=FALSE, fig.cap = "Tradeoffs between ethical costs and scientific benefits. A design might have too *many* subjects but also too *few* subjects.", fig.height=5, fig.width=5} -->
<!-- dat <-  -->
<!--   tibble( -->
<!--     X = seq(1, 10, 0.001), -->
<!--     cost =  4* X + 6 , -->
<!--     high = log(X, base = 1.05), -->
<!--     med = log(X, base = 1.06), -->
<!--     low = log(X, base = 1.10) -->
<!--   )  -->

<!-- dat_long <- -->
<!--   dat %>%  -->
<!--   pivot_longer(c(high, med, low)) %>% -->
<!--   mutate(cost_benefit = if_else(value > cost, "A", "B")) -->

<!-- label_df <- -->
<!--   tibble( -->
<!--     X = c(9.9, 9.9, 9.9), -->
<!--     value = c(22, 36, 48), -->
<!--     label = c("Low", -->
<!--               "Medium", -->
<!--               "Inquiry importance: High"), -->
<!--     cost_benefit = c("B", "B", "A") -->
<!--   ) -->

<!-- ggplot(dat_long, aes(X)) + -->
<!--   geom_ribbon(data = dat, aes(ymax = cost, x = X, ymin = 0), fill = gray(0.8, alpha = 0.3)) +  -->
<!--   geom_ribbon(data = dat, aes(ymin = cost, x = X, ymax = 50), fill = "#72B4F344") +  -->
<!--   geom_line(aes(y = value, color = cost_benefit, group = name)) + -->
<!--   geom_line(data = dat, aes(y = cost), color = dd_pink) + -->
<!--   geom_text(data = label_df, aes(y = value, label = label, color = cost_benefit), hjust = 1) + -->
<!--   scale_color_manual("", values = c(dd_dark_blue, gray(0.5))) +  -->
<!--   annotate("text", x = 1.5, y = 42, label = "Scientific benefits exceed ethical costs", hjust = 0, color = dd_dark_blue) +  -->
<!--   annotate("text", x = 4, y = 7, label = "Ethical costs exceed scientific benefits", hjust = 0, color = dd_gray) +  -->
<!--   labs(x = "Sample size", y = "Costs and benefits") +  -->
<!--   dd_theme() + -->
<!--     theme(legend.position = "none", -->
<!--           axis.text = element_blank(), -->
<!--           panel.grid.major = element_blank()) -->

<!-- ``` -->

<!-- ### Illustration: Assessing risks of adverse events  -->

<!-- <!-- Tara like exampe of swinging an election --> 

<!-- * * * -->

Scholars are increasingly calling for reporting of ethical considerations in study design beyond IRB approval. By declaring your expectations about the ethical outcomes of an experiment in terms of diagnosands such as the time participants devote to the study and the probability of harm to individuals, a declared research design can be an input to ethical reporting. Readers can review how you considered ethical outcomes in your design and judge the mitigation efforts you undertook in relation to those expectations. Other scholars have proposed including ethical assessments in preanalysis plans. Declarations of ethical diagnosands are a natural complement to these preregistered assessments.

<!-- - Is it the measurement they object to? Is it the random assignment?  -->

<!-- papers to cite here: the A/B illusion (Michelle Mayer); Cite APSA guidelines; preregistering ethics guidelines (Lyall paper); report on ethics in paper (Lauren Young's paper); Mac's paper; Belmont report -->

**Further readings**. 

<!-- - history: belmont report. tuskegee experiment. stanford prison experiment.  -->
<!-- - laws and IRBs: revised common rule, paper on IRBs -->
<!-- - guidelines from econ, poli sci, soc, psych. -->

- @humphreys2015reflections
- @teele2020
- @meyer2015two
- @luft2020you
- @young2020
- @lyall2020
