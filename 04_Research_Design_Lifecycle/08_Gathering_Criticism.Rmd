---
title: "Criticism"
output:
  html_document: default
  pdf_document: default
bibliography: ../bib/book.bib
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

## Criticism 

<!-- make sure to rename the section title below -->

```{r criticism, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```

A vital part of the research design process is gathering criticism and feedback from others. Timing is delicate here. Asking for comments on a project that is underdeveloped can sometimes lead to brainstorming sessions about what research questions one might look into -- possibly quite useful, but essentially restarts the research design lifecycle from the begining. Sharing work only after a full draft has been produced is worse, since the data strategy will have already produced the realized data $d$. Feedback can only help a project so much if the fieldwork has already been conducted, the treatments have already been allocated, or the outcomes have already been measured. While critics can always suggest changes to $I$ and $A$ post-data collection, an almost-finished project is fundamentally constrained by the data strategy as it was implemented.

The best moments to seek advice come before the registration of preanalysis plans or, if not pre-registereing, before the implemation of major data strategy elements. The point is not to seek advice exclusively on sampling, assignment, or measurement procedures -- it's that when there's still time to modify those design elements, feedback about the design as a whole can inform changes to the data strategy. 

Feedback will come in many forms. Sometimes the comments are directly about diagnosands -- the critic may think the design has too many arms and so won't be well-powered for many inquiries. The critic may be concerned about bias due to excludability violations or selection issues. Other comments are harder to pin down. A fruitful exercise in such cases is to understand how the criticism fits in to M, I, D, and A. A comment like, "I'm concerned about external validity here" might seem to be about the data strategy -- since the units weren't randomly sampled from some well-specified population, we can't generalize from the sample to the population. But if the inquiry is not actually a population quantity, then this inability to use sample data to estimate a population quantity is irrelevant. Now the question is whether knowing the answer to your sample inquiry helps make theoretical progress, or whether we need to switch the inquiry to the population quantity in order to make headway. Critics will not usually specificy how their cricitism relates to M, I, D, or A, so it is up to the person seeking feedback to understand the implications of the criticism for the design.

Possibly the most common forum for feedback is the causal in-passing converation. Someone will ask you what you're working on -- "Oh, we're doing this cool RCT on the effect of PSAs on social norms" and they'll say "Oh neat, have you read [article they know about], it seems related." This kind of exchange is often more useful when you can quickly convey what you're trying to learn (your inquiry) and how you're trying to learn about it (your data and answer strategies) while in line for coffee or milling about before a talk. 

More formal settings include meetings with your advisor or colleagues in which you are specifically asking for help. In order to give good feedback, the advisor needs to understand M, I, D, and A -- so sending documents in advance that describe these elements is crucial.



TIMING


Before implimentations of D.

After implementations of D, and your levers are restricted to changes in A or I-- those are usually quite limited

WORKSHOP setting


don't defend yourself.
The point is not to defeed the research. The goal is to break it before implementation.

Learn to interpret criticism as changes to MIDA

you're saying to change to question

Telling me to do diffeerent analysis. How to tell whether to accept this criticms.

Too many arms
not enough data
I don't think that's how it works
wrong estimator
lots of excludability
dont by selection on obseervables
I already knew that
meansurement strategy not good for ystar
Spillovers
I dont care
This doesn't distinguish between theories (can you rule out alternatives)















- there is a silent piece in the declare-diagnose-redesign framework: getting outside advice on the design and diagnosis *before* implementation 
- most scientific criticism takes place ex post, when 
- why before? you can't change it afterward

- research design document

