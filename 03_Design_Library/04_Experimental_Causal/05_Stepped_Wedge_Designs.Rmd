---
title: "Stepped wedge designs"
output: html_document
bibliography: ../../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

## Stepped wedge designs

In a stepped wedge design, individuals are randomly assigned to enter into
treatment in different stages, and at each stage their outcomes are remeasured.
Figure \@ref(fig:stepped-wedge) illustrate where the study gets its name: 
as two units are randomly added to the treatment group in each of the three waves, 
the treatment group increases in "steps" while the control group diminishes.

Often, stepped wedge designs are vaunted for their policy appeal, because they allow for 
everyone to be (eventually) treated in the context of an experiment. Yet, that isn't a 
particularity of stepped wedge designs: you could achieve the same goal by treating everyone
in the control after the final wave of measurement in a regular two-armed trial!
The real advantage of the stepped wedge is not in its ethical appeal: it's the ability to 
squeeze more power out of a small sample by treating each wave as though it were its own
study. 

### Declaration

- **M**odel: the design has eight units randomized and remeasured at three time
points. Units' untreated potential outcomes consist of an unit- and a
unit-period-specific shock. Their treated potential outcome increases relative to their
control potential outcome by a rate of 1 each period.

- **I**nquiry: Since any unit at any given point in time reveals one of only two potential
outcomes, we can define our estimand simply as the average treatment effect. The ATE
averaged over the three periods is (1 + 2 + 3) / 3 = 2.

- **D**ata strategy: our assignment strategy adds two units (e.g., one-quarter of the total
sample) to the treatment at random in each wave, leaving two units who are not treated in
any wave---see the remaining two orange squares at the top-right corner of  Figure
\@ref(fig:stepped-wedge). Notice that, while every *unit* is assigned to a treatment wave
with equal probability, each wave reveals treated and untreated potential outcomes of 
*unit-periods* with different probabilities. In the first wave, one-quarter of the units 
reveal their treated potential outcomes; in the second wave, one-half of the units reveal
their treated potential outcomes, and in the final wave, three-quarters of the units 
reveal treated potential outcomes. In essence, our experiment is like a block-randomized
trial, with unit-periods grouped into wave blocks that have differential probabilities
of assignment.

- **A**nswer strategy: Just as in a block-randomized trial with differential probabilities,
we need to take account of the fact that our assignment strategy "under-represents"
treatment potential outcomes in early waves and "over-represents" treatment potential
outcomes in the last wave. Inverse-propensity weights (IPWs) are one way to correct for
such disparities. Each unit's IPW is represented on Figure \@ref(fig:stepped-wedge). But
what do the numbers mean, and why do they change from one wave to another? In a sampling
context, the IPW tells us how many units in the population each sampled unit represents. In
the experimental context, the treatment assignment literally randomly samples *potential
outcomes*. So, in the first wave, the two treated units each have to stand in for four
units' treated potential outcomes (4 + 4 = 8 units). The potential outcomes revealed by the
six units assigned to the control each stand in for 1.33 other units' potential outcomes
(1.33 + 1.33 + 1.33 + 1.33 + 1.33 + 1.33 = 8 units). Since the second wave is comprised of
one-half treated potential outcomes and one-half control potential outcomes, each unit
represents two other units' potential outcomes. Using these weights, we get a
"representative" estimate of the average control and treatment potential outcomes in each
wave. If we didn't apply the weights, we wouldn't get a representative view of the
unobserved potential outcomes we're sampling, and our estimates would be biased. So what
does all this buy us? We also declare a "two-arm" estimator that focuses on wave 2 only,
where half of the units are in control and half in treatment. Diagnosis shows that the
stepped wedge has (.52 - .41) / .41 = 27% higher power!


```{r}
design <- 
  declare_population(
    unit = add_level(N = 8, X = rnorm(N)),
    period = add_level(N = 3, time = as.numeric(period), 
                       p = c(1/4, 1/4 + 1/4, 1/4 + 1/4 + 1/4), 
                       nest = FALSE),
    obs = cross_levels(by = join(unit, period), U = rnorm(N))) + 
  declare_potential_outcomes(Y ~ X + U + Z * time) +
  declare_assignment(clusters = unit, conditions = 1:4, assignment_variable = "wave") + 
  declare_assignment(Z = as.numeric(time >= wave), ipw = 1 / (Z * p + (1 - Z) * (1 - p)), handler = fabricate) + 
  declare_reveal(Y, Z) + 
  declare_estimand(ATE = mean(Y_Z_1 - Y_Z_0)) + 
  declare_estimator(Y ~ Z, model = lm_robust, estimand = "ATE", label = "1: Stepped Wedge", weights = ipw, clusters = unit) +
  declare_estimator(Y ~ Z, model = lm_robust, estimand = "ATE", label = "2: Wave 2 Only", subset = period == 2) 
```

```{r stepped-wedge, echo=FALSE}
dat <- draw_data(design)

treatment_color <- "royalblue2"
control_color <- "darkorange3"

dat %>% 
  arrange(wave,unit) %>% 
  group_by(period) %>%
  mutate(unit = 1:n(), Assignment = ifelse(Z == 1, "Treatment", "Control")) %>% 
  ggplot(aes(x = period, y = unit, fill = Assignment)) +
  geom_tile(color = "white") + 
  scale_fill_manual(values = c(control_color, treatment_color)) +
  # scale_fill_grey(start = .9,end = .5) +
  geom_text(aes(label = round(ipw,2))) +
  dd_theme() +
  theme(legend.position = "right")
```

### Dag


```{r, echo=FALSE}
dag <- dagify(Y ~ Z + X + U + time,
              Z ~ time)

nodes <-
  tibble(
    name = c("X", "U", "time", "Z", "Y"),
    label = c("X", "U", "T", "Z", "Y"),
    annotation = c(
      "**Unknown heterogeneity**<br>Unit effects",
      "**Unknown heterogeneity**<br>",
      "**Time period**<br>",
      "**Treatment assignment**<br>",
      "**Outcome variable**<br>"
    ),
    x = c(1, 5, 1, 3, 5),
    y = c(4, 4, 1, 2.5, 2.5), 
    nudge_direction = c("N", "N", "S", "N", "S"),
    answer_strategy = "uncontrolled"
  )

ggdd_df <- make_dag_df(dag, nodes, design)

base_dag_plot %+% ggdd_df
```


### Exercises

1. Add an answer strategy to the design that doesn't include IPWs and diagnose the design. 
  
  i. How does this affect the bias in the estimates? Explain your answer.
  ii. Now change the potential outcomes function so that the treatment effect is constant across periods. How does this affect the bias? Explain your answer.


2. Our design makes a subtle but crucial assumption about the potential outcomes: namely, that the treated potential outcome revealed in one period is the same irrespective of whether the unit was treated in the previous (or subsequent) periods. What would a violation of this assumption look like? 


### Online Appendix Applied Example

FIND AND ADD EXAMPLE.

<!-- - Comparing 1 and 2, stepped wedge gives a big improvement in power, is -->
<!-- unbiased, and gets the coverage correct. Clearly better than just doing a -->
<!-- cross-section at wave 2.  -->

<!-- - Estimator 3 shows two pitfalls, however, that can lead us to overestimate -->
<!-- benefits of SW. -->

<!-- 1. First, it is biased: [explain how treated POs are more commonly observed in -->
<!-- periods when they're higher, we need to weight for this. How weights come about: -->
<!-- There is one way that a unit can be observed in a treated state in wave 1: they -->
<!-- are assigned to W1 with probability `p_W1`. There are two ways in which a unit -->
<!-- can be treated in wave 2: they are assigned in W1 with `p_W1` or in W2 with -->
<!-- `p_W2`. Because being assigned in W1 or in W2 are exclusive and independent -->
<!-- events, we can get the prob of being treated in any period by wave 2 by summing -->
<!-- the probs.] -->

<!-- 2. Second, standard errors are wrong. Units should be treated as clusters (draw -->
<!-- analogue to two-stage random assignment in saturation design?) -->

<!-- A natural question is how power changes as more or fewer units are assigned.  -->
<!-- Here, we consider variations on the stepped wedge design declared above, in  -->
<!-- which we hold constant at 3 the number of units assigned to the pure control,  -->
<!-- and shift an increasing proportion of the assignment to later waves. -->

<!-- ```{r} -->
<!-- designs <- list( -->
<!--   a = redesign(design, p_00 = 3/8, p_W1 =  3/8, p_W2 = 1/8, p_W3 = 1/8), -->
<!--   b = redesign(design, p_00 = 3/8, p_W1 =  2/8, p_W2 = 2/8, p_W3 = 1/8), -->
<!--   c = redesign(design, p_00 = 3/8, p_W1 =  2/8, p_W2 = 1/8, p_W3 = 2/8), -->
<!--   d = redesign(design, p_00 = 3/8, p_W1 =  1/8, p_W2 = 3/8, p_W3 = 1/8), -->
<!--   e = redesign(design, p_00 = 3/8, p_W1 =  1/8, p_W2 = 2/8, p_W3 = 2/8), -->
<!--   f = redesign(design, p_00 = 3/8, p_W1 =  1/8, p_W2 = 1/8, p_W3 = 3/8) -->
<!--   ) -->
<!-- ``` -->

<!-- ```{r, eval = do_diagnosis & !exists("do_bookdown")} -->
<!-- # Diagnose design -->
<!-- diagnoses <- diagnose_designs(designs) -->
<!-- ``` -->

<!-- ```{r, echo = FALSE, purl = FALSE} -->
<!-- # figure out where the dropbox path is, create the directory if it doesn't exist, and name the RDS file -->
<!-- rds_file_path <- paste0(get_dropbox_path("05_Stepped_Wedge_Designs.Rmd"), "/diagnoses.RDS") -->
<!-- if (do_diagnosis & !exists("do_bookdown")) { -->
<!--   write_rds(diagnoses, path = rds_file_path) -->
<!-- } -->
<!-- diagnoses <- read_rds(rds_file_path) -->
<!-- ``` -->


<!-- ```{r, echo = FALSE} -->
<!-- designs_data <- names(designs) %>%  -->
<!--   lapply(function(name) designs[[name]] %>%  -->
<!--            draw_data %>%  -->
<!--            mutate(design_id = name)) %>%  -->
<!--   do.call(what = rbind,args = .) %>%  -->
<!--   arrange(design_id,wave,i) %>%  -->
<!--   group_by(t,design_id) %>% -->
<!--   mutate(i = 1:n(), Assignment = ifelse(Z == 1, "Treatment", "Control"))  -->


<!-- diags <- diagnoses %>%  -->
<!--   get_diagnosands() %>%  -->
<!--   filter(estimator_label == "2: Weighted, clustered SW") %>%  -->
<!--   mutate( -->
<!--     design_name = paste0("Design ", design_label, ": W1 = ",8*p_W1, -->
<!--                          "; W2 = ", 8*p_W2,  -->
<!--                          "; W3 = ", 8*p_W3,",\nPower = ",round(power,2) -->

<!--                          ) -->
<!--   ) -->

<!-- designs_data <- left_join(designs_data, diags %>% select(design_name, design_label), by = c("design_id" = "design_label")) -->

<!-- designs_data %>%  -->
<!--   ggplot(aes(x = t, y = i, fill = Assignment)) + -->
<!--   geom_tile(color = "white") +  -->
<!--   scale_fill_manual(values = c(control_color, treatment_color)) + -->
<!--   dd_theme() + facet_wrap(~ design_name, nrow = 1) +  -->
<!--   scale_y_continuous("",labels = NULL) -->


<!-- ``` -->

<!-- - We see a monotonic decrease in the power as more of the sample is treated  -->
<!-- later. This occurs because treating units later means observing less of the -->
<!-- potential outcomes. The potential outcomes are more variant, so we're better -->
<!-- off when we observe more of them [I think!] -->

<!-- ### Spillovers -->

<!-- An important assumption is that the potential outcomes revealed are not a -->
<!-- function of what wave the unit entered into treatment. In other words, there are -->
<!-- no Show how, in case of such spillovers, you can just treat the effects as -->
<!-- different, but then you lose power gains (and possibly change estimand) -->



### References




