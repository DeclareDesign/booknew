---
title: "Process tracing"
output: html_document
bibliography: ../../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```



<!-- make sure to rename the section title below -->

```{r process_tracing, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```



<!-- start post here, do not edit above -->

## Bayesian process-tracing

Process-tracing is a qualitative method that uses evidence from in-depth interviews and written records to test causal theories. Process-tracing designs often focus on "causes-of-effects" inquiries (e.g., did the presence of a strong middle class cause a revolution?), rather than on "effects-of-causes" inquiries (e.g., what is the average effect of a strong middle class on the probability of a revolution happening?) \citep{goertz2012tale}. 

Causes-of-effects inquiries imply a hypothesis -- "the strong middle class caused the revolution," say. One widely-promoted answer strategy suggests evaluating whether such hypotheses are correct given the presence or absence of different "clues" found in the archives or interviews [@collier2004sources; @Mahony:Logic:2012; @bennett2014process; fairfield2013going]. \citet{VanEvera1997} categorizes different kinds of clues according to whether one would only believe the hypothesis if one observed the clue (necessity) and whether observing the clue would suffice to infer the hypothesis was correct (sufficiency). "Smoking guns" are well-known: observing them is sufficient to infer the hypothesis is true, but not necessary (as they are quite rare). "Hoop tests," on the other hand, are pieces of evidence that one would expect to find if the hypothesis is correct (necessary), but do not necessarily prove it (not sufficient). "Straw-in-the-wind" tests are neither necessary nor sufficient, while "doubly-decisive" pieces of evidence are fully informative: you should expect to find them if you are correct and if you do, you have proven your theory. 

Of course, it is rare to have such certainty---we typically attach varying degrees of belief to statements of truth. Bayesian process-tracing uses probability theory to form a posterior belief about a hypothesis, given our *beliefs* about whether we would observe different pieces of evidence if we are right or wrong~\citep[e.g.,][]{bennett2015, humphreys2015mixing, fairfield2017explicit}. Extending \citet{VanEvera1997}, "hoop tests"" are clues that are nearly certain to be seen if the hypothesis is true, but likely either way, "smoking-guns" are unlikely to be seen in general but are extremely unlikely if a hypothesis is false, "straws-in-the-wind" are more likely when the hypothesis is true but still somewhat likely when it is not, and ``doubly-decisive'' clues are very likely to be seen if a hypothesis is true and very unlikely if it is false. 

### Declaration

* $M$ *Model*: We posit a population of 195 cases, each of which does or does not exhibit the presence of an outcome, $Y \in \{0,1\}$. For the sake of illustration, we will suppose that $Y$ represents the presence or absence of a civil war. Each case also exhibits the presence or absence of a potential cause, $Z \in \{0,1\}$. For example, we might suppose that $Z$ represents the presence or absence of natural resources. At random, 30% of the cases get $Z=1$. We also assume researchers observe a clue, $C$, that $Z$ does or does not have a causal relationship with $Y$. 

The potential outcomes of $Y$ depend both whether the cause, $Z$, is present in a case and what "type" of causal relation the case exhibits. Conceptually, there are exactly four distinct types of causal relations. First, the presence of $Z$ might cause $Y$: if $Z = 0$, then $Y = 0$ and if $Z = 1$ then $Y = 1$. In other words, civil wars happen in such cases *because* the country has natural resources. Second, the absence of $Z$ might cause $Y$: if $Z = 0$ then $Y = 1$ and if $Z = 1$ then $Y = 0$. In such cases, civil war breaks out *because* the country does not have natural resources, and would not break out if the country had natural resources. Finally, $Y$ might be present irrespective of $Z$ or $Y$ might be absent irrespective of $Z$. Continuing our analogy, such countries would have had civil war or peace, irrespective of whether they also had natural resources (i.e., because war is related to some other causal process). We specify a model in which civil war is governed by causal pathway 1 ($Z$ causes $Y$) in roughly 20% of cases, by pathway 2 ($\neg Z$ causes $Y$) in only 10% of cases, by pathway 3 ($Y$ irrespective of $z$) in 20% of countries, and by pathway 4 ($\neg Y$ irrespective of $Z$) in half of all countries.

There are also potential outcomes for the clue, $C$. These depend on the case's causal type. Specifically, the clue appears with .25 probability if the case is one in which $Z$ causes $Y$, and with probability .005 if it is one where $Y$ occurs regardless. The clue does not appear in the other types of cases. Crucially, while the outcome, cause, and clue are observable to the researcher, the type is not.

* $I$ *Inquiry*: We wish to know the answer to a type of "cause of effects" question: in a specific case, what is the probability that $Z$ caused $Y$? More formally, we want to know $\Pr(Y_i(Z_i=0)=0| Z_i=1, Y_i(Z_i=1)=1)$---that is, what are the chances that $Y$ would have been 0 if $Z$ were 0 for a unit $i$ for which $Z$ was 1 and $Y$ was 1. This is equivalent to asking the probability that the case is of type 1. The inquiry thus takes the value 0 or 1 depending on the type of case.

* $D$ *Data Strategy*: The fundamental problem that the researcher faces is that of observational equivalence: different causal types can cause the same observed 
To a degree, this issue can be simplified by following a sampling strategy that is often criticized: selecting on $Y$. By selecting at random one case in which both $Z$ and $Y$ are present, the researcher can narrow her uncertainty to two candidate types: $Pr(H_{X \rightarrow Y} \mid X  \neq Y) = 0$, for example, because a type where $Z$ causes not $Y$ could never produce the observed data, $X = 1, Y = 1$. It cannot be that natural resources were the cause of peace (type 2), or that peace would have happened irrespective of natural resources (type 4), in a country that had a civil war and natural resources. The sampling strategy restricts our inferential challenge to adjudicating between two possibilities: 1) the hypothesis that   

<!-- discover whether the true reason that $Y$ is present is because $X$ caused it to be so.  -->

<!-- The data strategy is to generate evidence in favor of one or another underlying causal process through the use of causal process observations (CPO) tests. In other words, if a country had a civil war because natural resources caused the civil war, there should be observable clues consistent with this hypothesis. The researcher specifies two CPO tests. The first is a "straw-in-the-wind": if $X$ did not cause $Y$ the researcher still expects to observe this CPO with probability 0.25, and if $X$ did in fact cause $Y$ the probability of observing the CPO is 0.75. The second is a "smoking-gun": this CPO is believed to arise with probability 0.05 if $X$ is not the cause of $Y$, and with probability 0.30 if $X$ is the cause of $Y$. Thus, the smoking-gun provides rare but definitive proof of the underlying causal process. In contrast, observing the straw-in-the-wind is more likely when the hypothesis that $X$ caused $Y$ is true, but can also happen when this hypothesis is false. For example, if, just prior to the civil war, an armed group was created whose main name, aims, and ideology were centered around the capture and control natural resources, this CPO may constitute a smoking gun. It is extremely unlikely to happen if $H_{X\rightarrow Y}$ is false, but might not happen even if it is true. The national army taking control over natural resources during a civil war is a straw-in-the-wind. This is very likely to happen if the natural resources caused the war, but also somewhat likely even if they did not. Finally, in addition to specifying beliefs about observing the CPOs depending on whether the hypothesis is true or false, the researcher also (implicitly) specifies a belief about the joint probability of observing both CPOs when the hypothesis that $X$ caused $Y$ is true or false. Namely, they specify that the CPOs are independent conditional on the hypothesis being true or false. In terms of our analogy, this is equivalent to assuming that, while it is more likely to observe the argmed group and the national army's takeover of natural resources when resources truly did cause the civil war, this does not imply anything about the probability of observing the national army takeover *given that* the armed group was created. We relax this assumption below and show that it has strong and underexplored implications for process tracing inferences.  -->

<!-- * $A$ *Answer Strategy*: The researcher uses the CPOs in combination with Bayes' rule to update about the probability that $X$ caused $Y$. In other words, they form a posterior inference, $Pr(H_{X\rightarrow Y} \mid E)$, where $E$ denotes the CPOs they observe. We specify answer strategies for forming this inference. The first simply ignores the CPOs and is equivalent to stating a prior belief without doing any causal process tracing. The second looks only for a straw-in-the-wind, and the third looks only for a smoking-gun. These single-CPO strategies formalize the notion that process-tracing is time-consuming and costly. However, the fourth strategy conditions posterior inferences on both the straw-in-the-wind *and* the smoking-gun, which is consistent with the multiple-CPO strategies of many process-tracing applications [see, for example, @fairfield2013going]. -->

use mutate for posterior

use declare_measurement for CPOs

use PO function for types 

maybe don't reuse pr_SIW_H for *both* dgp and estimator

```{r}
types <- c('Z_caused_Y', 'Z_caused_not_Y', 'always_Y', 'always_not_Y')

design <-
  declare_population(N = 195,
                     Z = draw_binary(prob = .3, N = N),
                     type = sample(x = types, size = N, 
                                   replace = TRUE, prob = c(.2, .1, .2, .5)))  +
  declare_potential_outcomes(
    Y ~ Z * (type == "Z_caused_Y") + (1 - Z) * (type == "Z_caused_not_Y") + (type == "always_Y"),
    conditions = list(Z = c(0, 1), type = types)) +
  declare_potential_outcomes(
    pr_C_1 ~ Z * (.25 * (type == "Z_caused_Y") + .005 * (type == "always_Y")),
    conditions = list(Z = c(0, 1), type = types)) +
  declare_reveal(c(Y, pr_C_1), c(Z, type)) +
  declare_measurement(C = draw_binary(prob = pr_C_1)) +
  declare_sampling(handler = function(data) data %>% filter(Z==1 & Y==1) %>% sample_n(size = 1)) +
  declare_estimand(did_Z_cause_Y = type == 'Z_caused_Y') +
  declare_estimator(
    pr_type_Z_caused_Y = .5,
    pr_C_1_type_Z_caused_Y = .25,
    pr_C_1_type_always_Y = .005,
    pr_C_type_Z_caused_Y = C * pr_C_1_type_Z_caused_Y + (1 - C) * (1 - pr_C_1_type_Z_caused_Y),
    pr_C_type_always_Y = C * pr_C_1_type_always_Y + (1 - C) * (1 - pr_C_1_type_always_Y),
    posterior =
      pr_type_Z_caused_Y * pr_C_type_Z_caused_Y / (pr_type_Z_caused_Y * pr_C_type_Z_caused_Y + pr_C_type_always_Y * (1 - pr_type_Z_caused_Y)),
    estimator_label = "Smoking Gun",
    estimand_label = "did_Z_cause_Y",
    handler = summarize) 

# diagnose_design(process_tracing_design, 
#                 diagnosands = declare_diagnosands(
#                   bias = mean(posterior - estimand),
#                   rmse = sqrt(mean((posterior - estimand) ^ 2)),
#                   mean_estimand = mean(estimand),
#                   mean_posterior = mean(posterior),
#                   keep_defaults = FALSC
#                 ), sims = 1000)

```





Formalizing this kind of process-tracing exercise leads to non-obvious insights about the tradeoffs involved in committing to one or another CPO strategy ex ante. We declare a design based on a \textbf{M}odel of the world in which both the driver, $X$, and the outcome, $Y$, might be present in a given case either because $X$ caused $Y$ or because $Y$ would have been present regardless of $X$ (or perhaps, an alternative cause was responsible for $Y$). See Supplementary Materials Section 3.3. The \textbf{I}nquiry is whether $X$ in fact caused $Y$ in the specific case under analysis (i.e., would $Y$ have been different if $X$ were different?). The \textbf{D}ata strategy consists of selecting one case from a population of cases, based on the fact that both $X$ and $Y$ are present, and then collecting two causal process observations. Even before diagnosis, the declaration of the design illustrates an important point: the case selection strategy informs the answer strategy by enabling the researcher to narrow down the number of causal processes that might be at play. This greatly simplifies the application of Bayes' rule to the case in question. 

Importantly, the researcher attaches two different ex ante probabilities to the observation of confirmatory evidence in each CPO, depending on whether $X$ did or did not cause $Y$. Specifically, the first CPO contains evidence that is more likely to be seen when the hypothesis is true, $Pr(E_2\mid H) = 0.75$, but even when $H$ is false and $Y$ happened irrespective of $X$, there is some probability of observing the second piece of evidence: $Pr(E_2\mid\neg H) = 0.25$. The first CPO thus constitutes a ``straw-in-the-wind'' test (albeit a reasonably strong one). By contrast, the probability of observing the evidence in the second CPO when the hypothesis that $X$ caused $Y$ is true, $Pr(E_1\mid H)$ is 0.30, whereas the probability of observing the evidence when the hypothesis is false, $Pr(E_1|\neg H)$ is only 0.05. The first CPO thus constitutes a ``smoking gun'' test of $H$. Observing the second piece of evidence is more informative than observing the first, because it is so unlikely to observe a smoking gun when the hypothesis is false.

Diagnosis reveals that a researcher who relied solely on the weaker ``straw-in-the-wind'' test would make \textit{better} inferences on average than one who relied solely on the ``smoking gun'' test. One does better relying on the straw because, even if it is less informative when observed, it is much more commonly observed than the smoking gun, which is an informative, but rare, clue. The \citet[][826]{collier2011understanding} assertion that, of the four tests, straws-in-the-wind are ``the weakest and place the least demand on the researcher's knowledge and assumptions'' might thus be seen as an advantage rather than a disadvantage. In practice, of course, scholars often seek multiple CPOs, possibly of different strength \citep[see, for example,][]{fairfield2013going}. In such cases, the diagnosis suggests the learning depends on the ways in which these CPOs are correlated. There are large gains from seeking two CPOs when they are negatively correlated --- for example, if they arise from alternative causal processes. But there are weak gains when CPOs arise from the same process. Presentations of process tracing rarely describe correlations between CPO probabilities yet the need to specify these (and the gain from doing so) presents itself immediately when a process tracing design is declared.


### Dag



```{r, echo = FALSE}
dag <- dagify(C ~ Z + type,
              Y ~ Z + type)


nodes <-
  tibble(
    name = c("Z", "type","C", "Y"),
    label = name,
    annotation = c(
      "**Cause**<br>Suspected cause of Y",
      "**Type**<br>Causal relationship<br>between Z and Y",
      "**Clue**<br>Evidence that Z caused Y",
      "**Outcome**"),
    x = c(1, 1, 5, 5),
    y = c(1.5,3.5,1.5,3.5),
    nudge_direction = c("S", "N", "S", "N"),
    answer_strategy = "uncontrolled"
  )


ggdd_df <- make_dag_df(dag, nodes, design)

base_dag_plot %+% ggdd_df
```



### Example

The design itself makes use of the helper functions above in the `declare_estimator` steps.


Assumption: E can only be observed if X and Y present (e.g. militia forms around natural resources during a civil war--cannot happen if you don't have both a civil war and natural resources).


### Exercises

- Diagnosis starts with researcher correct about prior belief of hypothesis (.5) and about clue probs (smoking gun)
- Change prior and look at bias
- Change clue probs + clue prior and look at bias
- Change clue probs 


### Online Appendix Applied Example

- Point here is to explore cases where you look at multiple sources of 
  evidence
  
- In many parts of the world, people rely on non-state institutions to construct social order. Sometimes, those institutions persist for a long time [e.g., mourides], whereas sometimes they break down. Why do non-state institutions fail? Some scholars of African societies think that traditional institutions declined in the 1960s and 1970s due to the forceful efforts of post-independence leaders who saw these alternative authorities as a threat to the young state. Other scholars such as @ensminger1990 point instead to the internal political economy of rural societies, and emphasize the role of economic interests in the decline of traditional institutions. 

- @ensminger1990 is an economic anthropologist who does a bunch of cool work with the Orma in Kenya, a nomadic pastoralist group. She points out that, whereas the Orma were able to avoid a tragedy of the commons by policing access to scarce water resources by competing somali pastoralists throughout the 1960s and 1970s, by the 1980s the power of the council of elders was weakened, as evidenced by frequent defection of individual orma who sold their water to somalis, thus hurting the interests of the group. 

- Her study presents a case of causal process tracing in which the scholar presents evidence from rich fieldwork to support the inference that some effect was produced by a specific cause. It is useful to formalize as it provides lessons about what kinds of clues qualitative researchers might seek in order to maximize the probative value of their answer strategy. 

- The key pieces are the outcome (breakdown of council of elders -- measured through defections by orma selling their water to somalis), its potential cause (economic diversification -- measured as a move away from cattle-based pastoralism towards sendentary economic activity -- teaching, shops -- by some Orma), and the pieces of evidence or "clues" that support the notion that the relationship between the outcome and the cause is causal.
  
- We set up an imaginary study inspired by @ensminger1990

- The researcher seeks to test the claim that economic diversification leads to the breakdown of informal institutions. They look for a group in Kenya that has experienced diversification and whose institutions of managing the commons have failed. [think of cool empirical implications]. They want to test this claim against the idea that informal institutions failed due to a deliberate attempt by state authorities to supplant traditional leaders. 

- Their answer strategy diverges from the one in the book insofar as they seek not one but two clues to test their prior explanation. 


- This time the researcher needs to think not only about the typology of their clues in terms of Van Evera stuff, but also the joint probability distribution of the clues.

- We make use of the `joint_prob` function from the book R package, which calculates the joint probability distribution of two correlated events, given their marginal probabilities and correlation 

```{r, echo = FALSE}
# Calculate bivariate probabilities given correlation
joint_prob <- function(p1, p2, rho, which_prob = NULL) {
  r <- rho * (p1 * p2 * (1 - p1) * (1 - p2)) ^ .5
  probs <- c(`00` = (1 - p1) * (1 - p2) + r,
             `01` = p2 * (1 - p1) - r,
             `10` = p1 * (1 - p2) - r,
             `11` = p1 * p2 + r)
  
  if(!is.null(which_prob)) probs <- probs[which_prob]
  
  return(probs)
}


```


- Researcher imposes monotonicity (no `Z_caused_not_Y` types) -- economic diversity either
  has no or a negative effect on institutions
- Note: no variation in outcome. All informal institutions have declined, we just want to
  know if economic diversification caused it. A quant study would provide no leverage.
  
- Note: joint probabilities of observing clues depend only on type, not (as before) on type and Z

```{r}
types <- c('Z_caused_Y', 'Z_caused_not_Y', 'always_Y', 'always_not_Y')




design <-
  declare_population(N = 20,
                     Z = draw_binary(prob = .5, N = N),
                     type = sample(x = types, size = N, replace = TRUE, prob = c(.5, 0, .5, 0)))  +
  declare_potential_outcomes(
    Y ~ Z * (type == "Z_caused_Y") + (1 - Z) * (type == "Z_caused_not_Y") + (type == "always_Y"),
    conditions = list(Z = c(0, 1), type = types)) +
  declare_potential_outcomes(
    pr_C1C2_00 ~ (joint_prob(.75,.3,0,"00") * (type == "Z_caused_Y") + joint_prob(.25,.005,0,"00") * (type == "always_Y")),
    conditions = list(Z = c(0, 1), type = types)) +
    declare_potential_outcomes(
    pr_C1C2_01 ~ (joint_prob(.75,.3,0,"01") * (type == "Z_caused_Y") + joint_prob(.25,.005,0,"01") * (type == "always_Y")),
    conditions = list(Z = c(0, 1), type = types)) +
    declare_potential_outcomes(
    pr_C1C2_10 ~ (joint_prob(.75,.3,0,"10") * (type == "Z_caused_Y") + joint_prob(.25,.005,0,"10") * (type == "always_Y")),
    conditions = list(Z = c(0, 1), type = types)) +
    declare_potential_outcomes(
    pr_C1C2_11 ~ (joint_prob(.75,.3,0,"11") * (type == "Z_caused_Y") + joint_prob(.25,.005,0,"11") * (type == "always_Y")),
    conditions = list(Z = c(0, 1), type = types)) +
  declare_reveal(c(Y, pr_C1C2_00,pr_C1C2_01,pr_C1C2_10,pr_C1C2_11), c(Z, type)) +
  declare_assignment(blocks = ID, block_prob_each = cbind(pr_C1C2_00,pr_C1C2_01,pr_C1C2_10,pr_C1C2_11),
                     conditions = c("00","01","10","11"), 
                     assignment_variable = "C1C2") +  
  declare_sampling(handler = function(data) data %>% filter(Z==1 & Y==1) %>% sample_n(size = 1)) +
  declare_estimand(did_Z_cause_Y = type == 'Z_caused_Y') +
  declare_measurement(
  C1 = ifelse(C1C2 == "10" | C1C2 == "11", 1, 0),
  C2 = ifelse(C1C2 == "01" | C1C2 == "11", 1, 0),
  handler = fabricate) +
  declare_estimator(
    pr_type_Z_caused_Y = .5,
    pr_C_1_type_Z_caused_Y = .75,
    pr_C_1_type_always_Y = .25,
    C = C1,
    pr_C_type_Z_caused_Y = C * pr_C_1_type_Z_caused_Y + (1 - C) * (1 - pr_C_1_type_Z_caused_Y),
    pr_C_type_always_Y = C * pr_C_1_type_always_Y + (1 - C) * (1 - pr_C_1_type_always_Y),
    posterior =
      pr_type_Z_caused_Y * pr_C_type_Z_caused_Y / (pr_type_Z_caused_Y * pr_C_type_Z_caused_Y + pr_C_type_always_Y * (1 - pr_type_Z_caused_Y)),
    label = "Straw in the Wind",
    estimand_label = "did_Z_cause_Y",
    handler = summarize) +
  declare_estimator(
    pr_type_Z_caused_Y = .5,
    pr_C_1_type_Z_caused_Y = .30,
    pr_C_1_type_always_Y = .005,
    C = C2,
    pr_C_type_Z_caused_Y = C * pr_C_1_type_Z_caused_Y + (1 - C) * (1 - pr_C_1_type_Z_caused_Y),
    pr_C_type_always_Y = C * pr_C_1_type_always_Y + (1 - C) * (1 - pr_C_1_type_always_Y),
    posterior =
      pr_type_Z_caused_Y * pr_C_type_Z_caused_Y / (pr_type_Z_caused_Y * pr_C_type_Z_caused_Y + pr_C_type_always_Y * (1 - pr_type_Z_caused_Y)),
    label = "Smoking Gun",
    estimand_label = "did_Z_cause_Y",
    handler = summarize) +
  declare_estimator(
    pr_type_Z_caused_Y = .5,
    pr_C1_1_type_Z_caused_Y = .30,
    pr_C1_1_type_always_Y = .005,
    pr_C2_1_type_Z_caused_Y = .75,
    pr_C2_1_type_always_Y = .25,
    rho = 0,
    pr_C_type_Z_caused_Y = joint_prob(pr_C1_1_type_Z_caused_Y, pr_C2_1_type_Z_caused_Y, 
                                      rho, which_prob = C1C2),
    pr_C_type_always_Y = joint_prob(pr_C1_1_type_always_Y, pr_C2_1_type_always_Y, 
                                      rho, which_prob = C1C2),
    posterior =
      pr_type_Z_caused_Y * pr_C_type_Z_caused_Y / (pr_type_Z_caused_Y * pr_C_type_Z_caused_Y + pr_C_type_always_Y * (1 - pr_type_Z_caused_Y)),
    label = "Joint Updating",
    estimand_label = "did_Z_cause_Y",
    handler = summarize) 


# diagnose_design(design,
#                 diagnosands = declare_diagnosands(
#                   bias = mean(posterior - estimand),
#                   rmse = sqrt(mean((posterior - estimand) ^ 2)),
#                   mean_estimand = mean(estimand),
#                   mean_posterior = mean(posterior),
#                   keep_defaults = FALSE), 
#                 sims = 500)

# design_sims <- simulate_design(design, sims = 500)

```


### Dag

```{r}
dag <- dagify(C1 ~ type,
              C2 ~ type,
              Y ~ Z + type)


nodes <-
  tibble(
    name = c( "type","Z","C1", "C2", "Y"),
    label = name,
    annotation = c(
      "**Type**<br>Causal relationship<br>between economic diversification<br>and breakdown of institutions",
      "**Cause**<br>Economic Diversification",
      "**Clue 1**<br>Smoking gun interview evidence",
      "**Clue 2**<br>Straw-in-the-wind archival evidence",
      "**Outcome**<br>Breakdown of traditional<br>institutions"),
    x = c(1, 1, 5, 5, 5),
    y = c(1.5,3.5,2,1.5,3.5),
    nudge_direction = c("S", "N", "N", "S","N"),
    answer_strategy = "uncontrolled"
  )


ggdd_df <- make_dag_df(dag, nodes, design)

base_dag_plot %+% ggdd_df
```
  
















