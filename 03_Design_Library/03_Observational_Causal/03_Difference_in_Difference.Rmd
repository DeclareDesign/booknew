---
title: "Difference in differences"
output: html_document
bibliography: ../../bib/book.bib 
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

## Difference in differences

<!-- make sure to rename the section title below -->

```{r difference_in_difference, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 100
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
```


```{r}

```

```{r, eval = do_diagnosis & !exists("do_bookdown")}
# simulations_pilot <- simulate_design(design, sims = sims)
```

```{r, echo = FALSE, purl = FALSE}
# figure out where the dropbox path is, create the directory if it doesn't exist, and name the RDS file
rds_file_path <- paste0(get_dropbox_path("section_template"), "/simulations_pilot.RDS")
if (do_diagnosis & !exists("do_bookdown")) {
  write_rds(simulations_pilot, path = rds_file_path)
}
simulations_pilot <- read_rds(rds_file_path)
```


### Two-period two-group setting

- Show that comparison of T and C in period 2 is biased and comparison of T between period 1 and 2 is biased, but DiD unbiased in presence of confounding in treatment assignment (unit with higher unit shock is always treated) and time trends

```{r}
N_units <- 2
N_time_periods <- 2

two_period_design <- 
  
  declare_population(
    units = add_level(N = N_units, unit_shock = rnorm(N)),
    periods = add_level(N = N_time_periods, nest = FALSE,
                        time = (1:N_time_periods) - N_time_periods + 1),
    unit_period = cross_levels(by = join(units, periods), unit_time_shock = rnorm(N))
  ) + 
  
  # internal note: the unbiasedness obtains whether or not there is a unit-time shock
  declare_potential_outcomes(
    Y_Z_0 = unit_shock + 0.5 * time + unit_time_shock, # common pretreatment trend
    Y_Z_1 = Y_Z_0 + 0.2) +
  
  declare_estimand(ATE = mean(Y_Z_1 - Y_Z_0), subset = time == 1) + 
  
  declare_assignment(Z = unit_shock == max(unit_shock), handler = mutate) + 
  
  declare_reveal(
    Y = case_when(Z == 0 | time < 1 ~ Y_Z_0, TRUE ~ Y_Z_1), handler = mutate) +
  
  declare_estimator(estimate = (mean(Y[Z == 1 & time == 1]) - mean(Y[Z == 0 & time == 1])) - 
                      (mean(Y[Z == 1 & time == 0]) - mean(Y[Z == 0 & time == 0])), 
                    estimator_label = "DiD", handler = summarize, label = "DiD") + 
  
  declare_estimator(estimate = mean(Y[Z == 1 & time == 1]) - mean(Y[Z == 1 & time == 0]), 
                    estimator_label = "Diff", handler = summarize, label = "Diff") + 
  
  declare_estimator(estimate = mean(Y[Z == 1 & time == 1]) - mean(Y[Z == 0 & time == 1]), 
                    estimator_label = "DiM", handler = summarize, label = "DiM")
  
# diagnosis <- diagnose_design(
#   two_period_design, diagnosands = declare_diagnosands(select = bias), 
#   sims = 1000, bootstrap_sims = 1000)
```

### Parallel trends assumption

- Introduce assumption and visual test

```{r}
set.seed(2)
draw_data(two_period_design) %>% 
  ggplot(aes(time, Y, color = as.factor(Z))) + 
  geom_line()
```

- Show that evaluating parallel trends assumption by looking at a single pretreatment time period is flawed

### Multi-period design

- Switch to regression context with 20 periods, 100 units and show same results hold with two-way FE (controlling for one period before T is insufficient to remove bias)

```{r}
N_units <- 20
N_time_periods <- 20

multi_period_design <- 
  
  declare_population(
    units = add_level(N = N_units, 
                      unit_shock = rnorm(N), 
                      unit_treated = 1*(unit_shock > median(unit_shock)), 
                      unit_treatment_start = 
                        sample(2:(N_time_periods - 1) - N_time_periods + 1, N, replace = TRUE)),
    periods = add_level(N = N_time_periods, nest = FALSE, 
                        time = (1:N_time_periods) - N_time_periods + 1),
    unit_period = cross_levels(by = join(units, periods),
                               noise = rnorm(N), 
                               pretreatment = 1*(time < unit_treatment_start))
  ) + 
  
  declare_potential_outcomes(
    Y_Z_0 = unit_shock + 0.5 * time + noise, # common pretreatment trend
    Y_Z_1 = Y_Z_0 + 0.2) +
  
  declare_estimand(ATE = mean(Y_Z_1 - Y_Z_0), subset = time == 1) + 
  
  declare_assignment(Z = 1*(unit_treated & pretreatment == FALSE), handler = fabricate) + 
  declare_reveal(Y, Z) + 
  
  declare_estimator(Y ~ Z + time, fixed_effects = ~ units + periods, 
                    model = lm_robust, label = "twoway-fe", estimand = "ATE") 
  
# diagnose_design(multi_period_design, diagnosands = declare_diagnosands(select = bias), sims = 500, bootstrap_sims = 1000)
```

- Show that in case where some units switch back and forth between T and C during panel there is bias (point to Imai and Kim appear with weighted FE estimator to fix this)



