---
title: "Policing and post-treatment bias"
output: html_document
bibliography: ../../bib/book.bib
---

<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book-->
```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # files are all relative to RStudio project home
```

```{r, eval = !exists("do_bookdown"), echo = FALSE, include = FALSE, purl = FALSE}
# load common packages, set ggplot ddtheme, etc.
source("scripts/before_chapter_script.R")
```

<!-- start post here, do not edit above -->

## Policing and post-treatment bias

@imai2008

<!-- make sure to rename the section title below -->

```{r policing, echo = FALSE, output = FALSE, purl = FALSE}
# run the diagnosis (set to TRUE) on your computer for this section only before pushing to Github. no diagnosis will ever take place on github.
do_diagnosis <- FALSE
sims <- 200
b_sims <- 20
```

```{r, echo = FALSE}
# load packages for this section here. note many (DD, tidyverse) are already available, see scripts/package-list.R
library(blockTools)
```

Knox, Lowe, and Mummolo (2020) (https://www.cambridge.org/core/journals/american-political-science-review/article/administrative-records-mask-racially-biased-policing/66BC0F9998543868BB20F241796B79B8) study the statistical biases that accompany estimates of racial bias in police use of force when presence in the dataset (being stopped by police) is conditioned on an outcome that is a downstream consequence of race. They show the estimate is not identified unless additional modelling assumptions are brought to bear. 

Gaebler et al. (2020) (https://5harad.com/papers/post-treatment-bias.pdf) study the same question and make such modeling assumptions (subset ignorability, definition 2). 

In a twitter thread (https://twitter.com/jonmummolo/status/1275790509647241222?s=20), Mummolo shows the three DAGs that are compatible with subset ignorability. We agree with Mummolo that these DAGs assume away causal paths that are very plausible.



```{r echo=FALSE, out.width='100%'}
#knitr::include_graphics('../figures/mummolo_dag.png')
knitr::include_graphics("figures/mummolo_dag.png")
```

This document provides a design declaration for this setting and shows how estimates of the controlled direct effect (effect of race on force among the stopped) are biased unless those paths are set to zero by assumption.

# Design Declaration

There are four variables: (D: minority, M: stop, U: suspicion (unobserved), Y: force) and five paths:

```{r}
D_M = 1 # effect of minority on stop
U_M = 1 # effect of suspicion on stop
D_Y = 1 # effect of minority on force
U_Y = 1 # effect of suspicion on force
M_Y = 1 # effect of stop on force
```

This basic design allows all five paths.

```{r}
design_1 <-
  declare_population(N = 1000,
                     D = rbinom(N, size = 1, prob = 0.5),
                     U = rnorm(N)) +
  declare_potential_outcomes(M ~ rbinom(N, size = 1, prob = pnorm(D_M *
                                                                    D + U_M * U)),
                             assignment_variable = "D") +
  declare_reveal(M, D) +
  declare_potential_outcomes(Y ~ rnorm(N, D_Y * D + M_Y * M + U_Y * U),
                             conditions = list(D = c(0, 1), M = c(0, 1))) +
  declare_reveal(outcome_variables = "Y",
                 assignment_variables = c("D", "M")) +
  declare_estimand(CDE = mean(Y_D_1_M_1 - Y_D_0_M_1)) +
  declare_estimator(Y ~ D, subset = M == 1, estimand = "CDE")
```

We redesign the design 3 times, removing one path at a time, then simulate all four designs.

```{r, message=FALSE}
# no effect of D on M
design_2 <- redesign(design_1, D_M = 0)

# no effect of U on M
design_3 <- redesign(design_1, U_M = 0)

# no effect of U on Y
design_4 <- redesign(design_1, U_Y = 0)
```

This chunk is set to `echo = TRUE` and `eval = do_diagnosis`
```{r, eval = do_diagnosis & !exists("do_bookdown")}
simulations <- simulate_designs(design_1, design_2, design_3, design_4, sims = sims)
```

Right after you do simulations, you want to save the simulations rds. 

```{r, echo = FALSE, purl = FALSE}
# figure out where the dropbox path is, create the directory if it doesn't exist, and name the RDS file
rds_file_path <- paste0(get_dropbox_path("policing"), "/simulations_policing.RDS")
if (do_diagnosis & !exists("do_bookdown")) {
  write_rds(simulations, path = rds_file_path)
}
simulations <- read_rds(rds_file_path)
```


```{r, echo=FALSE, message = FALSE}

simulations <-
  simulations %>%
  mutate(`Assumed DAG` = factor(
    design_label,
    levels = c("design_1", "design_2", "design_3", "design_4"),
    labels = c(
      "All paths possible",
      "no effect of D on M",
      "no effect of U on M",
      "no effect of U on Y"
    )
  ))


summary_df <-
  simulations %>%
  group_by(`Assumed DAG`) %>%
  summarise(
    mean_estimand = mean(estimand),
    mean_estimate = mean(estimate),
    bias = mean(estimate - estimand)
  ) %>%
  pivot_longer(cols = c("mean_estimand", "mean_estimate"))
```

This plot confirms that unless one of those implausible assumptions hold, estimates of the CDE are biased. 

```{r, echo=FALSE}
ggplot(simulations, aes(estimate)) +
  geom_histogram(bins = 50) +
  geom_vline(data = summary_df, aes(xintercept = value, color = name)) +
  facet_wrap(~`Assumed DAG`) +
  xlab("Simulated CDE estimates") +
  theme_bw() +
  theme(legend.position = "bottom",
        strip.background = element_blank(),
        axis.title.y = element_blank(),
        legend.title = element_blank())
```
