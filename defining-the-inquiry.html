<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 7 Defining the inquiry | Research Design: Declare, Diagnose, Redesign</title>
<meta name="author" content="Graeme Blair, Alexander Coppock, and Macartan Humphreys">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.3.9000/tabs.js"></script><script src="libs/bs3compat-0.2.3.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<link href="libs/bs4_book-1.0.0/dd_imgpopup.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/bs4_book-1.0.0/dd_imgpopup.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://hypothes.is/embed.js" async></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Research Design: Declare, Diagnose, Redesign</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li class="book-part">Introduction</li>
<li><a class="" href="preamble.html"><span class="header-section-number">1</span> Preamble</a></li>
<li><a class="" href="improving-research-designs.html"><span class="header-section-number">2</span> Improving research designs</a></li>
<li><a class="" href="primer.html"><span class="header-section-number">3</span> Software primer</a></li>
<li><a class="" href="part-i-exercises.html"><span class="header-section-number">4</span> Part I Exercises</a></li>
<li class="book-part">Declaration, Diagnosis, Redesign</li>
<li><a class="" href="declaration.html"><span class="header-section-number">5</span> Declaration</a></li>
<li><a class="" href="specifying-the-model.html"><span class="header-section-number">6</span> Specifying the model</a></li>
<li><a class="active" href="defining-the-inquiry.html"><span class="header-section-number">7</span> Defining the inquiry</a></li>
<li><a class="" href="crafting-a-data-strategy.html"><span class="header-section-number">8</span> Crafting a data strategy</a></li>
<li><a class="" href="choosing-an-answer-strategy.html"><span class="header-section-number">9</span> Choosing an answer strategy</a></li>
<li><a class="" href="p2diagnosis.html"><span class="header-section-number">10</span> Diagnosis</a></li>
<li><a class="" href="redesign-2.html"><span class="header-section-number">11</span> Redesign</a></li>
<li><a class="" href="part-ii-exercises.html"><span class="header-section-number">12</span> Part II Exercises</a></li>
<li class="book-part">Research Design Library</li>
<li><a class="" href="research-design-library.html"><span class="header-section-number">13</span> Research Design Library</a></li>
<li><a class="" href="observational-designs-for-descriptive-inference.html"><span class="header-section-number">14</span> Observational designs for descriptive inference</a></li>
<li><a class="" href="experimental-designs-for-descriptive-inference.html"><span class="header-section-number">15</span> Experimental designs for descriptive inference</a></li>
<li><a class="" href="observational-designs-for-causal-inference.html"><span class="header-section-number">16</span> Observational designs for causal inference</a></li>
<li><a class="" href="experimental-designs-for-causal-inference.html"><span class="header-section-number">17</span> Experimental designs for causal inference</a></li>
<li><a class="" href="multi-study-designs.html"><span class="header-section-number">18</span> Multi-study designs</a></li>
<li><a class="" href="part-iii-exercises.html"><span class="header-section-number">19</span> Part III Exercises</a></li>
<li class="book-part">Research Design Lifecycle</li>
<li><a class="" href="research-design-lifecycle.html"><span class="header-section-number">20</span> Research Design Lifecycle</a></li>
<li><a class="" href="before.html"><span class="header-section-number">21</span> Before</a></li>
<li><a class="" href="during.html"><span class="header-section-number">22</span> During</a></li>
<li><a class="" href="after.html"><span class="header-section-number">23</span> After</a></li>
<li><a class="" href="part-iv-exercises.html"><span class="header-section-number">24</span> Part IV Exercises</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="defining-the-inquiry" class="section level1">
<h1>
<span class="header-section-number">7</span> Defining the inquiry<a class="anchor" aria-label="anchor" href="#defining-the-inquiry"><i class="fas fa-link"></i></a>
</h1>
<p>An inquiry is a summary of a reference model. Suppose in your reference model that <span class="math inline">\(D\)</span> possibly affects <span class="math inline">\(Y\)</span>. Using the framework provided in <span class="citation">Pearl and Mackenzie (<a href="references.html#ref-pearl2018book" role="doc-biblioref">2018</a>)</span>, one inquiry might be descriptive, or associational: what is the average level of <span class="math inline">\(Y\)</span> when <span class="math inline">\(D=1\)</span>? A second might be about the effects of interventions: what is the average treatment effect of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span>? A third is about counterfactuals: for what share of units would <span class="math inline">\(Y\)</span> have been different if <span class="math inline">\(D\)</span> were different? If a theory involves more variables, many more questions open up, for instance regarding how the effect of one variable passes through, or is modified by, another.</p>
<p>Your inquiry is your research question. Simple or complex, causal or descriptive, your inquiry can be thought of as a summary of a data generating process. Like models, inquiries—the questions you ask—are themselves theoretical objects. It is easy to confuse inquiries and the output of answer strategies. If our theory posits the existence of an Average Treatment Effect, we might use an answer strategy like difference-in-means to estimate it, but the estimate is fundamentally distinct from the inquiry. Estimates are empirical, inquiries are theoretical.</p>
<!-- Is the estimate from simulated data empirical? -->
<p>In general, an inquiry is a summary function <span class="math inline">\(I\)</span> that operates on an instance of a model <span class="math inline">\(m \in M\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Recall we are thinking here of &lt;span class="math inline"&gt;\(M\)&lt;/span&gt; as a class of models with element &lt;span class="math inline"&gt;\(m\)&lt;/span&gt;. If the model class has only one element then &lt;span class="math inline"&gt;\(m=M\)&lt;/span&gt;. &lt;/p&gt;'><sup>6</sup></a> When we summarize the model with the inquiry, we obtain an “answer under the model.” We formalized this as <span class="math inline">\(I(m) = a^m\)</span>. You can think of the difference between <span class="math inline">\(I\)</span> and <span class="math inline">\(a^m\)</span> as the difference between a question and its answer. <span class="math inline">\(I\)</span> is the question we ask about the model and <span class="math inline">\(a^m\)</span> is the answer. Alternatively, you can think of <span class="math inline">\(I\)</span> as the “estimand” (that which is to be estimated) and <span class="math inline">\(a^m\)</span> as the value of the estimand.</p>
<!-- I'm getting tripped up by I being the estimand. In APSR we say a^m is what we want to estimate. I think we don;t want to estimate I -- I is a function, we want to estimate a^m-->
<p>In this book when we talk about inquiries, we will usually be referring to single-number summaries of models. Some common estimands are descriptive, such as the means, conditional means, correlations, partial correlations, quantiles, and truth statements about variables in the model. Others are causal, such as the average difference in one variable when a second variable is set to two different values. You can think of a single-number inquiry as the atom of the research question.</p>
<p>While most inquiries are “atomic” in this way, some inquiries are more complex than a single-number summary. For example, the best linear predictor of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span> is a two-number summary: it is the pair of numbers (the slope and intercept) that minimizes the total squared distance between the line and each value of <span class="math inline">\(Y\)</span>. Note that this is not a <em>causal</em> estimand but it is still well defined. No need to stop at two-number summaries though. We could imagine the best quadratic predictor of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span> (three-number summary), and so on. See Figure <a href="defining-the-inquiry.html#fig:ch3polynomials">7.1</a>. We could have an inquiry that is the full conditional expectation function of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>, no matter how wiggly, nonlinear, and nuanced the shape of that function – it could in principle be a 1,000 number summary of the model, or much more.</p>
<!-- MH: Is this an example of an estimand that is a function of d not m?  -->
<div class="figure">
<span id="fig:ch3polynomials"></span>
<img src="book_files/figure-html/ch3polynomials-1.svg" alt="Inquiries based on different numbers of parameters" width="100%"><p class="caption">
Figure 7.1: Inquiries based on different numbers of parameters
</p>
</div>
<p>And of course, it need not be a number at all: the answer to your question might be “blue” or “the normal distribution.” Or it might be a set. For instance, in qualitative comparative analysis (QCA) with Boolean variables (“crisp-set QCA”), a common inquiry is: what is the minimal set of conditions sufficient to produce <span class="math inline">\(Y\)</span> <span class="citation">(Ragin <a href="references.html#ref-ragin1987" role="doc-biblioref">1987</a>)</span>. For instance, if <span class="math inline">\(Y\)</span> happens any time that causal factor <span class="math inline">\(A\)</span> is present or when <span class="math inline">\(A\)</span> is absent but <span class="math inline">\(B\)</span> is present, then <span class="math inline">\(a^M\)</span> is a set: <span class="math inline">\(\{A, \neg A \&amp; B\}\)</span>.</p>
<p>It could be a set of questions about an explanatory model. For instance, a researcher might articulate a handful of important questions about the model that all have to come out a certain way or the model itself should be rejected. These complex inquires are made up of a series of atomic inquiries – we’re interested in the sub-inquiries only insofar as they help us understand the real inquiry – is this model of the world a good one or not.</p>
<div id="three-families-of-inquiries" class="section level2">
<h2>
<span class="header-section-number">7.1</span> Three families of inquiries<a class="anchor" aria-label="anchor" href="#three-families-of-inquiries"><i class="fas fa-link"></i></a>
</h2>
<!-- MH: My vote: four types of queries: the three from Pearl (descriptive, interventionist, counterfactual) plus "model" queries in which you try to learn the model. -->
<!-- AC: Could you say more about "interventionist"? not sure I understand the difference vs. counterfactual. Also, I was thinking here that the basic distinction between descriptive and causal is the most important, "model" queries are made up of a series of sub-inquiries that themselves are either descriptive or causal. Model queries can mix both. Would that cover it?-->
<!-- MH: INterventionist would be a treatment effect; attribution is counterfactual --- imagine different to how things are. These are Pearlean usages; not a great fan since of course treatment effect requires imagining things different, though only at the population level -->
<!-- MH: Suggest a table that gives a real broad set of inquiries that people can use as a reference; ATE, LATE, PATEs, SATEs, CDEs, lots and lots. Even better if we can define most of them off a simple DAG. -->
<!-- AC: tough for one DAG, but We've got the table started now at least -->
<p><span class="citation">Pearl and Mackenzie (<a href="references.html#ref-pearl2018book" role="doc-biblioref">2018</a>)</span> usefully describes a “ladder of causation” which can be used to categorize classes of inquiries. The bottom rung of the ladder focuses on descriptive inquiries about how the world was, is, and will be. The second rung focuses on questions about the effects of interventions: what happens to <span class="math inline">\(Y\)</span> if you do something to <span class="math inline">\(X\)</span>? The third rung is about counterfactuals: How would <span class="math inline">\(Y\)</span> have been different if <span class="math inline">\(X\)</span> were different. The last two rungs both involve causal inquiries, questions about how the world would have been, would be, or would be in the future if some variables were set to different levels.</p>
<!-- You might think of the distinction in terms of a DAG. Descriptive inquiries are about the nodes of a dag whereas causal inquires are about the edges.  -->
<p>Descriptive and causal inference have in common the difficulty of inferring unseen things from observed data. The fundamental problem of causal inference is well known. Because a unit cannot simultaneously be both treated and untreated, we can only observe at most one potential outcome for any particular unit and so can never <em>measure</em> causal effects – we have to infer them. Similar problems confront descriptive inference. The concepts we want to measure are latent constructs. A perfect measurement is generally not possible, so our measurements of the latent constructs usually include some measurement error.
<!-- Just like we can't know for sure how, counterfactually, a unit would have responded if the treatment had been set to a different level, we likewise can't know for sure whether our measurements accurately reflect the latent construct. --></p>
<p>More specifically, a descriptive <em>inference</em> is a conclusion about the features of a latent variable <span class="math inline">\(Y^*\)</span> for some sets of units on the basis of observations of a measured variable <span class="math inline">\(Y\)</span>, with measurements possibly taken from a different set of units. The feature we seek to describe—our inquiry—is some summaries of <span class="math inline">\(Y^*\)</span> such as its mean or perhaps its covariance with a second latent variable <span class="math inline">\(X^*\)</span>. When we do descriptive research, we draw inferences about features of the nodes of the latent causal model <span class="math inline">\(M\)</span>. Our measurement can be imperfect for two reasons: that we do not get to observe the quantity of interest directly for the units we study, and that the units we study are only a subset of the units of interest. It is these challenges that give rise to the focus on descriptive <em>inference</em> rather than measurement alone.</p>
<p>A causal <em>inference</em> is a conclusion about the responses of variables to changes in other variables. Even if we do an exceptional job measuring <span class="math inline">\(X^*\)</span> and <span class="math inline">\(Y^*\)</span> with <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, we will still have trouble learning about causal effects because causal effects are quite literally unobservable, they have to be inferred.</p>
<div id="descriptive-inquiries" class="section level3">
<h3>
<span class="header-section-number">7.1.1</span> Descriptive inquiries<a class="anchor" aria-label="anchor" href="#descriptive-inquiries"><i class="fas fa-link"></i></a>
</h3>
<p>Descriptive inquiries are usually about latent variables since we mostly care about the true values of the variables in the models. Measured variables are often distinct from latent variables, which gives rise to a problem of descriptive inference. Normally, we define our inquiries in terms of the true latent variables rather than their measured counterparts; making the distinction explicit in a design object is especially important when the risks of measurement error loom large.</p>
<!-- MH: I am not sure that there is a fundamental problem of descriptive  inference. Sure if you stipulate that you cannot measure correctly then we have a problem; but the fundamental problem of causal inference is that this is technically impossible. It's not just a stipulation -->
<p>Table <a href="defining-the-inquiry.html#tab:descriptiveestimands">7.1</a> enumerates some common descriptive estimands. These estimands have in common that you do not need any counterfactual quantities in order to define. Note especially that the covariance (similarly, the correlation) between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> enters as a descriptive estimand, so too does the line of best fit for <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:descriptiveestimands">Table 7.1: </span> Descriptive inquiries</caption>
<colgroup>
<col width="24%">
<col width="52%">
<col width="22%">
</colgroup>
<thead><tr class="header">
<th>Inquiry</th>
<th>Description</th>
<th>Code</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mathbb{E}_{i\in N}(Y)\)</span></td>
<td>The average value of the variable Y</td>
<td><code><a href="https://rdrr.io/r/base/mean.html">mean(Y)</a></code></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathbb{E}[Y | X = 1]\)</span></td>
<td>A conditional expectation of Y given X = 1.</td>
<td><code><a href="https://rdrr.io/r/base/mean.html">mean(Y[X == 1])</a></code></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathbb{V}[Y]\)</span></td>
<td>The variance of Y</td>
<td><code>pop.var(Y)</code></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathrm{Cov}(X, Y)\)</span></td>
<td>The covariance of X and Y</td>
<td><code>pop.cov(X, Y)</code></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathrm{BLP}(Y | X)\)</span></td>
<td>The best linear predictor of Y given X</td>
<td><code>cov(Y, X) / var(X)</code></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathrm{CEF}(Y | X)\)</span></td>
<td>Conditional expectation function of Y given X</td>
<td><code>cef(Y, X)</code></td>
</tr>
<tr class="odd">
<td>Truth status of X</td>
<td>Is X True or False?</td>
<td><code>X == TRUE</code></td>
</tr>
</tbody>
</table></div>
</div>
<div id="inquiries-about-causal-effects" class="section level3">
<h3>
<span class="header-section-number">7.1.2</span> Inquiries about causal effects<a class="anchor" aria-label="anchor" href="#inquiries-about-causal-effects"><i class="fas fa-link"></i></a>
</h3>
<p>Inquiries about causal effects involve a comparison of at least two possible worlds. For example, an inquiry might be the causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> for a single unit. In order to infer that causal effect, we would need to know the value of <span class="math inline">\(Y\)</span> in two worlds: one world in which <span class="math inline">\(X\)</span> is set to 1 and one in which <span class="math inline">\(X\)</span> is set to 0.</p>
<p>Table <a href="defining-the-inquiry.html#tab:causalestimands">7.2</a> enumerates some common causal estimands. These estimands vary in the population they refer to—for instance are they statements about samples (SATEs) or populations (PATEs)? They can also depend upon possibly unobservable characteristics of populations—such as their value on a covariate (CATEs)–or the way they respond to other causes (the CACE targets the effect of treatment specifically for compliers —those that take up treatment because they are encouraged to). Finally, they may be summaries of more than one potential outcome: for instance, the interaction effect is defined here <em>at the individual level</em> as the effect of one treatment on the effect of another treatment.</p>
<!-- - Estimand scope:What is the set of units which you want to learn the answer about? Know what ATE averages over -->
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:causalestimands">Table 7.2: </span> Causal inquiries</caption>
<colgroup>
<col width="27%">
<col width="39%">
<col width="33%">
</colgroup>
<thead><tr class="header">
<th>Inquiry</th>
<th>Description</th>
<th>Code</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mathbb{E}_{i\in N}[Y_i(1) - Y_i(0)]\)</span></td>
<td>Average treatment effect (ATE)</td>
<td><code><a href="https://rdrr.io/r/base/mean.html">mean(Y_D_1 - Y_D_0)</a></code></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathbb{E}[Y_i(1) - Y_i(0) | X_i = 1]\)</span></td>
<td>Conditional average treatment effect (CATE) for X = 1</td>
<td><code><a href="https://rdrr.io/r/base/mean.html">mean(Y_D_1[X == 1] - Y_D_0[X == 1])</a></code></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\mathbb{E}[Y_i(1) - Y_i(0) | d_i(1) &gt; d_i(0)]\)</span></td>
<td>Complier average causal effect (CACE) or local average treatment effect (LATE)</td>
<td><code><a href="https://rdrr.io/r/base/mean.html">mean(Y_D_1[D_Z_1 &gt; D_Z_0] - Y_D_0[D_Z_1 &gt; D_Z_0])</a></code></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathbb{E}[(Y_i(1, 1) - Y_i(0,1)) - (Y_i(1, 0) - Y_i(0,0))]\)</span></td>
<td>Causal interactions of <span class="math inline">\(D_1\)</span> and <span class="math inline">\(D_2\)</span>
</td>
<td><code><a href="https://rdrr.io/r/base/mean.html">mean((Y_D1_1_D2_1 - Y_D1_0_D2_1) - (Y_D1_1_D2_0 - Y_D1_0_D2_0))</a></code></td>
</tr>
</tbody>
</table></div>
<p>Generations of students have been told to excise words that connote causality from their empirical writing. “Affects” becomes “is associated with” and “impacts” becomes “moves with.” Being careful about causal language is of course very important (it’s really true that correlation does not imply causation!). But this change in language is not usually accompanied by a change in inquiry. Many times we are faced with drawing causal inferences from less than ideal data – but the deficiencies of the data strategy should not lead us too far away from our inferential targets. If the inquiry is a causal inquiry, then the move from “causes” to “is correlated with” might be a good description of the actual data analysis, but it doesn’t move us closer to providing an answer to the inquiry.</p>
</div>
<div id="causalattribution" class="section level3">
<h3>
<span class="header-section-number">7.1.3</span> Causal attribution inquiries<a class="anchor" aria-label="anchor" href="#causalattribution"><i class="fas fa-link"></i></a>
</h3>
<p>Another kind of data-dependent inquiry that is distinct from the notion of a causal effect is that of causal attribution. A causal effect inquiry focuses on the change in an outcome that would be induced by a change in the causal variable (at the unit-level or across units) <em>irrespective of the values that the outcome takes</em>. By contrast, causal attribution inquiries focus on probabilities that condition on realized outcomes, such as, the “probability of the absence of the outcome in the hypothetical absence of the treatment (<span class="math inline">\(Y_i(0) = 0\)</span>) given the actual presence of both (<span class="math inline">\(D_i = Y_i = 1\)</span>)” <span class="citation">(Yamamoto <a href="references.html#ref-yamamoto2012understanding" role="doc-biblioref">2012</a>, 240–41)</span>. <span class="citation">Goertz and Mahoney (<a href="references.html#ref-goertz2012tale" role="doc-biblioref">2012</a>)</span> refers to causal attribution inquiries as cause-of-effects questions because they start with an outcome (an effect) and seek to validate a hypothesis about its cause.</p>
<p>The dependence of these inquiries on actual outcomes makes them harder (though not impossible!) to answer with the tools of quantitative science, though they are often of central interest to scientific and policy agendas and have occupied a large number of qualitative studies. Questions like “‘Was economic crisis necessary for democratization in the Southern Cone of Latin America?’ or ‘Were high levels of foreign investment in combination with soft authoritarianism and export-oriented policies sufficient for the economic miracles in South Korea and Taiwan?’” are examples of such inquiries <span class="citation">(Goertz and Mahoney <a href="references.html#ref-goertz2012tale" role="doc-biblioref">2012</a>)</span>. Though they bear a resemblance and <em>are</em> related to causal effects inquiries that focus on observed subsets (such as the average treatment effect on the treated, or ATT)<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Specifically, as &lt;span class="citation"&gt;Yamamoto (&lt;a href="references.html#ref-yamamoto2012understanding" role="doc-biblioref"&gt;2012&lt;/a&gt;)&lt;/span&gt; points out, the causal attribution estimand for binary variables can be written &lt;span class="math inline"&gt;\(\Pr(Y_i(0) = 0 \mid D_i = Y_i = 1)\)&lt;/span&gt;, while the average treatment effect among those successfully treated can be written &lt;span class="math inline"&gt;\(E[Y_i(1) - Y_i(0) \mid D_i = Y_i = 1]\)&lt;/span&gt;. Given binary outcomes and the additive property of expectations, the ATE among those successfully treated can be written &lt;span class="math inline"&gt;\(\Pr(Y_i(1)\mid D_i = Y_i = 1) - \Pr(Y_i(0) \mid D_i = Y_i = 1)\)&lt;/span&gt;. The causal attribution inquiry can be written as one minus the second term of the ATE among the successfully treated.&lt;/p&gt;'><sup>7</sup></a> it is important not to confuse the two kinds of inquiries, as often happens.</p>
<p>While it is increasingly common to explicitly formalize causal effect inquiries, it is less common to formalize causal attribution inquiries. Doing so, however, can be important to provide the specificity required to diagnose a design on a computer. <span class="citation">Pearl (<a href="references.html#ref-pearl1999probabilities" role="doc-biblioref">1999</a>)</span> provides formal definitions for these inquiries using the language of causal necessity and sufficiency, depicted in the table below. To put these inquiries in the context of the democratic peace hypothesis, for example, in a given country dyad-year, <span class="math inline">\(Y_i = 1\)</span> and <span class="math inline">\(D_i = 1\)</span> could represent “Peace” and “Both democracies” and <span class="math inline">\(Y_i = 0\)</span> and <span class="math inline">\(D_i = 0\)</span> could represent “War” and “Not both democracies.” Then <span class="math inline">\(\Pr(Y_i(D_i = 0) = 0 \mid D_i = Y_i = 1)\)</span> asks, among peaceful, fully democratic dyads, what is the proportion that would have had wars were they not both democracies—that is, in what proportion of dyad-years was democracy a necessary cause of peace? Similarly, <span class="math inline">\(\Pr(Y_i(D_i = 1)=1 \mid D_i = Y_i = 0)\)</span> asks, among dyads that had a war and at least one non-democracy in a given year, what is the proportion that would have experienced peace if both countries were democracies—in other words, in what proportion of cases would democracy have been sufficient to cause peace? <span class="citation">Yamamoto (<a href="references.html#ref-yamamoto2012understanding" role="doc-biblioref">2012</a>)</span> extends on this account to focus on causal attribution inquiries that focus on important subsets, such as compilers.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:attributionestimands">Table 7.3: </span> Causal attribution inquiries</caption>
<colgroup>
<col width="34%">
<col width="26%">
<col width="38%">
</colgroup>
<thead><tr class="header">
<th>Inquiry</th>
<th>Description</th>
<th>Code</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\Pr(Y_i(D_i=0)=0 \mid D_i = Y_i = 1)\)</span></td>
<td>Probability <span class="math inline">\(D\)</span> necessary for <span class="math inline">\(Y\)</span>
</td>
<td><code><a href="https://rdrr.io/r/base/mean.html">mean(Y_D_0[D == 1 &amp; Y == 1] == 0)</a></code></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\Pr(Y_i(D_i=1)=1 \mid D_i = Y_i = 0)\)</span></td>
<td>Probability <span class="math inline">\(D\)</span> sufficient for <span class="math inline">\(Y\)</span>
</td>
<td><code><a href="https://rdrr.io/r/base/mean.html">mean(Y_D_1[D == 0 &amp; Y == 0] == 1)</a></code></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\Pr(Y_i(D_i = 0) = 0 \mid D_i = Y_i = 1, D_i(Z_i)=z)\)</span></td>
<td>Complier probability <span class="math inline">\(D\)</span> necessary for <span class="math inline">\(Y\)</span>
</td>
<td><code><a href="https://rdrr.io/r/base/mean.html">mean(Y_D_0[D == 1 &amp; Y == 1 &amp; D_Z_1 == 1 &amp; D_Z_0 == 0] == 0)</a></code></td>
</tr>
</tbody>
</table></div>
<p>Like all designs, those with causal attribution inquiries can be declared, simulated, and diagnosed on a computer. Something to consider, however, is that the model may produce datasets in which the effect does not occur, and so questions defined over units for whom it occurred are undefined. One way to avoid this is to construct a model such that the event occurs for at least one unit with probability one.</p>
</div>
</div>
<div id="estimands-declared" class="section level2">
<h2>
<span class="header-section-number">7.2</span> Estimands declared<a class="anchor" aria-label="anchor" href="#estimands-declared"><i class="fas fa-link"></i></a>
</h2>
<p>Table <a href="defining-the-inquiry.html#tab:MI1b">7.4</a> shows the “draws” of three estimands. We declare a simple reference model and then an inquiry—or rather a set of inquiries. The estimand draws are then implemented by drawing a particular model <span class="math inline">\(m\)</span> from <span class="math inline">\(M\)</span> and then applying <span class="math inline">\(I\)</span> to the draw.</p>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">model</span> <span class="op">&lt;-</span>
  <span class="fu">declare_population</span><span class="op">(</span>N <span class="op">=</span> <span class="fl">100</span>,
                     U <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>,
                     D <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">1</span>, <span class="fl">.5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">declare_potential_outcomes</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="va">D</span> <span class="op">+</span> <span class="va">U</span>, 
                             assignment_variable <span class="op">=</span> <span class="st">"D"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">reveal_outcomes</span><span class="op">(</span><span class="va">Y</span>, <span class="va">D</span><span class="op">)</span>

<span class="va">inquiry</span> <span class="op">&lt;-</span>
  <span class="fu">declare_estimand</span><span class="op">(</span>
    treatment_group_mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">Y</span><span class="op">[</span><span class="va">D</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span><span class="op">)</span>,
    ATE <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">Y_D_1</span> <span class="op">-</span> <span class="va">Y_D_0</span><span class="op">)</span>,
    probability_of_causation <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">Y_D_0</span> <span class="op">&lt;</span> <span class="fl">0</span><span class="op">)</span><span class="op">[</span><span class="va">D</span> <span class="op">==</span> <span class="fl">1</span> <span class="op">&amp;</span> <span class="va">Y_D_1</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">]</span><span class="op">)</span>
  <span class="op">)</span>

<span class="fu">draw_estimands</span><span class="op">(</span><span class="va">model</span> <span class="op">+</span> <span class="va">inquiry</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:MI1b">Table 7.4: </span>One model three estimands.
</caption>
<thead><tr>
<th style="text-align:left;">
estimand_label
</th>
<th style="text-align:right;">
estimand
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
treatment_group_mean
</td>
<td style="text-align:right;">
0.332
</td>
</tr>
<tr>
<td style="text-align:left;">
ATE
</td>
<td style="text-align:right;">
0.500
</td>
</tr>
<tr>
<td style="text-align:left;">
probability_of_causation
</td>
<td style="text-align:right;">
0.276
</td>
</tr>
</tbody>
</table></div>
<p>The first estimand is a descriptive estimand: the average outcome for <span class="math inline">\(Y\)</span> when <span class="math inline">\(D = 1\)</span>. Note that the declaration of the estimand does not make use of any counterfactual quantities.</p>
<p>The second estimand is a causal effect. The inquiry is asked of the same model but this time the inquiry takes the average difference, across individuals, in two potential outcomes. Unlike the descriptive estimand, this estimand uses information about <span class="math inline">\(Y\)</span>’s potential outcomes but it does not use any information about the distribution of <span class="math inline">\(D\)</span>.</p>
<p>The third inquiry asks an attribution question, in this case on continuous data. In this case, we ask about the share of units with positive values of <span class="math inline">\(Y\)</span> and <span class="math inline">\(D=1\)</span> that <em>would have had</em> negative values of <span class="math inline">\(Y\)</span> were <span class="math inline">\(D=0\)</span>. This estimand requires information about both potential outcomes and actual outcomes (for <span class="math inline">\(D\)</span>).</p>
<p>In this illustration, each “run” of <code>model + inquiry</code> provides a different value for the estimand (or, more precisely, this is true in this design for the first and the third estimand). How is this variation to be understood? As we noted in the last chapter, we might think of a superpopulation with a distribution of estimands and that we have an interest in understanding that superpopulation distribution, or we might think of the model, <span class="math inline">\(M\)</span>, as representing a set of possible worlds and we are interested in performance in each of them <span style="color: red;"><small>[FLAG]</small></span>. Which approach we take will matter when we turn to diagnosis.
<!-- (WHAT DOES PERFORMANCE (IN A WORLD) MEAN?) --></p>
</div>
<div id="common-complexities-in-defining-estimands" class="section level2">
<h2>
<span class="header-section-number">7.3</span> Common complexities in defining estimands<a class="anchor" aria-label="anchor" href="#common-complexities-in-defining-estimands"><i class="fas fa-link"></i></a>
</h2>
<div id="data-dependent-inquiries" class="section level3">
<h3>
<span class="header-section-number">7.3.1</span> Data-dependent inquiries<a class="anchor" aria-label="anchor" href="#data-dependent-inquiries"><i class="fas fa-link"></i></a>
</h3>
<p>Most of the inquiries we have introduced thus far depend on variables in the model, but not on features of the data and answer strategies (the attribution estimands are an exception). However, common inquiries do depend on realizations of the research design.</p>
<p>The first type depends on realizations of the data <span class="math inline">\(d\)</span>: inquiries about units within a sample depend on which units enter the sample; inquiries about treated units depend on which are treated. The sample average treatment effect is a common inquiry used by experimental researchers who wish to not worry about how their effects generalize to a population but only about identifying the causal effect within the units in front of them. There is a true sample average treatment effect <span class="math inline">\(a^w\)</span> for every possible sample that we could draw. But which of those fixed values is selected as our inquiry if we define <span class="math inline">\(I\)</span> as the sample average effect depends on which sample is actually selected by our sampling procedure. The same is true when we condition inquiries on the set of treated units—in that case, our estimand is defined <em>conditional</em> on who received treatment.</p>
<p>There is a curiosity here in that one might wonder how to assess whether a given sampling scheme or assignment procedure is good, <em>ex ante</em>, in cases in which the question is only posed conditional on sampling and assignment. Odder still one might wonder about how to conduct statistics on effect estimates when both the sample and treatment assignment is fixed, since, conditional upon these features, it is hard to see where variation in a sampling distribution for estimates might come from. A reasonable response to such concerns is that in many cases one can pose an ex ante question in the following form: say I am committed to a family of designs in which I allocate 50 units to treatment, with each unit equally likely to be assigned, then what will be the effect on those that receive treatment, whoever they end up being? In this case, each “run” of the study produces a different treatment group and the quality of the design is assessed with respect to this distribution of possible treatment groups; similarly, errors are calculated over this distribution. Moreover, given the constraints on the admissible assignment schemes, one can assess whether one scheme fares better than another on different criteria.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:datadependentestimands">Table 7.5: </span> Data-dependent inquiries.</caption>
<colgroup>
<col width="28%">
<col width="39%">
<col width="32%">
</colgroup>
<thead><tr class="header">
<th>Inquiry</th>
<th>Description</th>
<th>Code</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\mathbb{E}[Y_i(1) - Y_i(0) | D_i = 1]\)</span></td>
<td>Average treatment effect on the treated (ATT)</td>
<td><code><a href="https://rdrr.io/r/base/mean.html">mean(Y_D_1[D == 1] - Y_D_0[D == 1])</a></code></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathbb{E}[Y_i(1) - Y_i(0) | S_i = 1]\)</span></td>
<td>Sample average treatment effect (SATE)</td>
<td><code><a href="https://rdrr.io/r/base/mean.html">mean(Y_D_1[S == 1] - Y_D_0[S == 1])</a></code></td>
</tr>
</tbody>
</table></div>
<p>A second design-dependent inquiry class depends not on <span class="math inline">\(d\)</span> but <span class="math inline">\(A(d) = a^d\)</span>, the <em>answer</em> given the data. In an <span class="math inline">\(a^d\)</span>-dependent inquiry, we only know the inquiry after seeing the results of our study. When we collect data on ten variables and calculate the correlation between all ten on a separate outcome variable, and then report on the magnitude of the correlation of the seventh variable - the only one that was statistically distinguishable from zero. If our inquiry is “which of these seven variables is significant” then there will be no problem, as long as we include a multiple comparisons correction to adjust for the probability of finding one significant under null effects due to random chance. If we started with the question of what is the correlation between variable seven and the outcome, we would also have no problem. However, if with our procedure we think of our inquiry as what is the correlation between variable seven and the outcome, then we have a problem: we are not accounting for the multi-step procedure in our answer strategy and we will not be able to provide good answers to that inquiry. In short, although there can be dangers if we are guided by the realization of our answer in <em>selecting</em> an inquiry, there is no problem with procedure-based answer strategies—we just must be honest about our original inquiry. This problem comes up in descriptive inference in looking at multiple correlations as in this example, but also in many other places such as searching for heterogeneity in treatment effects in experiments and nested research designs that iterate between levels of data <span class="citation">(Lieberman <a href="references.html#ref-lieberman2005nested" role="doc-biblioref">2005</a>)</span>.</p>
</div>
<div id="non-decomposable-inquiries" class="section level3">
<h3>
<span class="header-section-number">7.3.2</span> Non-decomposable inquiries<a class="anchor" aria-label="anchor" href="#non-decomposable-inquiries"><i class="fas fa-link"></i></a>
</h3>
<p>Most of the inquiries we have looked at are group level summaries of individual level inquiries. These are decomposable in the sense that you can think of an average effect for a large group as being the average of a set of average effects of smaller groups. However, not all inquiries are of this form. Some—such as the best linear fit—are complex summaries of possible data. Others are still more notional. Consider, for example, the estimand that the Regression Discontinuity Design (RDD) shoots at. In the RDD model (see Section <a href="observational-designs-for-causal-inference.html#RDD">16.4</a>), we imagine units with <span class="math inline">\(Y_i(1)\)</span>, <span class="math inline">\(Y_i(0)\)</span>. Each <span class="math inline">\(i\)</span> also has a value on a “running variable”, <span class="math inline">\(x_i\)</span>, and units receive treatment if and only if <span class="math inline">\(x_i&gt;0\)</span>. In this case the “effect at the point of discontinuity” might be written:</p>
<p><span class="math display">\[E_{i|x_i = 0}(Y_i(Z=1) - Y_i(Z=0))\]</span></p>
<p>Curiously, however, there may be no units for whom <span class="math inline">\(x_i = 0\)</span>, so we cannot easily think of the estimand as being a summary of individual potential outcomes.</p>
<p>One way to resolve this is to think of <span class="math inline">\(X\)</span> as being randomized, at least locally, in which case we can define the estimand as:</p>
<p><span class="math display">\[\mathbb{E}_{i}(Y_i(Z=1, X=0) - Y_i(Z=0, X=0))\]</span></p>
<p>With this conceptualization the estimand is an average of individual effects, the challenge is that we need to make an inference in a condition where we have no data.</p>
<p>Another approach is to imagine a more complex summary where we construct a best fit continuous potential outcomes function for the cases with <span class="math inline">\(Z=1\)</span> and <span class="math inline">\(Z=0\)</span> and evaluate the difference between these when <span class="math inline">\(X=0\)</span>. Though not an average of individual effects, this difference is nevertheless a summary of the potential outcomes. Note though that the nature of the estimand (recall we are discussing the estimand, not the estimate) depends on how the potential outcomes function is constructed—is it, for instance, a linear function or a higher-order polynomial?</p>
</div>
<div id="model-dependent-inquiries" class="section level3">
<h3>
<span class="header-section-number">7.3.3</span> Model-dependent inquiries<a class="anchor" aria-label="anchor" href="#model-dependent-inquiries"><i class="fas fa-link"></i></a>
</h3>
<p>A similar conceptualization can be used for settings where model parameters are estimands. For instance, we might have access to data on decisions by subjects in a lab and seek to estimate a “coefficient of risk aversion.” The reference model might not include such a coefficient—indeed we might not be willing to believe that such a number really exists for subjects. Yet we might still ask: if we had access to all possible choices, what coefficient would best summarize the choices of an agent. The answer provides the estimand which we then seek to estimate on finite data. <span style="color: red;"><small>[FLAG]</small></span>
<!-- (HOW IS IT MODEL DEPENDENT YET NOT INCLUDED IN THE REFERENCE MODEL?) --></p>
</div>
<div id="complex-counterfactual-inquiries" class="section level3">
<h3>
<span class="header-section-number">7.3.4</span> Complex counterfactual inquiries<a class="anchor" aria-label="anchor" href="#complex-counterfactual-inquiries"><i class="fas fa-link"></i></a>
</h3>
<p>The counterfactual queries we have described so far involve imagining a change to one variable and assessing the effects on another, yet much more complex causal queries are imaginable including quantities about events that are not possible even under the reference model. An example is the “controlled direct effect.” We imagine for instance that <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> directly and indirectly. Say in particular that <span class="math inline">\(X\)</span> causes <span class="math inline">\(M\)</span> and conditional on <span class="math inline">\(M=0\)</span> <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> directly. Then the controlled direct effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> is:</p>
<p><span class="math display">\[\mathrm{CDE} = Y(X=1, M=1) - Y(X=0, M=1)\]</span></p>
<p>this is a well-defined quantity under the potential outcomes and DAG formulation. But it can require mental gymnastics in situations in which, say <span class="math inline">\(M=1\)</span> would never arise if indeed <span class="math inline">\(X\)</span> were 0. For instance: would a Democrat win in the presidential elections affect the success of Democrats in mid-term elections, conditional on the presidency remaining in Republican hands.</p>
<!-- ### Relationship between causal and descriptive inquiries -->
<!-- You can think of causal inference as repeated descriptive inference: we have to describe $Y$ in multiple possible worlds. -->
<!-- Causal inquiries like the average effect of $A$ on $B$ in a causal model like $A \rightarrow B \leftarrow U$ are helped enormously by good descriptive inference about the nodes $A$ and $B$, but the focus is on the edge between them. You typically can't learn about the edge by doing descriptive inference on the nodes only. If we measure $A$ and $B$ and find that they covary, we can't be sure that $A \rightarrow B$ because it could be that $A \leftarrow U \rightarrow B$. This problem goes by the familiar phrase that "correlation doesn't imply causation," which is true and is a problem that can't be wished away. But "correlation doesn't imply causation" also kind of misses the point. The point is that you can't see causality because it involves counterfactuals, which are imaginary and unseen. You have to infer causality on the basis of design. -->
</div>
<div id="inquiries-with-continuous-causal-variables" class="section level3">
<h3>
<span class="header-section-number">7.3.5</span> Inquiries with continuous causal variables<a class="anchor" aria-label="anchor" href="#inquiries-with-continuous-causal-variables"><i class="fas fa-link"></i></a>
</h3>
<p>Inquiries that focus on a small number of potential outcomes are usually quite easy to write down: for a binary treatment in a model with no spillovers, there are only two potential outcomes, and the average treatment effect is defined as their average difference across units. But what about a treatment like income, for which there might be millions of potential outcomes, each one corresponding to a different dollar amount? For truly continuous treatments, there might even be an infinite number of potential outcomes.</p>
<p>One approach is to think of the estimand as a data-dependent marginal effect. For example, <span class="math inline">\(E[Y_i(X_i) - Y_i(X_i-1)]\)</span> captures the expected average difference between the observed data, in which people have income <span class="math inline">\(X_i\)</span>, and their unobservable outcome in which they have one dollar less. Another approach is to think of continuous-treatment estimands as the parameter from a regression that only an omniscient being could run. For example, we might define <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> as the solutions to:
<span class="math display">\[\min_{(\alpha,\beta)}\sum_i\int \left(Y_i(x) - \alpha - \beta x\right)^2f(x)dx\]</span>
Here, <span class="math inline">\(Y_i(x)\)</span> is the (unknown) potential outcome for unit <span class="math inline">\(i\)</span> in condition <span class="math inline">\(x\)</span>. Estimand <span class="math inline">\(\beta\)</span> can be thought of as the coefficient one would get on <span class="math inline">\(x\)</span> if one were to able to regress all possible potential outcomes on all possible conditions for all units (given the density of interest <span class="math inline">\(f(x)\)</span>). Often, the most straightforward approach is to define the inquiry over a finite number of potential outcomes drawn from the range of the treatment variable.
<!-- Mention here that the distribution of the treatment variable might affect the probability with which these POs are revealed? --></p>
</div>
<div id="undefined-and-unanswerable-inquiries" class="section level3">
<h3>
<span class="header-section-number">7.3.6</span> Undefined and unanswerable inquiries<a class="anchor" aria-label="anchor" href="#undefined-and-unanswerable-inquiries"><i class="fas fa-link"></i></a>
</h3>
<p>Declaring your design in terms of <span class="math inline">\(MIDA\)</span> may lead you to two awkward conclusions: your inquiry <span class="math inline">\(I\)</span> returns <span class="math inline">\(I(m) = a^m = \mathrm{NA}\)</span>, i.e., the answer to your inquiry is undefined; or your answer may be (currently) unanswerable, that is, there is no feasible <span class="math inline">\(D\)</span> and <span class="math inline">\(A\)</span> that yield an answer to <span class="math inline">\(I\)</span>. In both cases, one option is to change your inquiry. But often we selected <span class="math inline">\(I\)</span> because of its importance, so we may want to try to find an answer. In the case of undefined inquiries, we have no option but to select a new one. In the case of unanswerable inquiries, we can work to identify a novel <span class="math inline">\(D\)</span> and <span class="math inline">\(A\)</span> that change the set of feasible designs and provide an answer. In some cases, however, the fact that the inquiry is unanswerable may be due to unchangeable limitations of research such as the fundamental problems of causal inference or descriptive inference.</p>
</div>
<div id="example-1" class="section level3">
<h3>
<span class="header-section-number">7.3.7</span> Example<a class="anchor" aria-label="anchor" href="#example-1"><i class="fas fa-link"></i></a>
</h3>
<p><span class="citation">Björkman and Svensson (<a href="references.html#ref-Bjorkman:2009" role="doc-biblioref">2009</a>)</span> reports the results of a cluster-randomized trial of the effects of community-based monitoring of health clinics in Uganda to improve children’s health. The main inquiry was the average treatment effect on the child mortality rate. The study showed that the program was a success: in the control group, the child mortality rate was 144 per 1000 live births, compared with 97 in the treatment group, for a 33% reduction in child mortality.</p>
<p>The study also considered a second inquiry: the average treatment effect on the weight-for-age of children under 18 months. This inquiry is harder to think about, precisely because we know that community-based monitoring saved the lives of many children. To see the problem, consider Table <a href="defining-the-inquiry.html#tab:bstypes">7.6</a>, which shows four types of infants distinguished on the basis of their potential outcomes. Type A (for “Adverse”) is alive if in control, but dies if in treatment. Type B (“Beneficial”) is just the reverse: the child dies if untreated, but survives if treated. Type C (“Chronic”) would die under either condition and Type D (“Destined”) would live under either condition. For the first three types, the child dies under one condition, the other, or both. Since weight-for-age only exists if the child survives, the treatment effect on weight for A, B, and C types is undefined.</p>
<p>The main trouble here is that the average treatment effect averages over all four types so the ATE itself is also undefined. Since this inquiry is undefined, we’ll need to select a different one.</p>
<p>We might want to switch our inquiry to be about the average effect among D types only. However, this inquiry has a different problem – it’s unanswerable. Even though this inquiry is not undefined, it’s unanswerable because we won’t be able to learn who the D types are. In the treatment group, we can’t tell the Bs from the Ds and in the control group, we can’t tell the As from the Ds. The reason we can’t tell these types apart using realized data is the fundamental problem of causal inference.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:bstypes">Table 7.6: </span> Latent types.</caption>
<thead><tr class="header">
<th>Type</th>
<th>Alive(<span class="math inline">\(Z = 0\)</span>)</th>
<th>Alive(<span class="math inline">\(Z = 1\)</span>)</th>
<th>Weight(<span class="math inline">\(Z = 0\)</span>)</th>
<th>Weight(<span class="math inline">\(Z = 1\)</span>)</th>
<th>Estimand</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>1</td>
<td>0</td>
<td>exists</td>
<td>NA</td>
<td>undefined</td>
</tr>
<tr class="even">
<td>B</td>
<td>0</td>
<td>1</td>
<td>NA</td>
<td>exists</td>
<td>undefined</td>
</tr>
<tr class="odd">
<td>C</td>
<td>0</td>
<td>0</td>
<td>NA</td>
<td>NA</td>
<td>undefined</td>
</tr>
<tr class="even">
<td>D</td>
<td>1</td>
<td>1</td>
<td>exists</td>
<td>exists</td>
<td><span class="math inline">\(\mathbb{E}[\mathrm{Weight}(Z=1) - \mathrm{Weight}(Z=0)]\)</span></td>
</tr>
</tbody>
</table></div>
<p>What can be done in this situation? We might try to find a covariate <span class="math inline">\(X\)</span> that is correlated with being a D type and condition our analysis of the effect on weight on that covariate. Note that among this subgroup, the effect on mortality should be equal to zero. Finding such a covariate would be hard, though perhaps not impossible.</p>
<p>Alternatively, we might define our inquiry to be the average treatment on the average weight of living children within a cluster, but this inquiry requires careful interpretation. If the treatment saves the lives of children whose health is <em>marginal</em> in particular, then the effect on average weight could easily be negative, even though the treatment improves health. We specifically cannot interpret the answer to this inquiry to refer to the effect of treatment on health. That said, it might nevertheless be a useful number to know if we are in the position of administering healthcare resources – we’d want to send additional help to those treatment areas where the lives of unhealthy children (who otherwise would have perished) are being saved.</p>
</div>
</div>
<div id="how-should-you-select-inquiries" class="section level2">
<h2>
<span class="header-section-number">7.4</span> How should you select inquiries?<a class="anchor" aria-label="anchor" href="#how-should-you-select-inquiries"><i class="fas fa-link"></i></a>
</h2>
<p>It’s hard to know where to start when picking a research question. We want to pick one that is interesting in its own right or one that would facilitate a real-world decision. We want to pick research questions that we can learn the answer to someday, with a lot of effort. Unfeasible research questions should be abandoned as soon as possible, but of course, that’s hard to do. The trouble is that it’s hard to know what research questions are feasible before you start looking into it, and it’s really hard to quit research projects once you learn they are unfeasible because of the sunk cost fallacy. Among feasible research questions, we want to select ones that we are likely to obtain the most informative answers, in terms of moving our priors the most. This last criterion will often help us select among related, feasible inquiries that are about the same DAG but for which we know we can learn more and less through research.</p>
<p>Sometimes, people advise students to follow a “theory-first” route to picking a research question. Read the literature, find an unsolved puzzle, then start choosing among the methodological approaches that might answer the problem. Others eschew the theory-first approach: “How on earth are you going to happen to land upon an unsolved – and yet somehow solvable – puzzle just by reading!?” These advice-givers emphasize a method-first route. Master the technical data-gathering and analysis procedures first, then set off to find opportunities to apply them. The theory-first people then say: “how would you know an interesting theoretical question if it smacked you in the face!?”</p>
<p>Iteration between the two is typically necessary. In order to select research questions, empiricists have to be concerned about the entire research design. We have to develop empirical strategies to provide answers to our inquiries. We have to learn a lot about how to select data and answer strategies in ways that map on to inquiries about models. So empiricists have to learn both about models and inquiries (theory) as well as about data strategies and answer strategies (empirics).</p>
<p>The first criterion is the subjective importance of a question. The object of the importance may be a scientist, considering the value of building a theoretical understanding of the world; to a policymaker, deciding how to collect and allocate resources in a government; a private firm, who is making decisions about how to invest their own resources to maximize profit; or another individual or organization. The scientific enterprise is designed around the idea that importance is in the eye of the scientist and is not some objective quantity. This is for two reasons. First, the scientific or practical importance of a discovery may not be understood until decades later, when other pieces of the causal model are put together or the world faces new problems. Moreover, “importance” differs for different segments of society, and scientists must be able to study questions not judged important by groups in power in order to discover new ways to solve problems faced by the left-out groups.</p>
<p>Among important questions, researchers can select the <span class="math inline">\(I\)</span> they think they are likely to be able to learn the most about. We start with a prior distribution over <span class="math inline">\(a^w\)</span>, the true answer about the inquiry, from past research, and a good research design will substantially update that prior distribution, either by moving the mean of the distribution or reducing our uncertainty about it.</p>
<p>The final criterion is that among important, probative research designs there must be a feasible <span class="math inline">\(M\)</span>, <span class="math inline">\(D\)</span>, and <span class="math inline">\(A\)</span> that could answer <span class="math inline">\(I\)</span>. That means picking a good question <span class="math inline">\(I\)</span> does not just involve theory. You should study <span class="math inline">\(M\)</span> to understand which <span class="math inline">\(I\)</span>s are worth knowing. But you should also study <span class="math inline">\(D\)</span> and <span class="math inline">\(A\)</span> in order to learn how to demonstrate <span class="math inline">\(I\)</span>. A central goal of research methodologists is to expand the feasible set of <span class="math inline">\(D\)</span> and <span class="math inline">\(A\)</span> that can provide informative answers to important questions.</p>
<p>Clearly, research designs will vary how important, feasible, and probative they are, and so these criteria do not provide an immediate answer to how to select a design. Instead, the researcher must choose a weighting of the three, and norms in a research community may guide those weightings. In some disciplines, providing a minimally probative answer to a highly important question may be preferable to a highly probative answer to a less important question.
<!-- ```{r, fig.width = 4, fig.height = 4, echo = FALSE} -->
<!-- ggplot() +  -->
<!--   geom_abline(intercept = 5, slope = -1) +  -->
<!--   geom_abline(intercept = 6, slope = -1, lty = "dashed") +  -->
<!--   geom_function(fun = function(x) (x-2)^2, geom = "curve") +  -->
<!--   coord_fixed(ylim = c(0, 6), xlim = c(0, 6)) -->
<!-- ``` --></p>
<p>Here’s our best advice for how to get started picking a research question: Write down the <span class="math inline">\(M\)</span> and <span class="math inline">\(I\)</span> of any causal model that you think is important to get started thinking about selecting strong <span class="math inline">\(D\)</span>s and <span class="math inline">\(A\)</span>s. The goal is to learn how to map <span class="math inline">\(I(M)\)</span> to <span class="math inline">\(A(D)\)</span>. Then return to theory to find new important inquiries, then write down a new model, inquiry, data strategy, and answer strategy. This process is how we make progress on <span class="math inline">\(M\)</span>: we bring <span class="math inline">\(M\)</span> closer to <span class="math inline">\(W\)</span>, thereby making <span class="math inline">\(M\)</span> truer. In each iteration, consider how informative the answers you can provide: how much will they update what we know about the world?</p>
<p>People who are looking in the forest for mushrooms often don’t see a mushroom for a long period of time. After a while, they acclimate. They get their “eyes on,” and successful finds seem to be around every bend. In this analogy, the theory-building process is going for a walk in the forest and methods training is learning to spot mushrooms – you need to get your eyes on answerable research questions worth answering.</p>
</div>
<div id="further-reading-3" class="section level2">
<h2>
<span class="header-section-number">7.5</span> Further reading<a class="anchor" aria-label="anchor" href="#further-reading-3"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>
<span class="citation">Goertz and Mahoney (<a href="references.html#ref-goertz2012tale" role="doc-biblioref">2012</a>)</span> on differences across inquiries in qualitative and quantitative research.</li>
<li>
<span class="citation">Dawid (<a href="references.html#ref-dawid2000causal" role="doc-biblioref">2000</a>)</span> on cause-of-effects questions.</li>
<li>
<span class="citation">Yamamoto (<a href="references.html#ref-yamamoto2012understanding" role="doc-biblioref">2012</a>)</span> on causal attribution.</li>
<li>
<span class="citation">Zhang and Rubin (<a href="references.html#ref-zhang2003estimation" role="doc-biblioref">2003</a>)</span> on “truncation-by-death”</li>
</ul>
<!-- note do_bookdown is set in index.rmd, so we know if you're running just this .Rmd or compiling the book--><!-- start post here, do not edit above -->
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="specifying-the-model.html"><span class="header-section-number">6</span> Specifying the model</a></div>
<div class="next"><a href="crafting-a-data-strategy.html"><span class="header-section-number">8</span> Crafting a data strategy</a></div>
</div></main><div id="on-this-page-nav" class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#defining-the-inquiry"><span class="header-section-number">7</span> Defining the inquiry</a></li>
<li>
<a class="nav-link" href="#three-families-of-inquiries"><span class="header-section-number">7.1</span> Three families of inquiries</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#descriptive-inquiries"><span class="header-section-number">7.1.1</span> Descriptive inquiries</a></li>
<li><a class="nav-link" href="#inquiries-about-causal-effects"><span class="header-section-number">7.1.2</span> Inquiries about causal effects</a></li>
<li><a class="nav-link" href="#causalattribution"><span class="header-section-number">7.1.3</span> Causal attribution inquiries</a></li>
</ul>
</li>
<li><a class="nav-link" href="#estimands-declared"><span class="header-section-number">7.2</span> Estimands declared</a></li>
<li>
<a class="nav-link" href="#common-complexities-in-defining-estimands"><span class="header-section-number">7.3</span> Common complexities in defining estimands</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#data-dependent-inquiries"><span class="header-section-number">7.3.1</span> Data-dependent inquiries</a></li>
<li><a class="nav-link" href="#non-decomposable-inquiries"><span class="header-section-number">7.3.2</span> Non-decomposable inquiries</a></li>
<li><a class="nav-link" href="#model-dependent-inquiries"><span class="header-section-number">7.3.3</span> Model-dependent inquiries</a></li>
<li><a class="nav-link" href="#complex-counterfactual-inquiries"><span class="header-section-number">7.3.4</span> Complex counterfactual inquiries</a></li>
<li><a class="nav-link" href="#inquiries-with-continuous-causal-variables"><span class="header-section-number">7.3.5</span> Inquiries with continuous causal variables</a></li>
<li><a class="nav-link" href="#undefined-and-unanswerable-inquiries"><span class="header-section-number">7.3.6</span> Undefined and unanswerable inquiries</a></li>
<li><a class="nav-link" href="#example-1"><span class="header-section-number">7.3.7</span> Example</a></li>
</ul>
</li>
<li><a class="nav-link" href="#how-should-you-select-inquiries"><span class="header-section-number">7.4</span> How should you select inquiries?</a></li>
<li><a class="nav-link" href="#further-reading-3"><span class="header-section-number">7.5</span> Further reading</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="download-code" href="./defining-the-inquiry.R"><i class="far fa-file-code"></i> Download R code</a></li>
          
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Research Design: Declare, Diagnose, Redesign</strong>" was written by Graeme Blair, Alexander Coppock, and Macartan Humphreys. </p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
